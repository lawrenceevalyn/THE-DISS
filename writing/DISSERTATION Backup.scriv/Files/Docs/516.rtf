{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 TimesNewRomanPSMT;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgenericrgb\c0\c0\c0;\csgenericrgb\c100000\c99997\c99999;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\deftab720
\pard\pardeftab720\sl360\sa240\pardirnatural\partightenfactor0

\f0\fs32 \cf2 \cb3 \expnd0\expndtw0\kerning0
Chapter one takes up the eternal problem of archival gaps, and asks how we might interrogate or fill these gaps with computational methods. It asks how existing corpora of eighteenth century literature (mis)represent the 1790s. It begins with a task somewhere between a literature review and a scientific meta-analysis. My first goal will be to survey as broadly as possible the accessible mass holdings of eighteenth century texts (at least, the ones containing at least 100 works from the 1790s): simply putting all of this information in one place is useful as a lit review; adding a discussion of each archive\'92s selection criteria brings it into the realm of a meta-analysis. I expect to find systematic exclusions as archives \'93specialize\'94 from bibliographic data to fascimiles to transcripts. To contextualize these decisions about inclusion, I will research the history of how each corpus was formed. I will discuss the nature of their exclusions, and consider paths to ameliorate them. Then I will synthesize these disaparate sources of texts and metadata, a substantial technical challenge, to see how the task may be accomplished, and to see what correlations between archives might illuminate the decade. I am particularly curious to see if even one text will appear in all corpora, and, if so, which one it will be. Whichever texts appear most persistently will form the basis of my \'93case study\'94 in this chapter.\
Current materials acquired include:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\sl360\sa240\pardirnatural\partightenfactor0
\ls1\ilvl0\cf2 \cb3 \kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
51,965 bibliographic entries in the English Short Title Catalogue\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
42,463 facsimiles in Eighteenth Century Collections Online\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
10,832 facsimiles in 12 archives of Nineteenth Century Collections Online\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
4,381 facsimiles with OCR transcription in the HathiTrust Digital Library\
\ls1\ilvl0\kerning1\expnd0\expndtw0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
466 XML files created by the ECCO Text Creation Partnership\
\pard\tx560\pardeftab720\sl360\sa240\pardirnatural\partightenfactor0
\cf2 \cb3 Also under consideration is Project Gutenberg (as the corpus everyone uses but no one likes to admit to using).\
The first chapter thus introduces my decade of interest and the materials and perspectives I bring to bear on it, laying the foundation for my future questions about literary popularity and literary legacy.}