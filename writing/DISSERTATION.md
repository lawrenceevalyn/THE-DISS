Title: DISSERTATION  
Author: Lawrence Evalyn

# ch 1 - intro #



## Intro ##



### intro to overall argument ###



This dissertation seeks to determine, in as minute detail as possible, what the print landscape in England 1789-99 was actually like. It also seeks to explain, in equally minute detail, why this task of historical recovery is, in fact, impossible. [FLESH OUT MY ACTUAL ARGUMENT AND TOPIC]



### many definitions of DH ###



The field of “digital humanities,” now several scholarly generations into its development, has entered the phase in which so many scholars are carrying out “DH” research that no universally-acceptable definition of “DH” can exist. Many definitions are fundamentally methodological. [ADD A COUPLE DEFINITIONS OF DH HERE]. These definitions describe what might be called a “computational humanities.” Other definitions take up the new importance of digitality in daily life. [ADD SOME DIGITAL CULTURAL STUDIES STYLE DEFINITIONS HERE]. This kind of work is increasingly described as “digital cultural studies.” In positioning this work as a “DH” dissertation, I might at first glance seem to belong squarely within the “computational humanities.” To be sure, much of this work is intended to apply existing computational methodologies to conduct otherwise old-fashioned literary research. Several of my contributions, too, are purely methodological in nature, in the development of new code and new guidelines for computational research using particular digital resources. However, as a fuller discussion of Johanna Drucker’s distinction between “data” and “capta” will elucidate later in this chapter, no computational research exists separately from a specific, local, culturally-defined context. Accordingly, my computational research into eighteenth century literature and my development of new computational methodologies are both inevitably tied to “digital culture.” My results often have more to say about contemporary digital archives, and the history of literary record-keeping, than they do about the eighteenth century itself. I therefore rely on an extensive body of work in cultural digital studies to examine not only the eighteenth century, but eighteenth century studies.



### many histories of 1790s ###



So, too, are there many “histories” — or perhaps, narratives — available to describe the 1790s. [FOCUS ON POLITICS]. [FOCUS ON ROMANTICISM]. [FOCUS ON GOTHIC]. [RISE OF THE NOVEL] Of necessity, each of these histories must exclude something. [WHAT EACH EXCLUDES].



### reparative reading ###



It is difficult, when faced with flawed and complex competing narratives, to resist the impulse to simply critique and reject all options. If we may learn any lessons from the 1790s, however, surely one must be the danger of universal paranoia. Eve Sedgwick persuasively describes, in “Paranoid Reading and Reparative Reading,” the dominance of paranoia in literary criticism \cite{Sedgwick:2015up}. Rita Felski, in her article “After Suspicion” and then further in her recent monograph The Limits of Critique, continues in Sedgwick’s line. Felski asks: “Can we be postcritical — as distinct from uncritical?” \cite{Felski:z11z1lQx p.151}. Reparative readers are often critiqued for painting a much clearer picture of the paranoid mode than the reparative mode, leaving it unclear how one is meant to escape paranoia’s double-bind. But this is not to say that the attempt itself is unworthy. [CONCLUSION HERE - DH somehow?]. 



### BLUF ###



These, then, are the three scholarly conversations to which this dissertation contributes: the digital humanities, as an increasingly self-reflective set of practices; eighteenth century studies, and the challenges presented by the 1790s; and the theoretical frameworks within queer theory which seem to offer valuable resources for both. The remainder of this chapter will describe in more detail the relevant scholarship in all three fields, then discuss the overlaps between them which enable my work. Finally, this chapter will conclude with a description of the two experiments which drive the dissertation as a whole, situating them within the three fields, and providing a sketch of their development across the dissertation.



## DH ##



### many histories of DH ###



When telling a history of “DH,” one has many histories to choose from, all freighted with different implications for contemporary practice. [TRADITIONAL HISTORY OF DH]. [FEMINIST HISTORY OF DH.] As these competing historiographies show, much more is at stake than mere description, when certain methodologies are named as “digital humanities.” [CONCLUSION TO THIS PARAGRAPH.]



Ted Underwood’s “Genealogy of Distant Reading” presents a history of “distant reading” which is not for the most part centrally concerned with computers, and therefore fundamentally distinct from concepts of “digital humanities” \cite{Underwood:2017uc}.



### code is not neutral ###



The central contention of my computational praxis is that, despite the aura of empirical truth which accrues to some ‘scientific’ methodologies and discourses, nothing is neutral/objective. As Johanna Drucker argues, “data” is not neutral/objective. As Sophia Noble and Wendy Chun demonstrate, algorithms are not neutral/objective. As Alberto Cairo shows, graphs and charts are not neutral/objective. [PUT THESE IN ORDER ACCORDING TO FOLLOWING PARAGRAPHS] Each of these is constructed, by humans, for human purposes, constrained by human biases. As the humanities have long known, of course, things need not be neutral/objective to be meaningful or valuable. By setting aside the desire for a singular neutral/objective truth, we can instead draw quite close to the messy multitudes of truths which enable insight. Accordingly, [CONCLUSION].



### my methods ###



This dissertation will, nonetheless, make use of algorithms, “data”, and data visualizations to carry out its inquiry. At every possible point, however, the underlying methodology will be made visible, and its assumptions scrutinized. Much of the code underlying this project I have written myself. Some has been written at my request. In every case where the code is available to me, the program itself appears in Appendix A (“Codebase”), accompanied by a plain-language explanation of how it operates. Where I have used closed-source software, Appendix A contains an explanation of my best guess at its underlying process. My exact use of these tools — sufficient for another to replicate my work — is provided in Appendix B (“Methodology”). These details are explicated in full in the appendices in order not to over-burden the body of the dissertation, but they are by no means confined to the appendices. Computation is not a “black box” to be consulted for simple answers, but an inextricable from my reasoning and argument.



### capta ###



My attention to the sources of digital knowledge creation comes from Johanna Drucker, and her distinction between “data” and “capta.” Drucker, in “Humanities Approaches to Graphical Display,” specifically addresses the digital humanities practice of creating, and then close-reading, data visualizations. She argues that the tools for visual representation which may be effective in the sciences cannot be simply and uncritically transposed to humanistic subject matter. When an experiment is presented as a ‘data visualization,’ she says, “the rendering of statistical information into graphical form gives it a simplicity and legibility that hides every aspect of the original interpretative framework” \cite{Drucker:2011hu p.8}. In fields where the readers of such charts are also frequent creators of charts, and where norms exist to explicitly describe one’s interpretive frameworks in a methodology section, the simplicity and legibility of an individual chart may be a benefit which does not impede complex scrutiny of the information it presents.[^cf1] In a field like literature, however, the “graphical force” of something like a network graph or even a simple pie chart “conceals what the statistician knows very well — that no ‘data’ preexist their parameterization” \cite{Drucker:2011hu p.8}. Drucker problematizes the term “data,” the etymology of which presents it as a “given” which is stable and independent of observation. She proposes that humanities visualizations embrace, instead, the framework of “capta,” that which is “‘taken’ actively” \cite{Drucker:2011hu p.3}, “fundamentally codependent, constituted relationally, between observer and observed phenomena” \cite{Drucker:2011hu p.50}. Drucker’s assessment shapes my own prioritization of qualitative and reflective computational research. The term “capta” itself has not seen uptake in subsequent digital humanities scholarship, even in cases where scholars explicitly take Drucker’s warnings to heart. Accordingly, for clarity, this dissertation will continue to use the more usual term “data” to refer to the information gathered for analysis here. However, as I integrate and compare a wide variety of data from many disparate sources, a preliminary task of my analysis is always to determine, as precisely as possible, how the information was captured and quantified. 



### data viz ###



Additionally, all of the figures presented in this dissertation are of my own design. My design praxis is informed by the work of Edward Tufte and Alberto Cairo, both of whom provide practical design advice in service of demystifying the visual rhetoric by which graphs present their arguments.[^cf2] Neither Tufte nor Cairo is a scholar of media studies; rather, they are professional practitioners of ‘data visualization’ who reflect critically on the assumptions of their work. Tufte’s work primarily strives to correct badly-designed data visualizations, and the dangerous decisions that bad design can lead people to. His most famous example is an analysis of the scientists’ report at NASA which led to the ill-fated launch of the Challenger space shuttle in 1986: as his extensive visual analysis argues, the scientists (untrained in graphic design) unintentionally obfuscated crucial information about the day’s launch conditions \cite{Tufte:2001vw}. Tufte’s six principles of design[^cf3] primarily seek to guide undertrained designers away from misleading themselves. Cairo, following on Tufte’s work from the perspective of an active journalist, more often turns his attention to successful designs which mislead their audiences intentionally. His forthcoming book, How Charts Lie, addresses the readers of infographics with insights into visual literacy \cite{Cairo:2019uf}. His preceding book, The Truthful Art, addresses the creators of good-faith infographics with insights into visual manipulation \cite{Cairo:2016uv}. Cairo draws a distinction between “data visualization” and “infographics”: “an infographic tells the stories that its designer wants to explain, but a data visualization lets people build their own insights based on the evidence provided,” summarized more succinctly as “infographics to explain, data visualizations to explore” \cite{Cairo:2014tl}. Using this terminology, my argument will proceed with infographics in the body of the dissertation as curated figures to support my argument, with fuller data visualizations available in Appendix C (“Data”) to allow further exploration. Following in both Tufte and Cairo’s footsteps, I conceive of the figures throughout this dissertation as rhetorical devices. In service of arguing honestly, therefore, my designs — in the body of the dissertation and in Appendix C — are accompanied by footnoted explanations of my design rationale. 



### fruitful models/samples ###



In light of the challenges of “empiricism,” my goal in this dissertation is to produce a series of fruitful models. [Willard McCarty’s descriptive work on the concept of modelling VERBS modelling’s processes of abstraction. ][QUOTES FROM McCARTY] Another way of expressing this might be to borrow from the vocabulary of social science research: I would like to make discoveries about a “population” which is inaccessible to me, namely, “everything printed in England 1789-99.” Since I cannot access this population in full, I have taken a series of “samples,” which I hope to be representative; each sample can be examined as evidence of the makeup of the source population, but must also be examined in and of itself as a sample. [therefore, not attempting ‘accuracy’] [Rather than making claims about the 1790s each claim is filtered through / constrained by the specific model of the 1790s used to make it] Rather than producing a clear and pristine truth, my models are, in fact, quite likely to contradict each other. In these moments of contradiction, [we have the best opportunity to learn, because we can see why they contradict, and therefore why something may or may not be true.] [These opportunity are “fruitful”] [Expand on “fruitfulness”]



## 1790s ##



### 1790s ###



All of these [capta, samples, algorithms, models, and self-reflective methodologies — match preceding section] do have an aim beyond themselves: to recapture, in as minute detail as possible, the print landscape in England between January 1 1789 and December 31 1799. This eleven-year “decade” was a turbulent one across the Channel, encompassing the whole of the French Revolution, from the Estates General in 1789 to Napoleon’s coup in 1799.[^cf4] In England, [HISTORY OF THE KEY EVENTS OF THIS DECADE IN ENGLAND]. [CONCLUSION: an environment which felt like it was on the edge of history]

The [world of letters? Public sphere? What do I call it?] in England responded to these events by [writing WAY TOO MUCH]. This is the decade of Common Sense, it is the decade of Lyrical Ballads; it is the decade of Hannah More, it is the decade of Ann Radcliffe; it was the age of wisdom, it was the age of foolishness; it was the epoch of belief, it was the epoch of incredulity. Charles Dickens’ now-famous superlative degree of comparison captures the tension between empiricist or otherwise political thinkers and Romantic or Gothic artists as contemporary literary scholars grapple with these modes. Each literary ‘mode’ was imbued with the potential for national importance. [WRITE ABOUT IMPORTANCE OF READING/WRITING TO NATIONAL IDENTITY —> CONCLUSION.]



### canons ###



Not coincidentally, the 1790s are also a decade in which some literary “canons” begin to take form. John Guillory contends that the “canon debate” taking place during his moment of writing in 1993 “signifies nothing less than a crisis in the form of cultural capital we call ‘literature’” \cite{Guillory:1993ve p.viii}; the roots of this crisis lie two hundred years earlier, in the eighteenth century formation of a vernacular (rather than classical) literary canon, and in the 1790s “first crisis” (\cite{Guillory:1993ve p.xi} of that canon. Guillory turns particularly to Wordsworth and Coleridge, and the strategies by which they confer a high status on their own work by undermining the cultural capital of other forms. Wordsworth, Coleridge, and the other ‘big six’ Romantics are surely the winners of the eighteenth century historical battle for cultural capital; just as surely, the loser has been the Gothic. E.J. Clery’s The Rise of Supernatural Fiction, 1762-1800 provides an account of what was at stake for the representations of supernatural events in supernatural stories in fiction, drama, and popular news \cite{Clery:HFvEup7z}. The “rise” she describes is not an increase in volume and prominence of supernatural stories, since her starting point in 1762 (the Cock Lane ghost) is a major national phenomenon with many imitators. Rather, supernatural fiction ‘rises’ when it acquires cultural legitimacy. Michael Gamer has more recently expanded on how this ‘rise’ fuelled romanticism’s own rise \cite{Gamer:jX8nTxB-}. In Romanticism and the Gothic: Genre, Reception, and Canon Formation, he details  the interconnectednesss of what are now seen as the separate categories of ‘high’ Romantic literature and ‘low,’ popular Gothic writing. By using Gothic materials in self-avowedly non-Gothic ways, Gamer argues, Romantic writers could appeal to popular taste without risking the loss of cultural capital which attended the Gothic’s “popularity”. Gamer, like Guillory, primarily uses Wordsworth and the ‘winners’ of the struggle for cultural capital: I, like Clery, am more interested in the ‘losers.’ Accordingly, I attend to much that is not literature, in order to better understand why it is not.



#### rise of the novel? ####



### monographs ###



### touchstone authors ###



Ann Radcliffe, Charlotte Turner Smith, Hannah More, and Mary Robinson



#### Ann Radcliffe ####



#### Charlotte Turner Smith ####



#### Hannah More ####



#### Mary Robinson ####



### conclusion ###



My synthesizing approach [SAYS SOMETHING THAT WRITING PREVIOUS PARAS WILL CLARIFY]



## theory ##



### reparative reading ###



My primary theoretical framework is that of reparative reading. My touchstones are two descriptions from Sedgwick’s original chapter, “Paranoid Reading and Reparative Reading”:  

The desire of a reparative impulse... is additive and accretive. Its fear, a realistic one, is that the culture surrounding it is inadequate or inimical to its nurture; it wants to assemble and confer plenitude to an object that will then have resources to offer to an inchoate self. \cite{Sedgwick:2015up p.149}

What we can best learn from such practices are, perhaps, the many ways selves and communities succeed in extracting sustenance from the objects of a culture - even of a culture whose avowed desire has often been not to sustain them. \cite{Sedgwick:2015up pp.150-151}

These two comments are somewhat lacking as “definitions.” 

I understand reparative reading to mean [DEFINITION OF REPARATIVE READING]. Others have worked to carry out scholarship in this mode, including [OTHER REPARATIVE READERS]. [Felski’s neophenomenology in Everyday Aesthetics]   [SUMMARIZE THE MAIN THREADS / CATEGORIES OF THEIR WORK.] [WHY I VALUE REPARATIVE READING (INDEPENDENT OF DH & 1790s)].



### queer theory ###



Implicit in my prioritization of reparative reading is an affinity for queer theory more broadly. I take it as read, for example, that history consists of major discontinuities in cultural ontology and identity, as Foucault describes. I follow Judith Butler in understanding these historically-framed identities as being “performative,” actively re-created in conversation between self and others. (In my understanding of performative identity creation I also borrow from J.L. Austin, who is not typically understood as a ‘queer theorist,’ but who contributes valuable vocabulary for how words do things.) [This queer-theory foundation shapes my approach to literature as an encounter with an ‘other’, which, as Rita Felski says, [FELSKI HAS SOMETHING ON THIS]] [CONCLUSION.]



### surface reading ###



My search for other ways of relating to literature has also led me to emerging work under the umbrella of “surface reading”. “Surface reading” positions itself as an alternative to “symptomatic reading”; [RATHER THAN X, IT Y.] The analogues to reparative and paranoid reading are obvious, but also, I argue, overly simplistic: all paranoid reading is symptomatic, but not all symptomatic reading is paranoid. Reparative reading, as described by Sedgwick and potentially modelled by Felski, is still interested in ‘deep’ meanings of texts, in which striking textual features can be interpreted to locate additional meanings. [A LOT OF QUEER THEORY IS ALSO SYMPTOMATIC, EVEN WHEN IT’S NOT PARANOID (AND TBH IT’S OFTEN PARANOID).] In contrast, “surface reading” [DOES SOMETHING ELSE.] [GIVE EXAMPLES OF SURFACE READINGS.] [GROUP/CATEGORIZE SURFACE READINGS.] [CONCLUSION]



### conclusion ###



Surface reading and reparative meaning are not synonymous modes: Felski, at the forefront of reparative reading, explicitly distances herself from surface reading “I have no quarrel with interpretation, even though I favor description; nor am I drawn to a language of textual surfaces over depths” (CITE).



Talk to Dana Seitler about the distinctions between surface reading and reparative reading

History of queer theory: Oscillations of Literary Theory, AC Fecundo



Reparative reading rejects paranoia & the role of the critic as master

	Felski rejects negativity? & role of critic?

Queer reading rejects ?

Surface reading interpretation (?) — focus on taking the text at its word & examining all details equally



## synthesis of 3 fields ##



### we need Venn ###



Drawing together three scholarly conversations with three distinct histories, it is difficult to attentively delineate the links and the tensions between each thread. Especially since many of these fields have, in fact, overlapped substantially, there is a danger of simplistically conflating distinct lines of thoughts. At the same time, over-emphasis on distinctions can overstate the separations between fields which do in fact (as the existence of this dissertation contents) share important affinities. To navigate these conceptual overlaps carefully, let us make our way through each area of an imagined Venn diagram of the three. We can discuss each pair in turn — DH and eighteenth century studies; eighteenth century studies and queer theory; queer theory and DH — to make our way toward the centre where all three overlap.



### DH & 1790s ###



#### DH & bibliography ####



In the intersection of the digital humanities and eighteenth century studies, I turn to bibliography. If there is any research as magnificent in its ambition than The Dictionary of Old English, it is work like Garside & Raven’s The English Novel. This kind of work seeks to be both comprehensive and accurate. [DESCRIBE THE SIMILARITIES I SEE. — Resources for future research] [Now I’m going to survey the kinds of digital corpora and non-digital bibliographic resources that I focus on.]



#### scholarly archives ####



Eighteenth century materials of various kinds have been collected in many digital archives, of very different scope. These are discussed in more detail in Chapter 2. On the tip of anyone’s tongue, of course, is Gale’s Eighteenth Century Collections Online (ECCO), containing over 180,000 titles 1701-1800, of which 42,000 were printed in England between 1789 and 1799. ECCO is itself (mostly) a subset of the broader English Short Title Catalogue (ESTC), which contains more 460,000 texts 1473-1800, of which 51,965 were printed in England between 1789 and 1799 (indicating that nearly 10,000 in the decade titles appear in the ESTC but not ECCO). The ESTC does not provide access to texts themselves: instead, it is an authoritative bibliographic catalogue, available as a searchable database. It is ECCO which provides texts themselves: ECCO’s 180,000 titles works are available as photographed facsimiles of the full text of each title. The facsimiles can be searched within ECCO’s online interface; these searches examine a plaintext version of the facsimile pages that was generated by Optical Character Recognition (OCR), but this OCR text is not made directly available. As a result, the facsimiles may be read individually by scholars, but cannot form the basis for computational corpus analysis. A subset of ECCO’s texts have been hand-prepared, as part of the Text Creation Partnership (TCP), to be easier to use in computational research. The resulting corpus of ECCO-TCP texts contains 2,231 titles, of which 466 were printed in England between 1789 and 1799. These titles are available as carefully-edited texts encoded according to the Text Encoding Initiative (TEI) standard, which not only provides an accurate version of the text’s words, but encodes substantial details regarding its context on the page. Most large-scale distant reading of eighteenth century literature relies in the ECCO-TCP corpus as its ‘model’ or ‘sample’ to represent the period. Accordingly, one of the tasks of this dissertation is to precisely examine the makeup of thus corpus, and how it differs both from other corpora and from print culture in the period itself. These three digital collections — ECCO, ESTC, and ECCO-TCP — are the primary digital resources for the period, which form the basis of most digital research. However, they represent only one approach toward the collection and presentation of digital texts, to which there are two broad kinds of alternatives. These large but meticulous collections occupy a middle space between, on the one hand, highly selective thematic collections, of which there are many, and the giants of indiscriminate textual accumulation, of which there are few.



#### micro archives ####



Smaller collections allow for more scholarly curation, but have corresponding limitations. Whereas the ‘main players’ can be easily enumerated for the mega-archives, these specialized collections are numerous. Some will focus on particular kinds of texts, such as the Early Novels Database (2,041 novels 1700-1799) or Broadside Ballads Online (more than 30,000 broadside ballads). Others exhaustively index particular publications, such as The Hampshire Chronicle, the Index to the Lady’s Magazine (1770 to 1818), or the Novels Reviewed Database (1,836 reviews from The Critical Review and The Monthly Review, 1790-1820). Feminist scholarship in particular has seen the creation of resources like the Orlando Project, the Chawton House library Novels Online, Northeastern University’s Women Writers Online and UC Davis’s British Women Romantic Poets. The virtue of these collections is that they achieve even greater accuracy and comprehensiveness within their defined scope. The Shelley-Godwin Archive, for example, can reasonably aspire to digitize every known manuscript of Percy Bysshe Shelley, Mary Wollstonecraft Shelley, William Godwin, and Mary Wollstonecraft, and to provide these manuscripts in hand-encoded plaintext transcripts. However, as is inevitable, these specialized archives have the vices of their virtues: their specialized focus allows them to adapt precisely to their materials, and their idiosyncratic data structures can rarely be combined with other resources. The William Blake Archive, for example, benefits enormously from designing its archive around the unique images of each page of each copy of each of Blake’s works. But because this approach is so well-suited to Blake, it cannot be applied beyond Blake. Even if the archive’s resources were available for download, they could not be directly compared to materials from another source which does not record its information at such a minute level of detail. 

Also in the category of ‘smaller and specialized’ archives is Project Gutenberg. Project Gutenberg makes no claims to scholarly reliability but nonetheless underlies a not-significant amount of scholarly work[^cf5] — its cultural capital as a resource lags far behind its use and utility. Project Gutenberg is easily conceived of as a haphazard, ‘unscholarly’ source for materials, but unlike Google Books, Project Gutenberg actually does have selection criteria. Project Gutenberg is only interested in public domain works which contemporary audiences might be interested in reading for pleasure. It narrows the field substantially to exclude works which have either ceased to be broadly interesting (as in the case of most forgotten fiction), or which was never particularly interesting (as in the case of almanacs and tax codes). Project Gutenberg includes 57,796 texts: far more than specialized scholarly archives like the Early Novels Database or the Shelley-Godwin Archive, but nonetheless an order of magnitude fewer than its more-voracious potential competitors. And, like smaller specialized scholarly archives, Project Gutenberg has tailored its holdings to make it easy for readers to read, and quite difficult for its collection to be applied to any other use. By tailoring the structure of the archive itself to its specific materials, these collections are able to thoughtfully achieve their aims — but they also make it correspondingly difficult for users to achieve their own, different aims.



#### mega archives ####



The best known mega-archive is, of course, Google Books. In a scholarly context, one hesitates even to designate this as an “archive,” particularly in the same breath as resources like ECCO: books of all kinds are scanned indiscriminately with only the bare minimum of roughly-accurate metadata collected about them. Books are sourced from libraries whose collections are being scanned in bulk, or are submitted directly by publishers or authors who are attracted by Google’s call to “Promote your books on Google—for free” (CITE[^cf6]).   These rapidly-scanned books are prone to unpredictable errors, including inaccurate dates, misspellings, duplicate copies, and inaccurate subject classifications (Harper 2016; Jacsó 2008; Weiss 2016) (CITE Mike Sutton and Mark D. Griffiths) — infamously, many books have “1899” assigned as their publication date because this date was used as a placeholder for “no date”.[^cf7] Many photographed pages still include the fingers of the employee holding open the book. Nonetheless, Google Books is frequently used to study the prevalence of various “n-grams” (words or short phrases) over time, thanks to Google’s built-in tool. The tool is able to search books which are, for copyright restrictions, not available directly to readers, making it highly tempting for question about contemporary language use. Similar in scope to Google Books but with more limited research tools is The Internet Archive. The Internet Archive, unlike Google Books, is a non-profit, but like Google Books, it carries out mass scanning of books. The Internet Archive declares that it contains 20 million books and texts, and scans 1,000 books per day in 28 locations around the world (CITE).[^cf8] Equivalent numbers are not published for Google Books, which has received less attention from Google as it encountered more legal barriers; in 2013 books were scanned at the rate of 1,000 pages per hour, and in 2015 more than 25 million books had been scanned. Google Books, Project Gutenberg, and the Internet Archive are not “canonical” sources of texts, but they are nonetheless part of the ecosystem of digital eighteenth century studies.





#### HathiTrust ####



Moreover, as in eighteenth century texts themselves, the boundary between “canonical” and “noncanonical” digital archives is a permeable one: Google Books and the Internet Archive are also integrated into HathiTrust, an increasingly popular resource for scholars. [EXPLANATION OF HATHITRUST]. The scholarly benefit of HathiTrust is most evident in the study of contemporary literature. On a technical level, whereas OCR typically produces gibberish when faced with eighteenth century typefaces captured in photographs of microfiche, OCR is extremely effective at reading contemporary typefaces and direct high-resolution digital scans of books. The materials 



#### print archives ####



[But of course not everything is digital]. [It is a core contention of my work that DH can’t ignore non-digital resources]. [LIST AND CATEGORIZE MAJOR PRINT BIBLIOGRAPHIC RESOURCES].

Garside

William St Clair



#### conclusion: ####



As I scrutinize the underlying assumptions that are structurally reinforced by this work, I do so not in order to dismiss their value. These resources are created to enable future scholarship: for that future scholarship to thrive, 

Literary study already involves modelling / sampling

Thus, I see DH and bibliography as able to enhance each other reciprocally. 



### 1790s & queer ###



#### queer gothics ####



Queer readings of the 1790s — which is to say, of the Gothic — provide an invigorating way to value some of the most vibrant writing of the decade precisely for the features which rendered it less than “respectable.” [HISTORY OF QUEER GOTHIC STUDIES - Palmer I think, leading up to Franz Potter… this history is prob multiple paras] [A lot of really good Gothic work is connected thematically rather than strictly chronologically, examining the “transtemporal affinities and connections” (CITE) that Felski argues are often shut out by contemporary historicist critique. And indeed, this mode of study is falling out of favour regarding the Female Gothic.]



#### reparative gothic ####



[A lot of queer Gothic work has been paranoid] [Something about Susan Sontag & camp being how I reparatively read the Gothic?]



#### I'm not just gothic ####



Although the queerest work in this period has centred on the Gothic, I intentionally do not limit my focus to the Gothic. My broader scope is, in part, based in an argument about the Gothic’s prevalence: following scholars like [EXAMPLE], I see the Gothic not as a clearly-defined literary genre, but rather as an affective ‘mode’ that can (and did) permeate writing far beyond the realm of supernatural fiction. Accordingly, [although I am interested in the Gothic, I study everything.] [Also I’m not just interested in the gothic.]



### queer & DH ###



#### critical algorithm studies ####



My emphasis on transparent, critical, and reflective praxis in the capture and visual presentation of data[^cf9] owes much to the emerging field of critical algorithm studies. Any methodology is, to a certain extent, an “algorithm,” in the loose definition of ‘a series of pre-defined steps to be carried out’. But computational algorithms differ from “algorithms” implemented by humans. Computational algorithms have two key vulnerabilities: first, their operations are less easily scrutinized; second, their results are more easily trusted. The second vulnerability — the cultural aura of empirical trustworthiness which accrues to anything ‘computational’ — is another flavour of the same vulnerability that Drucker describes with ‘data’ generally. Because the human agents who designed and trained any given algorithm appear to be absent from its operation, the algorithm appears able to discover truth directly. This is how Daily Wire reporter Ryan Saavedra was able to tweet with disdain that “Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist” \cite{Saavedra:2019wr}: anything “driven by math,” he assumes, must be incapable of human fallibilities like racism. But as Safiya Noble shows extensively in Algorithms of Oppression, algorithms by default reproduce, and can easily exaggerate, the assumptions and biases of the culture in which they are made \cite{Noble:2018wo}. In other words, in a racist world, algorithms are racist — and sexist, and duplicative of all other systemic institutional inequities.

Wendy Chun suggests that the problem with much algorithmic inquiry lies in its most core assumption: the insistence that the future must look like the past \cite{Chun:2018tq}. This assumption is essential to any system which exclusively bases its predictions on past data. It is particularly intertwined with what Chun calls “homophily,” “the axiom that similarity breeds connection—which grounds contemporary network science” \cite{Chun:2018tq p.60}. Homophily, as it is currently applied to network science, Chun argues, both “assumes and creates segregation” \cite{Chun:2018tq p.76} in a fashion that allows it to operate “like money laundering for bias” \cite{Chun:2018tq pp.62-63}. Importantly, however, the analogy to money laundering is imperfect: it cannot be resolved with “better, cleaner data” \cite{Chun:2018tq p.64}. Instead, Chun insists, “new theories of connection—which do not presume a dangerously banal and reciprocal notion of friendship—are needed” \cite{Chun:2018tq p.89}, a call to action which places its emphasis not on the information provided to an algorithm but on the algorithm’s procedures.



##### procedural argument #####



An additional and perhaps-unexpected resource, for scrutinizing algorithms critically, comes from the work of those who study games, especially video games. [Ian Bogost argues that procedures contain arguments.] This framework allows us to see that all research methodologies, including non-digital ones, contain implicit arguments about the nature of what is studied. [EXAMPLE PROCEDURE FROM MY MATERIALS - something non-computational?] 



#### queer DH ####



[“Queer DH” is now a vibrant field in its own right.] [WRITE UP HISTORY / BROAD CATEGORIES OF QUEER DH RESEARCH] I draw on this work in my pursuit of less “extractive” and more anti-oppressive digital humanities methodologies.



##### queerying homophily #####



#### reparative DH ####



As I encounter the limitations of the various information and tools with through which I attempt to understand the 1790s, my goal is to do something other than facilely observe that they are limited. Critique, in many venues, still has valuable new information to contribute regarding the contemporary digital landscape. Drucker, Noble, and Chun’s warnings about the subjective nature of data and algorithms, for example, all [HAVE REAL AUDIENCES]. In part because their critiques have been presented so effectively, however, I do not give critique a central role here. Most of the digital artefacts that I examine have been created, not by ever-hungering capitalist corporations, but by my fellow scholars. In the spirit of laying down the next few stones in the building of a cathedral begun long before me, [I WANT TO BUILD]. In a digital humanities context, a focus on building connections can be mundanely practical: typing indexes from print works into spreadsheets, [DATA CLEANING], writing programs to process metadata: all of these maintain the functional usability of existing resources in new contexts. [But not just maintaining them, repairing them.] 



[TALK ABOUT WHAT REPARATIVE DH METHODS LOOK LIKE, SOMEHOW] [Examples - TL Cowan, ]



By marrying “surface reading” and “distant reading” I may seem to leave “reparative reading” behind: after all, Felski’s call for postcritical analysis explicitly insists, “Sometimes serious thinking calls for a judicious decrease rather than and increase of distance” (CITE). Felski then defines a decrease of distance as “a willingness to acknowledge and more fully engage our attachments”: it is in this readiness to acknowledge and embrace the [DETAILS OF SOMETHING-SOMETHING]



#### surprise! ####



Thus far, the importance of queer theory to DH is evident. But what about the other direction? Just as, I argue, both DH and bibliography have important resources to offer to each other, so to do I argue that DH has something to offer queer theory. Specifically, a well-formulated DH praxis can introduce a new relationship to the experience of surprise which is so challenging in paranoid reading. The most common dismissals of DH research are attempts to say, “we already knew that” — essentially, [PARANOID AVOIDANCE OF UNPLEASANT SURPRISE FROM DH THREAT]. This reaction invites two responses. First, [if the experiment told us that everything we knew was COMPLETELY WRONG, this would not be very good because probably at least some of what we know is right]. [Experiments fall into two categories: those which tell us about our methods, and those which tell us about our fields of study]. Second, as scholars such as Ted Underwood have noted, it is often only retroactively that these discoveries are declared to be “obvious” results which everyone “already knew” (CITE). If we are asked to form an explicit hypothesis in advance, we might be very surprised by the exact numbers. [CONCLUSION]



### all together now! ###



#### CANONS ####



“overall, about how texts do or don't 'enter' a 'canon' of writings - by which you mean, as per e.g. Guillory or Bourdieu, and the idea of cultural capital, a set of texts studied, produced, valued (to varying degrees over time) within certain cultural fields, most especially the field of academic research (but also education, modern publishing, creative industries etc). And then your contribution to the many discussions that go on about (and indeed change) canon, is to bring show we can use digital tools to ask and answer that question? I think maybe it is, and if that is the case, then you need to say just that, and that the other issues - timelessness, popularity, marginalization, immediacy, fall out of that larger question”

(This can be a shorter section; write it after the rest?)



## upcoming 2 experiments ##



### overall goal ###



Having delineated a large and complex scholarly context for this work, and made some preliminary efforts toward synthesis of these disparate backgrounds, it is time, now, to delineate the research born of this context. This dissertation proceeds in two major parts. The first examines the 1790s through the lens of ‘titles,’ and the second through ‘persons.’ In both cases my central interest is the vexed category of ‘popularity.’ With both ‘titles’ and ‘persons’, I establish the materials with which I will be working and their implicit models. Using the information they make most readily accessible, I explore which works and individuals emerge as ‘popular’ or ‘important’ in each resource. I also probe each resource for its representation of (or failure to represent) my touchstone authors, Ann Radcliffe, Charlotte Turner Smith, Hannah More, and Mary Robinson. The resulting findings are primarily used to evaluate how the underlying digital resources participate in or resist the projects of canon-building. Then, for both titles and persons, there is a ‘turn.’ For each area of inquiry I introduce a novel experiment which synthesizes my materials and repurposes them. These experiments are then used to draw conclusions about 1790s print culture.



### titles ###



The first phase of this project takes up titles and databases. Throughout this work, a ‘title’ is the broadest possible umbrella term for a text: it is synonymous with ‘a database entry which I believe to represent a printed work.’ Each individual database will shape the precise correspondences between a ‘title’ and the printed texts about which I use ‘titles’ to reason. For example, it will vary based on my source whether multiple editions of the same work are several ‘titles’ or one ‘title,’ and whether the titles exclusively represent ‘books’ or also include chapbooks, broadsheets, or even ephemera. Due to the inscrutability of digital infrastructure discussed above, it is often not possible for me to know prior to experimentation what kinds of titles I am working with. Chapter two, therefore, two takes up contemporary digital archives directly, examining corpora of eighteenth-century literature through the same critical lens by which anthologies and classroom teaching are often scrutinized.





#### ch 2 ####



In chapter two, I make the case that digital archives can implicitly shape scholarly research, and begin the process of revealing and interrogating their invisible assumptions. The chapter begins with a task somewhere between a literature review and a scientific meta-analysis. My first goal will be to survey as broadly as possible the accessible mass holdings of eighteenth-century texts (all those containing at least 100 works from the 1790s). I expect to find systematic exclusions where archives are investing more labour in their holdings, with narrower selections as they move from bibliographic data to facsimiles to scholarly transcripts. To contextualize these decisions about inclusion, I research the history of how each corpus was formed. As part of this demystification process, I also discuss and theorize the difficulties involved in researching these histories: drawing on, for example, my experience with HathiTrust’s codebase, I critique the assumption that digital resources make all information transparent and accessible. Returning to the actual contents of each archive, I discuss the nature of their exclusions, and consider paths to greater inclusivity.  The second chapter thus establishes the corpora which will drive my argument in chapter three, and will shape the later phases of my research in chapters four and five.



#### ch 3 ####



In chapter three, I synthesize these disparate sources of texts and metadata, to examine popularity as it manifests in print culture. I begin by creating my own ‘superset’ database of all records. I then query this database through random sampling and topic modelling. Both random sampling and topic modelling, as methodologies, allow me to examine information outside of its pre-designed data structures. Random sampling, which Steven Zwicker \cite{Zwicker:2006ck} and Leo Lahti, Niko Ilomäki, and Mikko Tolonen \cite{Lahti:2015dd} have applied successfully to the English Short Title Catalogue’s holdings, makes it feasible to apply a greater level of human scrutiny to a large body of texts. Topic modelling makes it feasible regularize otherwise-disparate materials without imposing a pre-defined ontology. My use of topic modelling differs somewhat from its typical use in literary distant reading, which generally applies topic models to the full text of literary works, and examines topics themselves as proxies for subtle elements of textual content. I model only the titles of works, taking advantage of the eighteenth century’s distinctively rich title conventions.[^cf10] Both of these methods allow me to use my ‘superset’ database to ask questions about 1790s literature itself. Influenced by Lesser and Farmer’s articulation of “structures of popularity,” I consider popularity in terms of total number of editions, frequency of reprinting, and market share. After presenting my proposals for how to calculate each of these metrics, I ask: what was most popular during the decade, according to my corpora? How do the corpora differ in their answers, and why? Many of the most reprinted works substantially pre-date the 1790s in their composition. Accordingly, taking up David Brewer’s challenge to account for the increased “footprint” of some texts beyond the moment of their original publication, I also pay attention to works originally written before the 1790s which nonetheless can be considered important “1790s literature” due to prominent reprinting. This inquiry’s first question is one of discovery: what works resurface in the 1790s? Its next question is one of close-reading and historical context: what makes them seem newly relevant? The chapter as a whole, then, presents a sustained study of the relative popularity of the most prominent works printed during the 1790s, and seeks to answer how these prominent works might affect what we define as “popular literature.”



### persons ###



The second phase of the project takes up persons and networks.



#### ch 4 ####



Chapter four introduces a mapping of the social world of print production 1789-99. As in chapter two, it is be a substantial technical and research project simply to recover contemporary printing practices; this time, rather than asking what was printed, I will ask who it was printed by. A great deal of scholarly work already exists on printing circles, coterie publishing, and individual publishing houses. My project will consult this scholarship to extract and encode connections between authors, printers, and publishers (but not patrons, readers, or other persons not immediately involved in the production of texts) in order to synthesize the implicit social networks underlying 1790s print production. I will begin my research for this chapter by encoding only a few existing studies, in order to evaluate the feasibility of my method at scale. It is possible that, rather than directly consulting the more richly historically-informed work of other scholars, I will instead fall back on inferring networks from the author and publisher metadata included with the corpora examined in chapters two and three. The resulting chapter will explain my methodology and its assumptions, and will provide a rich description of my resulting network graph. The graph I create may show one large interconnected network, or several separate networks of varying sizes; these networks may show highly distinct clusters, or evenly interconnected webs. Drawing on mathematical graph theory, the chapter will explain the implications of whichever shape the network ultimately displays. It will also present an overview of the people I identify as the “major players” in the publishing world of the 1790s, both mathematically (looking for nodes with various kinds of centrality) and in the scholarship.



#### ch 5 ####



Having recaptured these complex networks in some depth, I can then examine them, in chapter five, for their relation to our current understanding of mainstream and radical--or as I am terming them “mainstream” and “non-mainstream”--printing circles. My network graphs will model individual political affiliation as a complex, socially defined practice rather than a set of concrete and unchanging ideological stances. This chapter will look for traces of affiliation in the print practices of publishers and authors. I will consider individual printers with political allegiances, as in Dissenting societies, radical publishers, correspondence societies. This will then enable me to consider authors’ strategic choices as they publish with different printers. Having identified radical elements in the publishing world, I will interrogate the radicals’ claims to marginalization. I suspect that I might find that they were not as socially estranged from the mainstream as they describe themselves, and that their printed works may accordingly have been less marginal. I will discuss alternative print markets and alternative circulation, in context with the print production which they are alternatives to. The circulation of works in manuscript presents me with two challenges which will be discussed here. The first challenge is methodological: the circulation of manuscripts clearly occurred, and may have constituted “publication” within social circles, but manuscripts fall outside my purview. This chapter will therefore discuss the nature and rough shape of the gap which the exclusion of manuscript works leaves in my study. The second task of this chapter is more theoretical: as queer and decolonial DH scholars note, there is an ethical choice implicated in the decision to systematically discover, collect, and expose communities which intentionally operated below the notice of state observation. Historical distance prevents me from worrying about causing direct harm through my work, but nonetheless I will critically interrogate my own research practices and contextualize my choices with the horizon of expectations within the radical circles I expose. Finally, having discussed the networks of radical and mainstream publishing in the 1790s, I will also compare the position of radical publishers in the 1790s with their status in the corpora discussed in chapters two and three (where they may in fact be marginalized; I expect to find conservative works overrepresented in the corpora). Together, these approaches will further complicate the story of popularity which the dissertation challenges elsewhere, by suggesting ways to reassess of the popularity of radical works.



### chapter conclusion ###

[^cf1]: It may also be the case, of course, that even fields with a long history of graphical display would benefit from greater scrutiny of the evidence they use; see: the Data Dinosaur. But this is beyond the remit of what an English PhD can address.

[^cf2]: I cite Tufte and Cairo as the thinkers whose design philosophies best accord with my own current understanding of the work and craft of persuasive data visualization, but my actual practical training as a graphic designer is indebted to Judith Galas, Sonia Davis Gutiérrez, and Tom Hapgood.

[^cf3]: 1. show comparisons, contrasts, differences
	
	2. show causality, mechanism, explanation, systemic structure (intervention relies on manipulable causality -- can't do anything with the information without causality)
	
	3. show multiple variables (3 or more) -- the world is multivariate
	
	4. *completely integrate* words, numbers, maps, graphics, etc, etc. Provide information at exact point of need
	
	5. documentation must thoroughly describe evidence and its sources, provide complete measurement scales
	
	6. presentations succeed based on their content. for better presentations, get better content.

[^cf4]: Although these events, of course, did not occur on January 1 or December 31, respectively, the entirety of 1789 and 1799 are both included in my study here, out of sheer technological necessity.

[^cf5]: I have heard it quipped more than once in digital humanities gatherings that you always think you’re going to get your texts from somewhere else, but Project Gutenberg is where you’ll actually get them.

[^cf6]: https://books.google.ca/intl/en/googlebooks/partners/

[^cf7]: CITE http://languagelog.ldc.upenn.edu/nll/?p=1701

[^cf8]: https://archive.org/about/

[^cf9]: As a recurrent Freudian slip, I have more than once typo’d the word “data” as “danger”

[^cf10]: For example, a typical title in the English Short Title Catalogue for the decade is “The injustice and impolicy of the slave-trade, and of the slavery of the Africans: illustrated in a sermon preached before the Connecticut Society for the Promotion of Freedom, and for the Relief of Persons Unlawfully Holden in Bondage, at their annual meeting in New-Haven, September 15, 1791. / By Jonathan Edwards, D.D. Pastor of a church in New-Haven. ; To which is added, A short sketch of the evidence for the abolition of the slave-trade, delivered before a committee of the British House of Commons.” The usefulness of this title, as an advertisement for (if not necessarily an accurate representative of!) the work’s content, I argue, presents an opportunity unique to the eighteenth century. The eighteenth century is often dismissed as unsuitable for computational distant reading because eighteenth century printed type produces very low-quality OCR transcripts — but a focus on OCR-based distant reading itself seems to me like a response to the poverty of paratextual material in later literature.