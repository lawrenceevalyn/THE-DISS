Title: DISSERTATION  
Author: Lawrence Evalyn

**Print Politics in the Digital Archive, 1789--99**



My dissertation seeks to determine, in as minute detail as possible, what the print landscape[ TK: Books only, or also serials, periodicals, newspapers, print ephemera (for the 1790s, there are a lot of things like handbills and broadsides in ECCO)? A fairly restrictive definition might be wise ...  ] in England 1789-99 was actually like  --- in contrast to the version that is presented in filtered and interpreted literary histories, built up by scholars or later generations of writers --- and how this print landscape is represented now, in current digital archives[ TK: This will be very valuable, but of course you’re dealing here with a moving target and one subject to sudden transformations as well as gradual / incremental changes. Not sure what the solution is here but it’s something to thing about. Presumably you can’t make this chapter the last thing you do if you need the data for later chapters -- or can you?]. My first chapter establishes the vocabulary and theoretical frameworks of the dissertation. Chapter two turns a critical eye on existing digital archives that feature material printed in the 1790s. Chapter three uses these corpora of 1790s literature to examine the idea of “popularity” as it is manifested by print culture. Chapter four introduces a second substantial experiment, a comprehensive mapping of the social networks underlying print production during the decade. Chapter five uses these networks to compare mainstream and non-mainstream printing practices[ TK: NB that you tend to use printing and publishing a bit too interchangeably. Presumably this one should be publishing practices? Print technologies are also changing in this era but that’s a whole different story, not part of yours I would imagine.]. A possible afterword or coda may discuss the role of the Gothic across the textual landscape.



## 1.1.  ch 1 - intro ##



### 1.1.1.  intro ###



This dissertation in concerned with the mechanism by which texts do or don’t ‘enter’ into ‘canons’ of writings, particularly in the heightened political environment of England in the 1790s. In service of this goal, this dissertation seeks to determine, in as minute detail as possible, what the print landscape in England 1789-99 was actually like. It also seeks to explain, in equally minute detail, why this task of ‘objective’ historical recovery is, in fact, impossible. In the process, I show how our persistently perplexing questions about canons can be asked, and answered, in new ways with digital tools. Computational methods, in their close association with ‘big data’, are often advertised as the solution to the problems of scale which are presumed to motivate the formation of selective canons. As my own computational experimentation will reveal, however, computational study more commonly undertakes the same judgment and valuation of texts that characterizes ‘canon formation,’ and displaces this process onto ‘corpus building.’ It is difficult, when faced with flawed and complex competing narratives, to resist the impulse to simply critique and reject all options. If we may learn any lessons from the 1790s, however, surely one must be the danger of universal paranoia. Accordingly, this dissertation takes place within three scholarly conversations: the digital humanities, as an increasingly self-reflective set of practices; eighteenth century studies, and the challenges presented by the 1790s; and the frameworks of reparative reading within queer theory which seem to offer valuable resources for both. The remainder of this chapter will describe in more detail the relevant scholarship in all three fields, then discuss the overlaps between them which enable my work. Finally, this chapter will conclude with a description of the two computational experiments which drive the dissertation as a whole, situating them within the three fields, and providing a sketch of their development across the dissertation.



#### 1.1.1.1.  DH ####  

The field of “digital humanities,” now several scholarly generations into its development, has entered the phase in which so many scholars are carrying out “DH” research that no universally-acceptable definition of “DH” can exist. Many definitions are fundamentally methodological.[^cf1] These definitions describe what might be called a “computational humanities.” Other definitions take up the new importance of digitality in daily life.[^cf2] This kind of work is increasingly described as “digital cultural studies.” In positioning this work as a “DH” dissertation, I might at first glance seem to belong squarely within the first framework, that of the “computational humanities.” To be sure, much of this work is intended to apply existing computational methodologies to conduct otherwise old-fashioned literary research. My objects of study are by no means contemporary. Several of my contributions, too, are purely methodological in nature, in the development of new code and new guidelines for computational research using particular digital resources. However, as a fuller discussion of Johanna Drucker’s distinction between “data” and “capta” will elucidate later in this chapter, no computational research exists separately from a specific, local, culturally-defined context. Accordingly, my computational research into eighteenth century literature and my development of new computational methodologies are both inevitably tied to “digital culture.” My results often have more to say about contemporary digital archives, and the history of literary record-keeping, than they do about the eighteenth century itself. I therefore rely on an extensive body of work in cultural digital studies to examine not only the eighteenth century, but eighteenth century studies.  

Often discussed as synonymous with “DH” is a set of practices described as “distant reading.” Distant reading is undergoing a shift away from its figurehead in Franco Moretti, who famously coined the original term \\cite\{Moretti:2000ul\}. If we wish to think about distant reading without Moretti, Ted Underwood and Rachel Buurma both provide valuable histories. Ted Underwood’s “Genealogy of Distant Reading” presents a history of distant reading which is not for the most part centrally concerned with computers, and therefore fundamentally distinct from concepts of “digital humanities” \\cite\{Underwood:2017uc\}. In Underwood’s history, distant reading is “a tradition continuous with earlier forms of macroscopic literary history, distinguished only by an increasingly experimental method, organized by samples and hypotheses that get defined before conclusions are drawn” \\cite\{Underwood:2017uca p.29\}. Underwood “tease\[s\] out the elided social-scientific genealogy behind distant reading” \\cite\{Underwood:2017uca p.39\} to argue that the term “\[d\]istant reading was not coined to describe a radically new method. The first occurrence of the phrase, in \[Franco Moretti’s\] ’Conjectures on World Literature,’ seems in fact to describe the familiar scholarly activity of aggregating and summarizing previous research” \\cite\{Underwood:2017uca p.9\}.

Rachel Buurma’s history of Josephine Miles adds a specifically computational alternate geneaology for distant reading \\cite\{Buurma:2018wt\}. Miles is proposed as an alternative not to Moretti, but to Roberto Busa, who is often credited with the first large-scale computational literary study. Miles’ history, briefly, is as follows:

In the 1930s, as a graduate student at Berkeley, she completed her first distant reading project: an analysis of the adjectives favored by Romantic poets. In the 1940s, with the aid of a Guggenheim, she expanded this work into a large-scale study of the phrasal forms of the poetry of the 1640s, 1740s, and 1840s. In all of this distant reading work, Miles created her tabulations by hand, with pen and graph paper. She also directed possibly the first literary concordance to use machine methods. In the early 1950s, Miles became project director of an abandoned index-card-based Concordance to the Poetical Works of John Dryden. Partnering with the Electrical Engineering department at Berkeley, and contracting with their computer lab and its IBM tabulation machine, Miles used machine methods to complete the concordance. It was published in 1957, six years after she and several woman graduate students and woman punch-card operators began the work. It was thus begun around the time that Busa circulated early proof-of-concept drafts of his concordance to the complete works of St. Thomas Aquinas, and published 17 years before the first volumes of the 56-volume Index Thomasticus began to appear. \\cite\{Buurma:2018wt\}

Buurma brings Miles’ history to our attention not simply because Miles predates Busa, as a correction of a minor matter of fact.[^cf3] Rather, Buurma emphasizes, Miles’ origin story for computational literary study “can stand as an example of how we might write a history of literary scholarship that does not center originality and individual accomplishment” \\cite\{Buurma:2018wt\}. Unlike Busa, Miles not only gave authorship to the (female) graduate students who carried out much of the labour of creating the concordances, she also thanked and credited the (female) punch card operators who encoded the resulting data.[^cf4] Moreover, when talking of Penny Gee, one of the female staff members of the computer lab, Miles praises her as “‘very smart and good’ and---most importantly---a true collaborator, as opposed to those ‘IBM people from San Jose’ ... ‘I’ve never been able to connect with them,’ Miles explains, ‘though I did with Penny Gee. She really taught me’” \\cite\{Buurma:2018wt\}. Of the positive qualities highlighted here, only one, “smart,” is traditionally valorized among literary critics: to be “good,” a “collaborator,” who can “connect” and “teach” --- as I will discuss more fully in section 1.3 when I turn to Eve Sedgwick’s critique of paranoid reading, these qualities are often seen as incompatible with the singular authority of the figure of ‘the critic.’ Miles’ work, too, struggled to find appreciation “among literary critics who viewed her datasets as merely preparatory to the true work of evaluation” \\cite\{Buurma:2018wt[ Moretti’s mode of distant reading, Klein argues, pursues both the \[SOMETHING\] of the critic and the \[SOMETHING\] of critique, but, as Miles and many scholars like her have demonstrated, these are not inherent to distant reading.]\}.  

Lauren Klein’s paper at MLA 2018, “Distant Reading after Moretti,” in fact poses the turn away from Moretti as an urgent imperative: “what do we do about distant reading, now that we know that Franco Moretti, the man who coined the phrase ‘distant reading,’ and who remains its most famous exemplar, is among the men named as a result of the #MeToo movement” \\cite\{Klein:2018to\}? Klein, drawing on Sara Ahmed’s observation that “sexual harassment is a structural, as well as personal problem,” draws together critiques of distant reading’s exclusion of women in terms of its “issues of *representation* in the field,” its “unduly masculinized *rhetorical* positioning,” its “failure to engage with the *conceptual* issues that relate to women,” and the “actual computational *models* of gender that are often deployed” \\cite\{Klein:2018to\}. All of these critiques of distant reading, Klein argues, show that “it’s not a *coincidence* that distant reading does not deal well with gender, or with sexuality, or with race,” but also that these failings are not inevitable: “it’s not that distant reading *can’t* do this work,” she insists, “it’s that it’s yet to sufficiently do so” \\cite\{Klein:2018to\}.  

Klein’s prescription for change is not dissimilar to Katherine Bode’s somewhat earlier call for “a new object for data-rich literary history” \\cite\{Bode:2017gb\}. Klein calls for “more corpora---more accessible corpora---that perform the work of recovery or resistance” to allow research “beyond quote ‘representative’ samples, which tend to reproduce the same inequities of representation that affect our cultural record as a whole” \\cite\{Klein:2018to\}. Klein also suggests a change in how models are formed: “Instead of first asking what *can* be modeled---what phenomena we can track at scale---we might instead ask: what might be *hidden* in this corpus? And are there methods we might use to bring out significant texts, or clusters of words, that the eye cannot see?” \\cite\{Klein:2018to\}. Bode, too, despite her strong critique of distant reading as it has been practiced by Moretti and Matthew Jockers[^cf5], does not blame distant reading itself. Moretti and Jockers, she argues, “while claiming direct and objective access to ‘everything,’ ... represent and explore only a very limited proportion of the literary system, and do so in an abstract and ahistorical way” \\cite\{Bode:2017gb\}. The many criticisms which Klein compiles, Bode argues, “describe the symptoms -- not the essence -- of a problem, which in fact inheres in Moretti’s and Jockers’s common neglect of \[...\] the bibliographical and editorial approaches that explore and explicate the literary-historical record,” a neglect which is itself “not an effect of importing data into literary history but is inherited from the New Criticism” \\cite\{Bode:2017gb\}. Bode proposes, as an alternative, the creation of scholarly editions of literary systems, which would not only create new, nuanced corpora and models, but would transparently explain those corpora and models as intentionally-crafted expressions of the particular literary system they are being used to explore.  

This dissertation undertakes computational distant reading. My questions are macroanalytical, and my research proceeds from hypothesis through experiment and results. At every possible point, however, the underlying methodology will be made visible, and its assumptions scrutinized. Much of the code underlying this project I have written myself. Some has been written at my request. In every case where the code is available to me, the program itself appears in Appendix A (“Codebase”), accompanied by a plain-language explanation of how it operates. Where I have used closed-source software, Appendix A contains an explanation of my best guess at its underlying process. My exact use of these tools --- sufficient for another to replicate my work --- is provided in Appendix B (“Methodology”). These details are explicated in full in the appendices in order not to over-burden the body of the dissertation, but they are by no means *confined* to the appendices. Computation is not a “black box” to be consulted for simple answers, but is inextricable from my reasoning and argument.  

My attention to the *sources* of digital knowledge creation comes from Johanna Drucker, and her distinction between “data” and “capta.” Drucker, in “Humanities Approaches to Graphical Display,” specifically addresses the digital humanities practice of creating, and then close-reading, data visualizations. She argues that the tools for visual representation which may be effective in the sciences cannot be simply and uncritically transposed to humanistic subject matter. When an experiment is presented as a ‘data visualization,’ she says, “the rendering of statistical information into graphical form gives it a simplicity and legibility that hides every aspect of the original interpretative framework” \\cite\{Drucker:2011uo p.8\}. In fields where the readers of such charts are also frequent creators of charts, and where norms exist to explicitly describe one’s interpretive frameworks in a methodology section, the simplicity and legibility of an individual chart may be a benefit which does not impede complex scrutiny of the information it presents.[^cf6] In a field like literature, however, the “graphical force” of something like a network graph or even a simple pie chart “conceals what the statistician knows very well --- that no ‘data’ preexist their parameterization” \\cite\{Drucker:2011uo p.8\}. Drucker problematizes the term “data,” the etymology of which presents it as a “given” which is stable and independent of observation. She proposes that humanities visualizations embrace, instead, the framework of “capta,” that which is “‘taken’ actively” \\cite\{Drucker:2011uo p.3\}, “fundamentally codependent, constituted relationally, between observer and observed phenomena” \\cite\{Drucker:2011uo p.50\}. Drucker’s assessment shapes my own prioritization of qualitative and reflective computational research. The term “capta” itself has not seen uptake in subsequent digital humanities scholarship, even in cases where scholars explicitly take Drucker’s warnings to heart. Accordingly, for clarity, this dissertation will continue to use the more usual term “data” to refer to the information gathered for analysis here. However, as I integrate and compare a wide variety of data from many disparate sources, a preliminary task of my analysis is always to determine, as precisely as possible, how the information was captured and quantified.   

Additionally, all of the figures presented in this dissertation are of my own design. My design praxis is informed by the work of Edward Tufte and Alberto Cairo, both of whom provide practical design advice in service of demystifying the visual rhetoric by which graphs present their arguments.[^cf7] Neither Tufte nor Cairo is a scholar of media studies; rather, they are professional practitioners of ‘data visualization’ who reflect critically on the assumptions of their work. Tufte’s work primarily strives to correct badly-designed data visualizations, and the dangerous decisions that bad design can lead people to. His most famous example is an analysis of the scientists’ report at NASA which led to the ill-fated launch of the Challenger space shuttle in 1986: as his extensive visual analysis argues, the scientists (untrained in graphic design) unintentionally obfuscated crucial information about the day’s launch conditions. The poorly-designed graphics these engineers produced made the launch appear low risk to their superiors; despite the engineers’ strong warnings, their verbal argument was disregarded in favor of their accidental graphical argument. As Tufte demonstrates, a few simple alterations of their graphic design would have made it obvious that the day’s unprecedentedly low weather was extremely dangerous, and potentially averted disaster \\cite\{Tufte:2001vw\}.[^cf8] Tufte’s six principles of design[^cf9] primarily seek to guide undertrained designers away from misleading themselves. Cairo, following on Tufte’s work from the perspective of an active journalist, more often turns his attention to successful designs which mislead their audiences intentionally. His forthcoming book, *How Charts Lie*, addresses the readers of infographics with insights into visual literacy \\cite\{Cairo:ikIksuMr\}. His preceding book, *The Truthful Art*, addresses the creators of good-faith infographics with insights into visual manipulation \\cite\{Cairo:2016uv\}. Cairo draws a distinction between “data visualization” and “infographics”: “an infographic tells the stories that its designer wants to explain, but a data visualization lets people build their own insights based on the evidence provided,” summarized more succinctly as “infographics to explain, data visualizations to explore” \\cite\{Cairo:2014tl\}. Using this terminology, my argument will proceed with infographics in the body of the dissertation as curated figures to support my argument, with fuller data visualizations available in Appendix C (“Data”) to allow further exploration. Following in both Tufte and Cairo’s footsteps, I conceive of the figures throughout this dissertation as rhetorical devices. In service of arguing honestly, therefore, my designs --- in the body of the dissertation and in Appendix C --- are accompanied by footnoted explanations of my design rationale. 



#### 1.1.1.2.  1790s ####  

All of the computational work in this dissertation does have an aim beyond itself: to recapture, in as minute detail as possible, the print landscape in England between January 1 1789 and December 31 1799. This eleven-year “decade” was a turbulent one across the Channel, encompassing the whole of the French Revolution, from the Estates General in 1789 to Napoleon’s coup in 1799.[^cf10] In England, these events caused strong and variously nationalist reactions in a country which had so recently lost its colonies in America and feared that a French invasion could come at any moment. This is the decade of *Common Sense*, it is the decade of *Lyrical Ballads*; it is the decade of Hannah More, it is the decade of Ann Radcliffe; it was the age of wisdom, it was the age of foolishness; it was the epoch of belief, it was the epoch of incredulity. Charles Dickens’ now-famous superlative degree of comparison captures the tension between empiricist or otherwise political thinkers and Romantic or Gothic artists as contemporary literary scholars grapple with these modes. Each literary ‘mode’ was imbued with the potential for national importance.  

I am by no means the first to examine the writing of the 1790s in light of authors’ political strategies in the print marketplace, though preceding work is often organized along genre lines. For example, George Taylor, in *The French Revolution and the London Stage*, sets forth some key contentions about literature’s cultural capital. He argues that although eighteenth-century critics sought to make distinctions in the social value of different plays, or different parts of the theatrical program at a single show, audiences did not make these distinctions. “Although audiences were divided according to class between pit, box and gallery,” he argues, the division was purely physical: “all came to see the same shows, for within one programme there was a variety that not only satisfied the different groups but satisfied them all \[...\] all received plaudits from all corners of the house” \\cite\{Taylor:2001gp p.3\}. Taylor proceeds to define the central concerns and strategies of the plays staged during this period, arguing that “the determining feature of the period for the theatre was the sense of loss, a feeling that things had changed in ways that people did not expect or want,” a feeling that was reflected in “images of incarceration, dislocation and supernatural intervention” \\cite\{Taylor:2001gp p.221\}. This analysis of the theatre is structured by his originating observation that “Disagreement as to what is trash and what is treasure suggests cultural crisis, when values are put under question by social stress or political conflict” \\cite\{Taylor:2001gp p.3\}. The communal space of the theatre, which some cultural critics in the eighteenth century attempt to render non-communal and to dissect along class lines, is for Taylor fertile ground. For my inquiry, it is the “\[d\]isagreement as to what is trash and what it treasure” itself which animates me: the terms “trash” and “treasure” are hardly exaggerations of the extremity of the conflicting assessments which could be passed regarding the same works[ add a paragraph about the rise of the novel after this one, later on



The unexpected difficulty of distinguishing “trash” and “treasure” is also a throughline in the many competing histories of the rise of the novel, and in particular their need to address the Gothic novel’s astonishing popularity.].  

The desire to distinguish between “trash” and “treasure” also appears in studies of poetry, which in this period are nearly synonymous with studies of Romantic poetry. Particularly where poetry is examined in light of conflicts with France, analysis of poets’ work often doubles as an analysis of their success or failure in the pursuit of cultural capital. For example, Simon Bainbridge, in *British Poetry and the Revolutionary and Napoleonic Wars*, sees the decade and its poetry through the lens of war. His own interest is in what he terms “the attempts made by several writers to fill the role of national bard prior to Scott” \\cite\{Bainbridge:2003uk p.3\}. This framework leads Bainbridge to examine Charlotte Smith alongside Samuel Taylor Coleridge, William Wordsworth, Robert Southey, and eventually Walter Scott. In his conception of ‘a national bard’ he imagines a particular marriage of poetry’s special status as imaginative literature to a specific poet’s cultivation of a nationally important public persona. Both poetry and the poet are thus pursuing a particular kind of cultural capital that allows them to rise above their own popularity. Bainbridge frequently discusses strategies of print publication as part of his analysis: a particularly insightful footnote discusses, for example, a poem which circulated both as an ode in a magazine and as lyrics in a broadsheet. Bainbridge observes that “texts could shift in status and meaning as they were adapted for different forms of production and different audiences, in this case existing in both the relatively elevated form of the ode, to be read by an individual magazine reader, and as a new set of lyrics to a traditional tune, achieving its fullest realization in a communal performance at a political meeting in an alehouse or at a demonstration” \\cite\{Bainbridge:2003uk p.10\}. However, his explanations of individual print strategies are often hindered by his approach to literature’s cultural capital. At one point, for example, he argues that “the fact that the Gentleman’s Magazine was forced to reproduce at length a poem written two decades previously again emphasizes what was seen to be the failure of anyone convincingly to fill the role of the Bard until the emergence of Walter Scott” \\cite\{Bainbridge:2003uk p.53\}. I contend that the republication of substantially older works of literature is not a sign that England was destitute of true poetry before Walter Scott, but rather an attempt to solve the challenges to national identity posed by the 1790s’ disruption of history.  

Bainbridge is not alone is taking Walter Scott as a kind of pinnacle, and looking backwards in search of his antecedents. Richard Cronin, in *The Politics of Romantic Poetry*, concerns himself with “poetry that speaks to a divided society in an attempt to constitute its readers as citizens of \[...\] ‘the pure commonwealth’” \\cite\{Cronin:2000vz p.13\}. This definition of “political poetry” leads him to Erasmus Darwin as the poet of the the Revolution and the Revolutionary war, William Blake as the poet of the Napoleonic wars, and Richard Southey and Walter Savage Landor as the poets of the post-war period --- ending, irresistibly, as so many do, with Walter Scott. Despite the fact that Cronin’s chief interest is in each poet’s use of language to construct an ideal audience, print culture looms. Of Erasmus Darwin, Cronin emphasizes Darwin’s use of “\[t\]he most powerful of the languages available in the 1790s that could plausibly claim universal status,” namely, “the language of science” \\cite\{Cronin:2000vz p.16\}, but it is the “beautifully and expensively produced edition of The Botanic Garden” \\cite\{Cronin:2000vz p.29\} which asserts his importance. Blake’s eccentric, idiosyncratic language is mirrored in his eccentric, idiosyncratic printing practices \\cite\{Cronin:2000vz p.60\}. Southey and Landor’s universal, international language seeks to “escape from history” \\cite\{Cronin:2000vz p.81\}, which entails disavowing not only the popular prose fictions which sought to represent history but also the very circulating libraries in which they were distributed \\cite\{Cronin:2000vz p.74\}. In other words, Cronin, even more so than Bainbridge, seems to use ‘poetic language’ to explain phenomena which have important print culture dimensions. Nonetheless, his discussion of Scott accurately describes the particular nature of Scott’s success: “Scott’s *Minstrelsy* transforms ballads freely passed from speaker to speaker around cottage fires on the Scottish Borders into luxury items, items only available to book-buyers of some means” \\cite\{Cronin:2000vz p.94\}. The Romantic poets, in both Bainbridge and Cronin’s accounts, support their claims to insight and importance through the inaccessibility of their work in print.  

Poetry thus stands in a stark contrast to the volumes of writing which John Mee discusses in *Print, Publicity, and Popular Radicalism in the 1790s.* Although his title leaves open the possibility that he could consider any kind of writing in print, Mee is concerned solely with the activities of the London Corresponding Society, placed in the context of Romanticism. He examines “public lectures, toasting, tavern debates, and song, but also more mundane and less colourful associational practices, such as day-to-day editorial discussion about what to publish under the LCS’s name” \\cite\{Mee:2016wk p.28\}. These writers held a fundamentally different relationship to the print marketplace than the Romantic poets, or even than theatre critics: rather than concerning themselves with distinctions between ‘good’ and ‘bad’ forms of writing or publication, Mee argues, “At certain points the societies seem to operate under the spell of ‘print magic’, that is, a faith that print could liberate mankind simply by bringing ideas into printed circulation” \\cite\{Mee:2016wk p.24\}. This partly shifts to Mee himself the task of assessing whether the texts he studies are ‘literature.’ A partial claim to the status of ‘literature’ is suggested by the participation of his book within the series ‘Cambridge Studies in Romanticism,’ which, he acknowledges “implies an understanding of popular radicalism as a kind of ‘literary’ culture. At least, it argues for the centrality of the writing, production, and circulation of printed texts that took up so much of the time of the radical societies” \\cite\{Mee:2016wk p.18[ “this formation and the associated identification of the literary with what John Thelwall called ‘sallies of the imagination’ were the product of a crisis brought on by the emergence of the popular radical culture opened up in this book, but the story is not a straightforward one. Thelwall himself could identify ‘literature’ both with a domain of imagination separable from politics and with print as the principal engine of emancipatory change.” (Mee 18)]\}. Nonetheless, the book distances itself from “Romanticism and its major poets, novelists, and playwrights” \\cite\{Mee:2016wk p.18\}. Mee thus replicates the distance that the period’s “poets, novelists, and playwrights” sought to put between themselves as the “the role of print personality[^cf11] as a form of mediation” \\cite\{Mee:2016wk p.29\} that interests Mee in the LCS.  

John Guillory contends that the “canon debate” taking place during his moment of writing in 1993 “signifies nothing less than a crisis in the form of cultural capital we call ‘literature’” \\cite\{Guillory:1993ve p.viii\}; as both he and I argue, the roots of this crisis lie two hundred years earlier, in the eighteenth century formation of a vernacular (rather than classical) literary canon, and in the 1790s “first crisis” (\\cite\{Guillory:1993ve p.xi\} of that canon. Guillory turns particularly to Wordsworth and Coleridge, and the strategies by which they confer a high status on their own work by undermining the cultural capital of other forms. Wordsworth, Coleridge, and the other ‘big six’ Romantics are surely the winners of the eighteenth century historical battle for cultural capital; just as surely, the loser has been the Gothic. E.J. Clery’s *The Rise of Supernatural Fiction, 1762-1800* provides an account of what was at stake for the representations of supernatural events in supernatural stories in fiction, drama, and popular news \\cite\{Clery:HFvEup7z\}. The “rise” she describes is not an increase in volume and prominence of supernatural stories, since her starting point in 1762 (the Cock Lane ghost) is a major national phenomenon with many imitators. Rather, supernatural fiction ‘rises’ when it acquires cultural legitimacy. Michael Gamer has more recently expanded on how this ‘rise’ fuelled Romanticism’s own rise \\cite\{Gamer:jX8nTxB-\}. In *Romanticism and the Gothic: Genre, Reception, and Canon Formation*, he details  the interconnectednesss of what are now seen as the separate categories of ‘high’ Romantic literature and ‘low,’ popular Gothic writing. By using Gothic materials in self-avowedly non-Gothic ways, Gamer argues, Romantic writers could appeal to popular taste without risking the loss of cultural capital which attended the Gothic’s “popularity”. Gamer, like Guillory, primarily examines Wordsworth and the ‘winners’ of the struggle for cultural capital: I, like Clery, am more interested in the ‘losers.’ Accordingly, I attend to much that is *not* literature, in order to better understand why it is not.



#### 1.1.1.3.  theory ####  

The digital humanities and the eighteenth century are my primary subject matter, but in the interest of transparent methodology I wish to also state the theoretical frameworks which underpin my thinking. In the ‘venn diagram’ of three fields, the ‘queer theory’[ I feel like I really shouldn’t shorthand all this stuff as “queer theory,” since I’m not persuaded that eg Felski is at ALL a ‘queer theorist’ --- but it all comes from Sedgwick for me, and I do need some kind of name for this collection of ideas --- and my own attachment to Felski is tied to queerness] circle is smaller, but no less important. My primary theoretical framework is that of reparative reading. Eve Sedgwick persuasively describes, in “Paranoid Reading and Reparative Reading,” the dominance of paranoia in literary criticism \\cite\{Sedgwick:2003up\}, and attempts to sketch an alternative in what she terms  reparative reading. My touchstones are two descriptions from Sedgwick’s original chapter, “Paranoid Reading and Reparative Reading”:  

The desire of a reparative impulse... is additive and accretive. Its fear, a realistic one, is that the culture surrounding it is inadequate or inimical to its nurture; it wants to assemble and confer plenitude to an object that will then have resources to offer to an inchoate self. \\cite\{Sedgwick:2003up p.149\}

What we can best learn from such practices are, perhaps, the many ways selves and communities succeed in extracting sustenance from the objects of a culture - even of a culture whose avowed desire has often been not to sustain them. \\cite\{Sedgwick:2003up pp.150-151\} 

What Sedgwick describes, here, is a “desire,” not a methodology.  I do not (yet?) claim that my work *is* reparative, and certainly struggle to point to specific methodological decisions to draw a roadmap for reparative work generally. Nonetheless, this desire is at the core of my impulse toward the problems of canons, and of literature in turbulent times, and therefore I note it explicitly here. One reason I seek to go back to the simple, basic questions of ‘what was printed’ and ‘what was popular’ and ‘what was important’ is that I fear that previous forays into these questions have been limited by paranoia. I therefore understand “reparative reading” to refer, not to a precise set of practices, but to a position one might occupy in relation to a text. The reparative position is a generous one, both in terms of giving of oneself to a text, and in terms of seeking a text’s strengths over its weaknesses.



##### 1.1.1.3.1.  not close reading #####



Generosity is often assumed to be an affect which it is only possible to assume in conjunction with textual intimacy; that is to say, reparative reading is often assumed to entail *close* reading. However, I contend that generosity can occur at any scale. Rita Felski provides valuable theoretical insight for reparative readers who do not wish to be (only) close readers. Felski, in her article “After Suspicion” and then further in her monograph *The Limits of Critique*, frames the core question animated by Sedgwick’s conundrum as “Can we be postcritical --- as distinct from uncritical?” \\cite\{Felski:2015lc p.151\}. For Felski, the answer lies in attending seriously to literary attachments, including our own attachments as critics. Felski’s approach to these attachments is essentially sociological, drawing heavily on Bruno Latour’s actor-network-theory \\cite\{Latour:2005vh\}, and thus involves almost no close reading. Felski does accord serious attention to textual effects in her work under the umbrella of what she terms“neophenomenology,” as first described in her “Everyday Aesthetics” \\cite\{Felski:2009um\}, does accord more attention to textual effects. (This is where the “neo” arrives in “neophenomenology,” as Felski distinguishes herself from earlier phenomenologists who treat textual content as almost irrelevant to the meaning-making carried out by readers.) Nonetheless, rather than explicating individual texts, Felski’s neophenomenological work seeks to address the phenomenon of reading itself. My own work is neither sociological nor neophenomenological, but like Felski I undertake reparative, postcritical reading without close reading.  

My search for other ways of relating to literature has also led me to emerging work under the umbrella of “surface reading”. “Surface reading” positions itself as an alternative to “symptomatic reading”; rather than seeking to expose hidden truths concealed within texts, it attempts accurate descriptions that “make visible what is invisible only because it's too much on the surface of things” \\cite\{Best:2016ve p.13\}. The analogues to reparative and paranoid reading are obvious, but not perfect: all paranoid reading is symptomatic, but not all symptomatic reading is paranoid. The tensions between these two modes of reading are explored in more detail in A.C. Facundo’s *Oscillations of Literary Theory: The Paranoid Imperative and Queer Reparative* \\cite\{Facundo:2iP388Oj\}. Reparative reading, as described by Sedgwick, is often still interested in ‘deep’ meanings of texts, in which striking textual features can be interpreted to locate additional meanings. As a result, much of the work produced by queer theory is symptomatic even when it’s not paranoid --- and it’s often paranoid.

In contrast, “surface reading,” as Heather Love describes, pursues “a turn away from the singularity and richness of individual texts” \\cite\{Love:2010cv p.374\}, seeking descriptions are “complex and variegated, but not rich, warm, or deep” \\cite\{Love:2010cv p.378\}. Love’s disavowal of “richness” here is part of her attempt to move away from “the ethical charisma of the literary translator or messenger” \\cite\{Love:2010cv p.374\} who characterizes the paranoid, critical figure that both Sedgwick and Felski also seek to escape. The rejection of this figure also informs Love’s approach to description:

Good descriptions are in a sense rich, but not because they truck with imponderables like human experience or human nature. They are close, but they are not deep; rather than adding anything “extra” to the description, they account for the real variety that is already there. \\cite\{Love:2010cv p.377\}

Love’s articulation of this mode of is, partly, struggling with the task of describing something which does not yet fully exist. Her later article, “Close Reading and Thin Description,” provides a more precise articulation of the kind of close reading that she calls for, in which an “exhaustive, fine-grained attention to phenomena” \\cite\{Love:2013cu p.404\} enables “taking up the position of the device; by turning oneself into a camera, one could---at least ideally---pay equal attention to every aspect of a scene that is available to the senses and record it faithfully” \\cite\{Love:2013cu p.407\}. Although Love is somewhat uninterested in “distant reading” as synonymous with Moretti \\cite\{Love:2013cu p.411\}, this invocation of the mechanical implies, I argue, an obvious potential for computation. It is in order to create room for computation that I pay particular attention to Love’s earlier, more tentative discussion of description as a literary practice. Computational distant reading cannot answer Love’s call for “a model for close reading after the decline of the linguistic turn” \\cite\{Love:2013cu p.404\}, since it is not close reading, but computation does enable *closeness* without depth. As I will discuss more fully in \[FUTURE SECTION\], a good computational model is unlikely to “truck with imponderables,” but it *absolutely* *must* “account for the real variety that is already there” or else one’s code will simply fail to run.



##### 1.1.1.3.2.  conclusion #####



By marrying “surface reading” and “distant reading” I may seem to leave “reparative reading” behind: after all, Felski’s call for postcritical analysis explicitly suggests, “Sometimes serious thinking calls for a judicious decrease rather than and increase of distance” (CITE). However, Felski then defines a decrease of distance as “a willingness to acknowledge and more fully engage our attachments”: this, I insist, can be done at any scale.



### 1.1.2.  synthesis of 3 fields ###  

Drawing together three scholarly conversations with three distinct histories --- the digital humanities, the 1790s, and reparative reading --- it is difficult to attentively delineate the links and the tensions between each thread. Especially since many of these fields have, in fact, overlapped substantially, there is a danger of simplistically conflating distinct lines of thoughts. At the same time, over-emphasis on distinctions can overstate the separations between fields which do in fact (as the existence of this dissertation contents) share important affinities. To navigate these conceptual overlaps carefully, let us make our way through each area of an imagined Venn diagram of the three. We can discuss each pair in turn --- DH and eighteenth century studies; eighteenth century studies and queer theory; queer theory and DH --- to make our way toward the centre where all three overlap.



#### 1.1.2.1.  DH & 1790s ####  

Eighteenth century materials of various kinds have been collected in many digital archives, of very different scope.[ Does this whole section actually belong in chapter two? If so, what goes here instead --- lit review of other DH work done on the 18thC? Maybe, common methods used? --- maybe not until after Tom & Terry see, for now write a comment that this is the plan and list 18thC DHers I will cover instead] These are discussed in more detail in Chapter 2. On the tip of anyone’s tongue, of course, is Gale’s Eighteenth Century Collections Online (ECCO), containing over 180,000 titles 1701-1800, of which 42,000 were printed in England between 1789 and 1799. ECCO is itself (mostly) a subset of the broader English Short Title Catalogue (ESTC), which contains more 460,000 texts 1473-1800, of which 51,965 were printed in England between 1789 and 1799 (indicating that nearly 10,000 in the decade titles appear in the ESTC but not ECCO). The ESTC does not provide access to texts themselves: instead, it is an authoritative bibliographic catalogue, available as a searchable database. It is ECCO which provides texts themselves: ECCO’s 180,000 titles works are available as photographed facsimiles of the full text of each title. The facsimiles can be searched within ECCO’s online interface; these searches examine a plaintext version of the facsimile pages that was generated by Optical Character Recognition (OCR), but this OCR text is not made directly available. As a result, the facsimiles may be read individually by scholars, but cannot form the basis for computational corpus analysis. A subset of ECCO’s texts have been hand-prepared, as part of the Text Creation Partnership (TCP), to be easier to use in computational research. The resulting corpus of ECCO-TCP texts contains 2,231 titles, of which 466 were printed in England between 1789 and 1799. These titles are available as carefully-edited texts encoded according to the Text Encoding Initiative (TEI) standard, which not only provides an accurate version of the text’s words, but encodes substantial details regarding its context on the page. Most large-scale distant reading of eighteenth century literature relies in the ECCO-TCP corpus as its ‘model’ or ‘sample’ to represent the period. Accordingly, one of the tasks of this dissertation is to precisely examine the makeup of thus corpus, and how it differs both from other corpora and from print culture in the period itself. These three digital collections --- ECCO, ESTC, and ECCO-TCP --- are the primary digital resources for the period, which form the basis of most digital research. However, they represent only one approach toward the collection and presentation of digital texts, to which there are two broad kinds of alternatives. These large but meticulous collections occupy a middle space between, on the one hand, highly selective thematic collections, of which there are many, and the giants of indiscriminate textual accumulation, of which there are few.  

Smaller collections allow for more scholarly curation, but have corresponding limitations. Whereas the ‘main players’ can be easily enumerated for the mega-archives, these specialized collections are numerous. Some will focus on particular kinds of texts, such as the Early Novels Database (2,041 novels 1700-1799) or Broadside Ballads Online (more than 30,000 broadside ballads). Others exhaustively index particular publications, such as The Hampshire Chronicle, the Index to the Lady’s Magazine (1770 to 1818), or the Novels Reviewed Database (1,836 reviews from The Critical Review and The Monthly Review, 1790-1820). Feminist scholarship in particular has seen the creation of resources like the Orlando Project, the Chawton House library Novels Online, Northeastern University’s Women Writers Online and UC Davis’s British Women Romantic Poets. The virtue of these collections is that they achieve even greater accuracy and comprehensiveness within their defined scope. The Shelley-Godwin Archive, for example, can reasonably aspire to digitize *every* known manuscript of Percy Bysshe Shelley, Mary Wollstonecraft Shelley, William Godwin, and Mary Wollstonecraft, and to provide these manuscripts in hand-encoded plaintext transcripts. However, as is inevitable, these specialized archives have the vices of their virtues: their specialized focus allows them to adapt precisely to their materials, and their idiosyncratic data structures can rarely be combined with other resources. The William Blake Archive, for example, benefits enormously from designing its archive around the unique images of each page of each copy of each of Blake’s works. But because this approach is so well-suited to Blake, it cannot be applied beyond Blake. Even if the archive’s resources were available for download, they could not be directly compared to materials from another source which does not record its information at such a minute level of detail. 

Also in the category of ‘smaller and specialized’ archives is Project Gutenberg. Project Gutenberg makes no claims to scholarly reliability but nonetheless underlies a not-significant amount of scholarly work[^cf12] --- its cultural capital as a resource lags far behind its use and utility. Project Gutenberg is easily conceived of as a haphazard, ‘unscholarly’ source for materials, but unlike Google Books, Project Gutenberg actually does have selection criteria. Project Gutenberg will only collect public domain works which contemporary audiences might be interested in reading for pleasure. It narrows the field substantially to exclude works which have either ceased to be broadly interesting (as in the case of most forgotten fiction), or which was never particularly interesting (as in the case of almanacs and tax codes). Project Gutenberg includes 57,796 texts: far more than specialized scholarly archives like the Early Novels Database or the Shelley-Godwin Archive, but nonetheless an order of magnitude fewer than its more-voracious potential competitors. And, like smaller specialized scholarly archives, Project Gutenberg has tailored its holdings to make it easy for readers to read, and quite difficult for its collection to be applied to any other use. By tailoring the structure of the archive itself to its specific materials, these collections are able to thoughtfully achieve their aims --- but they also make it correspondingly difficult for users to achieve their own, different aims.  

The best known mega-archive is, of course, Google Books. In a scholarly context, one hesitates even to designate this as an “archive,” particularly in the same breath as resources like ECCO: books of all kinds are scanned indiscriminately with only the bare minimum of roughly-accurate metadata collected about them. Books are sourced from libraries whose collections are being scanned in bulk, or are submitted directly by publishers or authors who are attracted by Google’s call to “Promote your books on Google---for free” (CITE[^cf13]).   These rapidly-scanned books are prone to unpredictable errors, including inaccurate dates, misspellings, duplicate copies, and inaccurate subject classifications (Harper 2016; Jacsó 2008; Weiss 2016) (CITE Mike Sutton and Mark D. Griffiths) --- infamously, many books have “1899” assigned as their publication date because this date was used as a placeholder for “no date”.[^cf14] Many photographed pages still include the fingers of the employee holding open the book. Nonetheless, Google Books is frequently used to study the prevalence of various “n-grams” (words or short phrases) over time, thanks to Google’s built-in tool. The tool is able to search books which are, for copyright restrictions, not available directly to readers, making it highly tempting for question about contemporary language use. Similar in scope to Google Books but with more limited research tools is The Internet Archive. The Internet Archive, unlike Google Books, is a non-profit, but like Google Books, it carries out mass scanning of books. The Internet Archive declares that it contains 20 million books and texts, and scans 1,000 books per day in 28 locations around the world (CITE).[^cf15] Equivalent numbers are not published for Google Books, which has received less attention from Google as it encountered more legal barriers; in 2013 books were scanned at the rate of 1,000 pages per hour, and in 2015 more than 25 million books had been scanned. Google Books, Project Gutenberg, and the Internet Archive are not “canonical” sources of texts, but they are nonetheless part of the ecosystem of digital eighteenth century studies.

  

Moreover, as in eighteenth century texts themselves, the boundary between “canonical” and “noncanonical” digital archives is a permeable one: Google Books and the Internet Archive, distinctly ‘noncanonical’ archives, are also integrated into HathiTrust, an increasingly popular ‘canonical’ resource for scholars. HathiTrust’s collection contains digitized content from “a variety of sources, including Google, the Internet Archive, Microsoft, and in-house member institution initiatives” \\cite\{HathiTrust:2019vs\}. The “in-house member institutions” are six consortia (such as the University of California state university system), and one hundred and forty-nine individual universities and colleges \\cite\{HathiTrust:2019ti\}. The aggregate scholarly authority of these institutions carries the weight of elevating HathiTrust above the Google Books scans which form the backbone of much of its contents: “The members ensure the reliability and efficiency of the digital library,” the website assures us, “by relying on community standards and best practices” \\cite\{HathiTrust:2019vs\}. The collection itself is always expanding: the website contains a dedicated set of instructions for “Getting Content Into HathiTrust,” providing an “Ingest Checklist” for those who might contribute either existing or new digitized content \\cite\{HathiTrust:2019tf\}. The texts themselves are all stored as facsimile page images and full-text OCR transcripts. In order to comply with copyright law, however, HathiTrust only provides large-scale downloads and OCR transcripts for texts which are in the public domain. What does, in fact, distinguish HathiTrust from similar repositories is its commitment to enabling fair use and research-based access to texts as much as possible. Rather than favouring maximum restriction of access in order to ensure maximum protection from legal complaints, HathiTrust has innovated several ways to allow scholars to carry out text-mining analysis on copyrighted texts. The scholarly benefit of HathiTrust is most evident, therefore, in the study of contemporary literature, where copyright has been a major barrier to study. However, eighteenth century texts are so firmly in the public domain that copyright issues rarely arise; instead, the major challenge in building large-scale corpora of transcripts (rather than facsimiles) is the resistance of eighteenth century typefaces to OCR. Especially since many eighteenth century digital facsimiles are themselves fascimiles of microfiche (with resulting loss of image fidelity), running an eighteenth century page image through OCR software generally produces useless gibberish. As a result, HathiTrust’s key intervention --- using OCR to circumvent copyright restrictions --- has limited applicability to eighteenth century studies.  

As this survey of eighteenth century digital archives shows, there is no ‘perfect’ corpus for large-scale study of eighteenth century texts. Moreover, I argue, the imperfect samples which each archive provides are shaped not only by historical factors of eighteenth century print culture, but also by contemporary digital culture. Each archive represents a unique set of choices in response to the same sets of questions: what to include, why, how; what to make accessible, why, how, to whom; what, in the end, makes a text matter, and what we are meant to *do* with texts. As this dissertation will argue more fully in Chapter 2, these questions of digital history have important resonance with literary questions about literary canon formation.



#### 1.1.2.2.  1790s & queer ####  

\[This section is, essentially, unwritten as of yet --- but it’s a lot of stuff I’ve known for a long time that I can sit down and retrace and spell out fairly easily.\]



Queer readings of the 1790s --- which is to say, of the Gothic --- provide an invigorating way to value some of the most vibrant writing of the decade precisely for the features which rendered it less than “respectable.” \[HISTORY OF QUEER GOTHIC STUDIES - Palmer I think, leading up to Franz Potter... this history is prob multiple paras\] \[Put all that rise of the novel stuff in here, Tompkins and Kiely etc, as the motivation for queer and Gothic to go hand in hand in the 18thC\] \[A lot of really good Gothic work is connected thematically rather than strictly chronologically, examining the “transtemporal affinities and connections” (CITE) that Felski argues are often shut out by contemporary historicist critique. And indeed, historicist critique is causing this mode of study to fall out of favour regarding the Female Gothic. Nonetheless, there is a rich history of transtemporal work on the Female Gothic. \[I DON’T NECESSARILY BUY THIS STUFF BUT IT HAD IMPORTANT GOALS\]\]  

\[A lot of queer Gothic work has been paranoid\] \[Something about Susan Sontag & camp being how I reparatively read the Gothic?\]  

Although the queerest work in this period has centred on the Gothic, I intentionally do not limit my focus to the Gothic. My broader scope is, in part, based in an argument about the Gothic’s prevalence: following scholars like \[EXAMPLE - prob Miles?\], I see the Gothic not as a clearly-defined literary genre, but rather as an affective ‘mode’ that can (and did) permeate writing far beyond the realm of supernatural fiction. Accordingly, \[although I am interested in the Gothic, I study everything.\] \[Also I’m not just interested in the Gothic.\]



#### 1.1.2.3.  queer & DH ####  

My emphasis on transparent, critical, and reflective praxis in the capture and visual presentation of data[^cf16] owes much to the emerging field of critical algorithm studies. Any methodology is, to a certain extent, an “algorithm,” in the loose definition of ‘a series of pre-defined steps to be carried out’. But computational algorithms differ from “algorithms” implemented by humans. Computational algorithms have two key vulnerabilities: first, their operations are less easily scrutinized; second, their results are more easily trusted. The second vulnerability --- the cultural aura of empirical trustworthiness which accrues to anything ‘computational’ --- is another flavour of the same vulnerability that Drucker describes with ‘data’ generally. Because the human agents who designed and trained any given algorithm appear to be absent from its operation, the algorithm appears able to discover truth directly. This is how Daily Wire reporter Ryan Saavedra was able to tweet with disdain that “Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist” \\cite\{Saavedra:2019wr\}: anything “driven by math,” he assumes, must be incapable of human fallibilities like racism. But as Safiya Noble shows extensively in *Algorithms of Oppression*, algorithms by default reproduce, and can easily exaggerate, the assumptions and biases of the culture in which they are made \\cite\{Noble:2018wo\}. In other words, in a racist world, algorithms *are* racist --- and sexist, and duplicative of all other systemic institutional inequities.

Wendy Chun suggests that the problem with much algorithmic inquiry lies in its most core assumption: the insistence that the future must look like the past \\cite\{Chun:2018tq\}. This assumption is essential to any system which exclusively bases its predictions on past data. It is particularly intertwined with what Chun calls “homophily,” “the axiom that similarity breeds connection---which grounds contemporary network science” \\cite\{Chun:2018tq p.60\}. Homophily, as it is currently applied to network science, Chun argues, both “assumes and creates segregation” \\cite\{Chun:2018tq p.76\} in a fashion that allows it to operate “like money laundering for bias” \\cite\{Chun:2018tq pp.62-63\}. Importantly, however, the analogy to money laundering is imperfect: it cannot be resolved with “better, cleaner data” \\cite\{Chun:2018tq p.64\}. Instead, Chun insists, “new theories of connection---which do not presume a dangerously banal and reciprocal notion of friendship---are needed” \\cite\{Chun:2018tq p.89\}, a call to action which places its emphasis not on the information provided to an algorithm but on the algorithm’s procedures.  

As Chun’s punning title, “Queerying Homophily” suggests, she, like many scholars, turns to queer theory as a way to address the structural failings of algorithms. “Queer DH” is a vibrant field in its own right, which, like any vibrant field, contains many distinct but interwoven threads. Some work, like Chun’s, take the theoretical underpinnings of contemporary computational practices as their primary object of study, and conceptualize queerer theoretical approaches. Others similarly undertake non-computational research to examine computational subjects queerly, as in Bonnie Ruberg’s *Video Games Have Always Been Queer*. Many projects apply existing computational methods to queer literatures and histories. Often, these approaches coincide, as queer subjects demand queerer methods[ Need to add an example here. Also need to expand in more detail on all of these examples.], as in T.L. Cowan’s *Cabaret Commons*. I draw inspiration from work from across this spectrum of queer DH in my pursuit of less “extractive” and more anti-oppressive digital humanities methodologies.  

As I encounter the limitations of the various information and tools with through which I attempt to understand the 1790s, my goal is to do something other than facilely observe that they are limited. Critique, in many venues, still has valuable new information to contribute regarding the contemporary digital landscape. Drucker, Noble, and Chun’s warnings about the subjective nature of data and algorithms, for example, all have the potential for urgent relevance. In part because their critiques have been presented so effectively, however, I do not give critique a central role here. Most of the digital artefacts that I examine have been created, not by ever-hungering capitalist corporations, but by my fellow scholars. In the spirit of laying down the next few stones in the building of a cathedral begun long before me, I want to identify the best ways to continue building on their foundations. In a digital humanities context, a focus on building connections can be mundanely practical: typing indexes from print works into spreadsheets, correcting errors within datasets, writing programs to process metadata: all of these maintain the functional usability of existing resources in new contexts. When this kind of extended, detail-oriented labour is combined with serious reflection on the histories and possible futures of these resources, I contend, they bring us to new knowledge. In this, maintaining and using digital resources is also a way to repair them --- and to produce reparative readings of their contents.  

Thus far, the importance of reparative work to DH is evident. But what about the other direction? Just as, I argue, both DH and bibliography have important resources to offer to each other, so to do I argue that DH has something to offer to reparative reading. Specifically, a well-formulated DH praxis can introduce a new relationship to the experience of *surprise* which is so challenging in paranoid reading. The most common dismissals of DH research are attempts to say, “we already knew that” --- essentially, \[PARANOID AVOIDANCE OF UNPLEASANT SURPRISE FROM DH COMING FOR THEIR JOBS\]. This reaction invites two responses. First, \[if the experiment told us that everything we knew was COMPLETELY WRONG, this would not be very good because probably at least some of what we know is right; an experiment should validate some of our existing knowledge\]. \[Experiments fall into two categories: those which tell us about our methods, and those which tell us about our fields of study\]. Second, as scholars such as Ted Underwood have noted, it is often only *retroactively* that these discoveries are declared to be “obvious” results which everyone “already knew” (CITE). If we are asked to form an explicit hypothesis in advance, we might be very surprised by the exact numbers. \[TRANSITION\] Rather than being an awkward fit for my theoretical aims, and rather than pursuing reparative reading in spite of my computational methods, I see the laborious, intimate process of experimental computation as a directly valuable source



### 1.1.3.  upcoming 2 experiments ###  

Having delineated a large and complex scholarly context for this work, and made some preliminary efforts toward synthesis of these disparate backgrounds, it is time, now, to delineate the research born of this context. This dissertation proceeds in two major parts. The first examines the 1790s through the lens of ‘titles,’ and the second through ‘persons.’ In both cases my central interest is the vexed category of ‘popularity.’ With both ‘titles’ and ‘persons’, I establish the materials with which I will be working and their implicit models. Using the information they make most readily accessible, I explore which works and individuals emerge as ‘popular’ or ‘important’ in each resource. I also probe each resource for its representation of (or failure to represent) my touchstone authors, Ann Radcliffe, Charlotte Turner Smith, Hannah More, and Mary Robinson. The resulting findings are primarily used to evaluate how the underlying digital resources participate in or resist the projects of canon-building. Then, for both titles and persons, there is a ‘turn.’ For each area of inquiry I introduce a novel experiment which synthesizes my materials and repurposes them. These experiments are then used to draw conclusions about 1790s print culture.



#### 1.1.3.1.  titles ####



The first phase of this project takes up titles and databases. Throughout this work, a ‘title’ is the broadest possible umbrella term for a text: it is synonymous with ‘a database entry which I believe to represent a printed work.’ Each individual database will shape the precise correspondences between a ‘title’ and the printed texts about which I use ‘titles’ to reason. For example, it will vary based on my source whether multiple editions of the same work are several ‘titles’ or one ‘title,’ and whether the titles exclusively represent ‘books’ or also include chapbooks, broadsheets, or even ephemera. Due to the inscrutability of digital infrastructure discussed above, it is often not possible for me to know prior to experimentation what kinds of titles I am working with. Chapter two, therefore, two takes up contemporary digital archives directly, examining corpora of eighteenth-century literature through the same critical lens by which anthologies and classroom teaching are often scrutinized.  

In chapter two, I make the case that digital archives can implicitly shape scholarly research, and begin the process of revealing and interrogating their invisible assumptions. The chapter begins with a task somewhere between a literature review and a scientific meta-analysis. My first goal will be to survey as broadly as possible the accessible mass holdings of eighteenth-century texts (all those containing at least 100 works from the 1790s). I expect to find systematic exclusions where archives are investing more labour in their holdings, with narrower selections as they move from bibliographic data to facsimiles to scholarly transcripts. To contextualize these decisions about inclusion, I research the history of how each corpus was formed. As part of this demystification process, I also discuss and theorize the difficulties involved in researching these histories: drawing on, for example, my experience with HathiTrust’s codebase, I critique the assumption that digital resources make all information transparent and accessible. Returning to the actual contents of each archive, I discuss the nature of their exclusions, and consider paths to greater inclusivity.  The second chapter thus establishes the corpora which will drive my argument in chapter three, and will shape the later phases of my research in chapters four and five.  

In chapter three, I synthesize these disparate sources of texts and metadata, to examine popularity as it manifests in print culture. I begin by creating my own ‘superset’ database of all records. I then query this database through random sampling and topic modelling. Both random sampling and topic modelling, as methodologies, allow me to examine information outside of its pre-designed data structures. Random sampling, which Steven Zwicker \\cite\{Zwicker:2006ck\} and Leo Lahti, Niko Ilomäki, and Mikko Tolonen \\cite\{Lahti:2015dd\} have applied successfully to the English Short Title Catalogue’s holdings, makes it feasible to apply a greater level of human scrutiny to a large body of texts. Topic modelling makes it feasible regularize otherwise-disparate materials without imposing a pre-defined ontology. My use of topic modelling differs somewhat from its typical use in literary distant reading, which generally applies topic models to the full text of literary works, and examines topics themselves as proxies for subtle elements of textual content. I model only the titles of works, taking advantage of the eighteenth century’s distinctively rich title conventions.[^cf17] Both of these methods allow me to use my ‘superset’ database to ask questions about 1790s literature itself. Influenced by Lesser and Farmer’s articulation of “structures of popularity,” I consider popularity in terms of total number of editions, frequency of reprinting, and market share. After presenting my proposals for how to calculate each of these metrics, I ask: what was most popular during the decade, according to my corpora? How do the corpora differ in their answers, and why? Many of the most reprinted works substantially pre-date the 1790s in their composition. Accordingly, taking up David Brewer’s challenge to account for the increased “footprint” of some texts beyond the moment of their original publication, I also pay attention to works originally written before the 1790s which nonetheless can be considered important “1790s literature” due to prominent reprinting. This inquiry’s first question is one of discovery: what works resurface in the 1790s? Its next question is one of close-reading and historical context: what makes them seem newly relevant? The chapter as a whole, then, presents a sustained study of the relative popularity of the most prominent works printed during the 1790s, and seeks to answer how these prominent works might affect what we define as “popular literature.”



#### 1.1.3.2.  persons ####



The second phase of the project takes up persons and networks. As in the first phase of the project, it is a substantial undertaking simply to recover contemporary printing practices; this time, rather than asking what was printed, I ask who it was printed by. A great deal of scholarly work already exists on printing circles, coterie publishing, and individual publishing houses. My project consults this scholarship to extract and encode connections between authors, printers, and publishers (but not patrons, readers, or other persons not immediately involved in the production of printed texts) in order to synthesize the implicit social networks underlying 1790s print production.[^cf18]  

Chapter four introduces my mapping of the social world of print production 1789-99. My understanding and use of network analysis is contextualized in light of Wendy Chun’s work on networks in “Queerying Homophily” \\cite\{Chun:2018tq\}. I describe my methodology and its assumptions, and provide a rich description of my resulting network graph. The graph I create may show one large interconnected network, or several separate networks of varying sizes; these networks may show highly distinct clusters, or evenly interconnected webs. Drawing on mathematical graph theory, the chapter will explain the implications of whichever shape the network ultimately displays. It will also present an overview of the people I identify as the “major players” in the publishing world of the 1790s, both mathematically (looking for nodes with various kinds of centrality) and in the scholarship.  

Having recaptured these complex networks in some depth, I can then examine them, in chapter five, for their relation to our current understanding of mainstream and radical--or as I am terming them “mainstream” and “non-mainstream”--printing circles. My network graphs model individual political affiliation as a complex, socially defined practice rather than a set of concrete and stable ideological stances. This chapter will look for traces of affiliation in the print practices of publishers and authors. I consider individual printers with political allegiances, as in Dissenting societies, radical publishers, and correspondence societies. This then enables me to consider authors’ strategic choices as they publish with different printers. Having identified radical elements in the publishing world, I interrogate the radicals’ claims to marginalization. I suspect that I might find that they were not as socially estranged from the mainstream as they describe themselves, and that their printed works may accordingly have been less marginal. I discuss alternative print markets and alternative circulation, in context with the print production which they are alternatives to. The circulation of works in manuscript presents me with two challenges which will be discussed here. The first challenge is methodological: the circulation of manuscripts clearly occurred, and may have constituted “publication” within social circles, but manuscripts fall outside my purview. This chapter will therefore discuss the nature and rough shape of the gap which the exclusion of manuscript works leaves in my study. The second task of this chapter is more theoretical: as queer and decolonial DH scholars note, there is an ethical choice implicated in the decision to systematically discover, collect, and expose communities which intentionally operated below the notice of state observation. Historical distance prevents me from worrying about causing direct harm through my work, but nonetheless I critically interrogate my own research practices and contextualize my choices with the horizon of expectations within the radical circles I expose. Finally, having discussed the networks of radical and mainstream publishing in the 1790s, I also compare the position of radical publishers in the 1790s with their status in the corpora discussed in chapters two and three, where they may in fact be marginalized. Together, these approaches further complicate the story of popularity which the dissertation challenges elsewhere, by suggesting ways to reassess of the popularity of radical works.[ I’m not really sure how to conclude this chapter --- but I think this is probably something that will be clear when I’ve actually completed the rest of the diss.]  

There is material I don’t discuss in this introduction: what, if any, do I need to add?

\- Lesser & Farmer on popularity

\- Willard McCarty on modelling y

\- Ian Bogost on procedural argument n

\- Jerome McGann on deformance y



## 1.2.  ch 2 - archives ##  

Chapter two takes up contemporary digital archives directly, examining corpora of eighteenth-century literature through the same critical lens by which anthologies and classroom teaching are often scrutinized. It makes the case that digital archives can implicitly shape scholarly research, and begins the process of revealing and interrogating their invisible assumptions. The chapter begins with a task somewhere between a literature review and a scientific meta-analysis. My first goal will be to survey as broadly as possible the accessible mass holdings of eighteenth-century texts (all those containing at least 100 works from the 1790s): simply putting all of this information in one place will be a useful way to review it. Adding a discussion of each archive’s selection criteria will bring it into the realm of a meta-analysis. I expect to find systematic exclusions where archives are investing more labour in their holdings, with narrower selections as they move from bibliographic data to facsimiles to scholarly transcripts. To contextualize these decisions about inclusion, I will research the history of how each corpus was formed. I will discuss and theorize the difficulties involved in researching these histories: drawing on, for example, my experience with HathiTrust’s codebase, I will critique the assumption that digital resources make all information transparent and accessible. Returning to the actual contents of each archive, I will discuss the nature of their exclusions, and consider paths to greater inclusivity. Then I will synthesize these disparate sources of texts and metadata, a substantial technical challenge, to see how the task may be accomplished, and to see what correlations between archives might illuminate the decade. I am particularly curious whether even one text will appear in all corpora, and, if so, which one it will be. Whichever texts appear most persistently will form the basis of my “case study” in this chapter. The second chapter thus establishes the corpora which will drive my argument in chapter three, and will shape the later phases of my research in chapters four and five.  

A model for my work can be found in a methodological debate within the study of Early Modern drama, when Farmer & Lesser introduced revisions to Blayney’s field-changing 1997 essay “The Publication of Playbooks.”



Blayney believes that Lesser & Farmer attempt to disprove his “one inescapable fact about printed plays---namely, that they were not the best-selling moneyspinners that so many commentators have evidently believed they should have been” (7). But what really matters to him about identifying the “best-selling moneyspinners” of the day is not the ‘moneyspinning’ --- the question of whether, when publisher bought a play, he was making a sound financial decision --- but about the cultural centrality of ‘bestsellers’. The total market share of religious texts matters, not because it meant that publishers turned their highest profits off of religious texts, but because “\[c\]ustomers in early modern bookshops chose to spend far more of their money on religious books than they did on playbooks and other ‘literary’ publications,” evidence of “just how massively important godly books were to early modern readers” (7). Lesser and Farmer do not contradict the importance of religious texts to readers. But, in setting out “not merely to measure comparative popularity but also to explain why and how different kinds of books were published.” (F&L 213), they make the case that books with low market share, books that are not “best-selling,” could nonetheless be “moneyspinners.” Their rebuttal states that “...books could be in high demand even though their reprint rate was low. Likewise, books (such as ballads) could be in high demand even though their profitability per copy was low. And, as seems to have been the case with plays, books could be in high demand even though their market share was low” (F&L 213), but what they leave somewhat unstated is: “in high demand” *with whom*?



My own work seeks to examine reprints, but in a more limited fashion than Farmer & Lesser were able to do. Rather than determine the reprint rate of various kinds of fiction, I carry out a Blayney-style examination of pure market share. I seek to identify reprints in order to determine the market share of new versus reprinted material in any given year.   

1. **(Reprinting)** Simon Bainbridge: best-selling, most-reprinted, most-adapted
2. **(Assertion)** George Taylor: simply asserts that some things are popular
3. **(Assertion)** Peter Murphy: despite promising that his study “examines the tension between the material, economic pressures motivating poetry as an occupation, and traditional notions of the forces of literary history,” Murphy says NOTHING AT ALL about how well, to whom, for how much, etc etc things were sold.
4. **(Performances)** Emmet Kennedy, Marie-Laurence Netter, et al.: number of performances per play (*Theatre, Opera, and Audience in Revolutionary Paris: Analysis and Repertory*)
5. **(Book history)** Cronin: mostly asserts that people are “popular” or “celebrated”; with Erasmus Darwin, supports this by saying that the book The Botanic Garden is beautiful & expensive
6. **(Editions, reprints, market share, profitability)** Lesser & Farmer, Structures of Popularity in the Early Modern Book Trade **-** “we need to consider both total number of editions and frequency of reprinting, as well as market share and profitability. No single one of these four measurements by itself equates directly to popularity in the book trade; each addresses different questions about the market performance of books, and each points to a different aspect of both supply and demand.” (208)
7. **(Market share)** Blayney
8. **(Title counts)** MacLeod on the Minerva press --- evaluates most popular authors & subgenres based on the number of “works published” or “titles” (unclear if this includes reprints)
  

It is not, in fact, possible to calculate 



Without \[certain kinds of evidence\], as F&L note, “we will never be able to ascertain precisely the “popularity” of various kinds of books... if by popularity we mean something like the modern best-seller lists” (F&L 16)

Would need size of print runs and cost to produce, as well as sale price, and quantity sold.

\[So it’s a little nonsense when people just say that something is popular\]  

**Comedies vs tragedies performed**: the ratio of comedies to tragedies performed was an astonishing 14 to 1 in Paris (Theatre, Opera, and Audience in Revolutionary Paris: Analysis and Repertory by Emmet Kennedy, Marie-Laurence Netter, James P. McGregor, and Mark V. Olsen)  

The full scope of my project is to grapple with every online database which contains at least 100 texts meeting my criteria: printed, in England, between the years 1789-99. 

I exclude databases of diaries or correspondence, since they are not *printed*. This has the effect of excluding single-author databases.  

I make an exception for archives which specifically seek to address gaps in archival holdings due to systemic bias, that is, three archives focused on women’s writing: Orlando, Chawton, and \[I thought there was a third one\].

For the most part archives are either comprehensive and have significantly more than 100 texts, or they are single-author / single-researcher focused, and thus have significantly less than 100. These kinds of reparative projects occupy the middle space.  

The primary methodological challenge to the questions I would like to pose is the standard makeup of these academic resources: self-contained databases, which are searchable for individual materials but not queryable for overall statistics. (I'd love to know the distribution-by-year of everything in the databases as a whole, but that may be beyond my scope.)



What I'm trying to do, essentially, is to forcibly "join" all of those databases -- the ESTC is my best bet so far, it looks like, for unique keys.

A true "standard" is probably both unfeasible and undesirable. So what can be usefully done with things that follow different standards? I think the answer might be OpenRefine, which I haven't seen extolled enough.

Another approach is to ignore the categories and use things like topic modelling; relies on a more intimate knowledge of the information being studies (i.e., humanities expertise)  

These basic factual questions, about what is in the various eighteenth century digital corpora that represent “mass” 18thC holdings for scholars, matter because \[\]. Even though the specific numbers are likely to change as these digital holdings are continuously updated, my investigation of an archive “snapshot” matters because \[they show how questions of fact can (and cannot) be answered?\]  

Google Books prioritizes low-quality information over *no* information. The algorithmic extraction of publication dates from title pages, for example, can never be perfect. But algorithms give their predictions with certainty estimates: if accuracy was a higher priority, Google Books could calibrate the algorithm to simply provide no answer when none of the possibilities cross a given certainty threshold.



Per <http://languagelog.ldc.upenn.edu/nll/?p=1701> , they actually OVERWRITE metadata provided by partners with their algorithmic information!! They could very easily *not*.  

1. I identify male/female ratios?  

Before I develop custom code, I establish some baselines by taking a random sample of 100 titles from each of my key corpora. I manually identify the original publication date of each title, and whether that title appears reprinted elsewhere in the corpus.



As I expand to algorithmically examine the full corpora, I start with the simplest/dumbest way to identify a reprint: looking on its title page for the words “Xth edition.”

If this method achieves an accuracy of 85%+ (as determined by comparison to my random sample) I won’t bother with trying to fuzzy-match titles?

Then next step is to identify which of these reprinted works are multi-reprints of the same work, which will require some kind of fuzzy title matching... unless it’s small enough for me to do manually (unlikely)  

First, I make sure the data is “clean” and comparable to all the others:

\- Jan 1 1789 to Dec 31 1799

\- ENGLAND ONLY, no Ireland or Scotland

\- With ECCO, make sure I don’t have duplicate entries



I get a count of how many titles are in the corpus.



I use [random.org](http://random.org) to get 100 randomly-generated numbers. I use the “sequence” generator, not the “integer” generator.  

Compare most-reprinted texts overall to inclusions in smaller archives



ESTC

ECCO

ECCO-TCP



HathiTrust

ProQuest

BL 19thC



END?

WWO+Chawton combo?



Gutenberg

Book Tracker



Google Books??

Internet Archive?  

Take a random sample for which I attempt to locate size of print run



Radcliffe doesn’t need many editions because her print runs started out large --- take a random sample and see if I can find print runs for the works

Compare the popularity order produced by raw edition count to the one normalized by print run --- what’s the error rate?



Ask Tom how to find these numbers (it’s not in databases, but I can read a paper book! --- This is one of the things that makes my methodology not 100% DH)  

Computationally identify reprints in ECCO

Come up with a number that would be a "lot" of reprints vs "not a lot" (to gauge popularity generally)

How old were books, usually? (i.e., how long ago was their first edition)  

Paine vs Wordsworth vs Blake? (Vs CSmith and Radcliffe?) How to accord importance to these writers is at the heart of much of this project.  

Any cool “1790s lit” not written in the 1790s? Shakespeare? Goldsmith?  

Develop some kind of ontology of topic that encompasses "everything" (sticking to 18thC frameworks of, e.g., history vs romance)  

I turn to topic modelling as a way to move “laterally”: if I can only query attributes which every archive records, I can’t query anything at all.  

Take a random sample to see how accurate titles are to contents overall  

Count how many works of each topic appear in each archive -- what kinds of content has been excluded in each, esp. in ECCO-TCP  

Make my own guesses as to what the print landscape was like, and what this means (close-read something interesting that emerges, perhaps works that misrepresent their contents)  

Which of these archives are the most "reliable", and which the most "distorted"? (obvs interrogate this framework)

* What’s *in* all these, anyway?
    * What does ECCO-TCP leave out compared to ECCO? Compared to ESTC? (Can I come up with adjustment factors?)
    * How do digital vs physical holdings compare?  

What is a "normal" footprint in the print culture of this decade? (i.e., what are the boundaries a work has to surpass to be unusually popular or unusually unpopular?)



## 1.3.  ch 3 - archive popularity ##  

Chapter three expands upon the findings of the experiment carried out in chapter two, to examine popularity as it manifests in print culture. Influenced by Lesser and Farmer’s articulation of “structures of popularity,” I will consider popularity[ TK: Another tricky one. Might be best to avoid “popularity” unless you’re also going to factor in (as would be very hard) questions like print-runs (a nightmare imponderable), circulation (something aimed at libraries might have many more readers per copy than a book for home), unauthorized newspaper serializations, anthologization (is that a word?), false title pages (where a self-proclaimed 2^nd^ or 10^th^ edition might actually be just a new tp on remaindered sheets of a first edn that hasn’t sold. You could imagine (and this may have happened in practice) a novel published just once in 2,000 copies being more popular than one claiming five editions, none of which may have been more than 500 copies, and some of which may not have been true new editions at all. But which would come up as more popular give your metrics? This is all really tricky stuff and I think you’ll need a thorough discussion of the issues and assumptions.] in terms of total number of editions, frequency of reprinting, and market share.[ Lesser and Farmer also include profitability as one of the four measurements relevant to popularity in the book trade, but profitability is beyond the current scope of this project.] After determining how to calculate each of these metrics, I will ask: what was most popular during the decade, according to my corpora? How do the corpora differ in their answers, and why? I am particularly curious to see the place that chapbooks and religious tracts have in each corpus. My preliminary research suggests that many of the most reprinted works will substantially pre-date the 1790s in their composition. Accordingly, taking up David Brewer’s challenge to account for the increased “footprint” of some texts beyond the moment of their original publication, I will also pay attention to works originally written before the 1790s which nonetheless can be considered important “1790s literature” due to prominent reprinting. This inquiry’s first question is one of discovery: what works resurface in the 1790s? Its next question is one of close-reading and historical context: what makes them seem newly relevant? Restricting my inquiry only to the 1790s rather than nineteenth-century legacies, I will use my corpora to compare the publication output of various literary celebrities over the course of the decade. In addition to looking at the raw publication counts in the corpora defined in chapter two, I am currently exploring ways to use mentions in reviews and news articles to track prominence and reputation. The chapter as a whole, then, presents a sustained study of the relative popularity of the most prominent works printed during the 1790s, and seeks to answer how these prominent works might affect what we define as “popular literature”.  

The Reading Experience Database contains over 30,000 searchable records documenting the history of reading in Britain from 1450 to 1945. Evidence comes from published and unpublished sources such as diaries, commonplace books, memoirs, sociological surveys, and criminal court and prison records.



Combine with **Novels Reviewed Database**



Also <https://vls.english.qmul.ac.uk/> Dissenting Libraries Online

To find out more about the reading habits of individual borrowers, click on [**Browse borrowers**](http://vls.english.qmul.ac.uk/cgi-bin/koha/member.pl). Explore the borrowing records of tutors, such as the Baptist [**Frederick W. Gotch**](http://vls.english.qmul.ac.uk/cgi-bin/koha/readingrec.pl?borrowernumber=86), ministerial students, including [**Robert Cotton Mather**](http://vls.english.qmul.ac.uk/cgi-bin/koha/readingrec.pl?borrowernumber=502) (later a Congregational missionary), and their lay counterparts, such as [**William Rayner Wood**](http://vls.english.qmul.ac.uk/cgi-bin/koha/readingrec.pl?borrowernumber=198) (who became a prominent Unitarian businessman). 

The most frequently borrowed books include periodicals, theological textbooks, and historical works. Click on the links to see lists of the most popular titles at [**Manchester College**](http://vls.english.qmul.ac.uk/cgi-bin/koha/loansearch.pl?branchcode=MAN&groupby=book&order=loancountdesc), [**Homerton Academy**](http://vls.english.qmul.ac.uk/cgi-bin/koha/loansearch.pl?branchcode=HOM&groupby=book&order=loancountdesc), or [**Bristol Baptist Academy**](http://vls.english.qmul.ac.uk/cgi-bin/koha/loansearch.pl?branchcode=BRI&groupby=book&order=loancountdesc).



## 1.4.  ch 4 - networks ##  

Chapter four introduces my second major experiment, a mapping of the social world of print production 1789-99. As in chapter two, it will be a substantial technical and research project simply to recover contemporary printing practices; this time, rather than asking what was printed, I will ask who it was printed by. A great deal of scholarly work[ TK: Jon Mee, Kevin Gilmartin and Paul Keen are others who would be important here. Plus scholars who focus more on conservatism, perhaps M. O. Grenby for example? Or even much earlier work by Marilyn Butler?] already exists on printing circles, coterie publishing, and individual publishing houses.[^cf19] My project will consult this scholarship to extract and encode connections between authors, printers, and publishers (but not patrons, readers, or other persons not immediately involved in the production of texts) in order to synthesize the implicit social networks underlying 1790s print production. I will begin my research for this chapter by encoding only a few existing studies, in order to evaluate the feasibility of my method at scale. It is possible that, rather than directly consulting the more richly historically-informed work of other scholars, I will instead fall back on inferring networks from the author and publisher metadata included with the corpora examined in chapters two and three. The resulting chapter will explain my methodology and its assumptions, and will provide a rich description of my resulting network graph. The graph I create may reveal one large interconnected network, or several separate networks of varying sizes; these networks may consist of highly distinct clusters, or evenly interconnected webs. Drawing on mathematical graph theory, the chapter will explain the implications of whichever shape the network ultimately displays. It will also present an overview of the people I identify as the “major players” in the publishing world of the 1790s, both mathematically (looking for nodes with various kinds of centrality) and in the scholarship.  

OBVIOUSLY this work should be built on the back of the British Book Trade Index, I can’t BELIEVE nobody told me about it!!



<http://bbti.bodleian.ox.ac.uk/#>

<https://www.nls.uk/catalogues/scottish-book-trade-index>



## 1.5.  ch 5 - networks popularity ##  

Having recaptured these complex networks in some depth, I can then examine them, in chapter five, for their relation to our current understanding of mainstream and radical --- or as I am terming them “mainstream” and “non-mainstream” --- printing circles. My network graphs will model individual political affiliation as a complex, socially defined practice rather than a taxonomy of concrete and unchanging ideological stances.[ TK: Excellent point, especially in these fast-changing years. But again, this looks like potentially very daunting. Stable binaries are so much more convenient for scholars to work with! I’m excited to see what you come up with here.] This chapter will look for traces of affiliation in the print practices of publishers and of authors. I will consider individual printers with political allegiances, as in Dissenting societies, radical publishers, correspondence societies. This will then enable me to consider authors’ strategic choices as they publish with different printers[ TK: Again presumably you mean publishers not printers? NB too that the choice could work the other way round: authors for hire being commissioned by publishers to write something suitable for a list. I don’t know much about the Minerva Press, but I imagine that’s the way this kind of publisher would have operated, at least in part.]. Having identified radical elements in the publishing world, I will interrogate the radicals’ claims to marginalization. I suspect that I might find that they were not as socially estranged from the mainstream as they describe themselves, and that their printed works may accordingly have been less marginal. I will discuss alternative print markets and alternative circulation, and what kind of “alternatives” they offer to the mainstream. The circulation of works in manuscript presents me two challenges which will be discussed here. The first challenge is methodological: the circulation of manuscripts clearly occurred, and may have constituted “publication” within social circles, but manuscripts fall outside my purview[ TK: Yes, goodness, yes! You can deal with this via a brief discussion of recent scholarship on the persistence of manuscript culture and association practices e.g. Betty Schellenberg, Aileen Douglas, Michelle Levy, I would have thought.]. This chapter will therefore discuss the nature and rough shape of the gap which the exclusion of manuscript works leaves in my study. The second task of this chapter is more theoretical: as queer and decolonial DH scholars note, there is an ethical choice implicated in the decision to systematically discover, collect, and expose communities which intentionally operated below the notice of state observation. Historical distance prevents me from worrying about causing direct harm through my work, but nonetheless I will critically interrogate my own research practices and contextualize my choices within the horizon of expectations of the radical circles I (and other scholars) expose. Finally, having discussed the networks of radical and mainstream publishing in the 1790s, I will also compare the position of radical publishers in the 1790s with their status in the corpora discussed in chapters two and three (where they may in fact be marginalized; I expect to find conservative works overrepresented in the corpora). Together, these approaches will further complicate the story of popularity which the dissertation challenges elsewhere, by suggesting ways to reassess of the popularity of radical works.  

A potential coda or afterword could build on the work of Robert Miles and others to describe the role of the Gothic as a trans-generic mode which can appear across all print production (assuming that turns out to be true, of course.) Some of my earlier work suggests that Gothic modes of writing, unlike most literary content, can be “spotted” computationally. Since the Gothic operates by means of distinctive tropes and sensory appeals, the Gothic parts of a history and the Gothic parts of a picaresque can be distinguished from the non-Gothic parts of each by computational methods that could not distinguish a history from a picaresque. (Importantly, stylometric methods are not able to distinguish a parody of the Gothic from a “real” Gothic; as I theorize and interpret my findings, then, I would take up Horner and Zlosnik’s work on Gothic humour to discuss the problem of parody in taxonomy.) This final section could use a stylometric approach to identify and then search for “Gothic vocabularies” in full texts, computationally, in order to quantify the reach of the Gothic across my corpora. How many works can be identified as having Gothic influences? What kinds of literary production are most resistant to the Gothic? Does the Gothic appear differently in mainstream vs radical presses? This afterword would sketch out a preliminary map of the Gothic in the print world of the 1790s. This closing section would thus cite and build upon my prior work with the Gothic, in the context of the 1790s as a period when the penetration of Gothic modes into mainstream print had particularly complex political stakes.  

But wait, I want to use LaTeX or some other citation manager for this.

Command-shift-C will call up the Papers citation tool.

\\cite\{Scheuermann:2001tc\}

How can I use this to cite specific page numbers?

[^cf1]: TODO: footnote a couple examples of these.

[^cf2]: TODO: footnote a couple examples of these

[^cf3]: Indeed, Buurma notes, “There are good reasons, of course, that scholars and journalists like to begin with Busa: he was the first concordance-maker to automate all five stages of the process, in 1951,” and he intentionally foregrounded and publicized the innovative nature of his work. \\cite\{Buurma:2018wt\}

[^cf4]: In the interest of preserving this history of citation, the students were Mary Jackman and Helen S. Agoa, credited on the cover of the published Dryden index. (Miles herself attached her name only to the preface.) From the computer lab staff, Miles particularly thanked Shirley Rice, Odette Carothers, and Penny Gee.

[^cf5]: Jockers typically uses the term ‘macroanalysis’ to refer to his work, which is closely ties to Moretti’s distant reading, as in, for example, his monograph *Macroanalysis: Digital Methods and Literary History*  \\cite\{Jockers:2013uc\}.

[^cf6]: It may also be the case, of course, that even fields with a long history of graphical display would benefit from greater scrutiny of the evidence they use; see: the Data Dinosaur. But this is beyond the remit of what an English PhD can address.

[^cf7]: I cite Tufte and Cairo as the thinkers whose design philosophies best accord with my own current understanding of the work and craft of persuasive data visualization, but my actual practical training as a graphic designer is indebted to Judith Galas, Sonia Davis Gutiérrez, and Tom Hapgood.

[^cf8]: Tufte is careful not to blame the engineers for being better at engineering and systems analysis than they were at design: rather, this example shows that design is a skill that involves expertise; when designs matter, people with that expertise need to be involved.

[^cf9]: 1. show comparisons, contrasts, differences 2. show causality, mechanism, explanation, systemic structure (intervention relies on manipulable causality -- can't do anything with the information without causality) 3. show multiple variables (3 or more) -- the world is multivariate 4. \*completely integrate\* words, numbers, maps, graphics, etc, etc. Provide information at exact point of need 5. documentation must thoroughly describe evidence and its sources, provide complete measurement scales 6. presentations succeed based on their content. for better presentations, get better content.

[^cf10]: Although these events, of course, did not occur on January 1 or December 31, respectively, the entirety of 1789 and 1799 are both included in my study here, out of sheer technological necessity.

[^cf11]: By this, Mee means “both attacks on personalities by the radical press but also the development of personae by writers and booksellers” \\cite\{Mee:2016wk p.29\}.

[^cf12]: I have heard it quipped more than once in digital humanities gatherings that you always think you’re going to get your texts from somewhere else, but Project Gutenberg is where you’ll actually get them.

[^cf13]: https://books.google.ca/intl/en/googlebooks/partners/

[^cf14]: CITE http://languagelog.ldc.upenn.edu/nll/?p=1701

[^cf15]: https://archive.org/about/

[^cf16]: As a recurrent Freudian slip, I have more than once typo’d the word “data” as “danger”

[^cf17]: For example, a typical title in the English Short Title Catalogue for the decade is “The injustice and impolicy of the slave-trade, and of the slavery of the Africans: illustrated in a sermon preached before the Connecticut Society for the Promotion of Freedom, and for the Relief of Persons Unlawfully Holden in Bondage, at their annual meeting in New-Haven, September 15, 1791. / By Jonathan Edwards, D.D. Pastor of a church in New-Haven. ; To which is added, A short sketch of the evidence for the abolition of the slave-trade, delivered before a committee of the British House of Commons.” The usefulness of this title, as an advertisement for (if not necessarily an accurate representative of!) the work’s content, I argue, presents an opportunity unique to the eighteenth century. The eighteenth century is often dismissed as unsuitable for computational distant reading because eighteenth century printed type produces very low-quality OCR transcripts --- but a focus on OCR-based distant reading itself seems to me like a response to the poverty of paratextual material in later literature.

[^cf18]: I begin my research for this chapter by encoding only a few existing studies, in order to evaluate the feasibility of my method at scale. It is possible that, rather than directly consulting the more richly historically-informed work of other scholars, I will instead fall back on inferring networks from the author and publisher metadata included with the corpora examined in chapters two and three

[^cf19]: Per Terry’s suggestions, I would likely begin here with Jon Klancher, The Making of English Reading Audiences, 1790-1832; Marcus Wood, Radical Satire and Print Culture, 1790-1822; and David Worrall, Radical Culture: Discourse, Resistance, and Surveillance, 1790-1820. Other promising titles include Social networks in the long eighteenth century : clubs, literary salons, textual coteries, ed. Ileana Baird; and The enlightenment & the book : Scottish authors & their publishers in eighteenth-century Britain, Ireland & America, by Richard B. Sher, to capture different parts of the publishing landscape.