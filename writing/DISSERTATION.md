Title: DISSERTATION  
Author: Lawrence Evalyn

# ch 1 - intro #



## Intro ##



### intro to overall argument ###



This dissertation seeks to determine, in as minute detail as possible, what the print landscape in England 1789-99 was actually like. It also seeks to explain, in equally minute detail, why this task of historical recovery is, in fact, impossible. [FLESH OUT MY ACTUAL ARGUMENT AND TOPIC]



### many definitions of DH ###



The field of “digital humanities,” now several scholarly generations into its development, has entered the phase in which so many scholars are carrying out “DH” research that no universally-acceptable definition of “DH” can exist. Many definitions are fundamentally methodological. [ADD A COUPLE DEFINITIONS OF DH HERE]. These definitions describe what might be called a “computational humanities.” Other definitions take up the new importance of digitality in daily life. [ADD SOME DIGITAL CULTURAL STUDIES STYLE DEFINITIONS HERE]. This kind of work is increasingly described as “digital cultural studies.” In positioning this work as a “DH” dissertation, I might at first glance seem to belong squarely within the “computational humanities.” To be sure, much of this work is intended to apply existing computational methodologies to conduct otherwise old-fashioned literary research. Several of my contributions, too, are purely methodological in nature, in the development of new code and new guidelines for computational research using particular digital resources. However, as a fuller discussion of Johanna Drucker’s distinction between “data” and “capta” will elucidate later in this chapter, no computational research exists separately from a specific, local, culturally-defined context. Accordingly, my computational research into eighteenth century literature and my development of new computational methodologies are both inevitably tied to “digital culture.” My results often have more to say about contemporary digital archives, and the history of literary record-keeping, than they do about the eighteenth century itself. I therefore rely on an extensive body of work in cultural digital studies to examine not only the eighteenth century, but eighteenth century studies.



### many histories of 1790s ###



So, too, are there many “histories” — or perhaps, narratives — available to describe the 1790s. [FOCUS ON POLITICS]. [FOCUS ON ROMANTICISM]. [FOCUS ON GOTHIC]. [RISE OF THE NOVEL] Of necessity, each of these histories must exclude something. [WHAT EACH EXCLUDES].



### reparative reading ###



It is difficult, when faced with flawed and complex competing narratives, to resist the impulse to simply critique and reject all options. If we may learn any lessons from the 1790s, however, surely one must be the danger of universal paranoia. Eve Sedgwick persuasively describes, in “Paranoid Reading and Reparative Reading,” the dominance of paranoia in literary criticism \cite{Sedgwick:2015up}. Rita Felski, in her article “After Suspicion” and then further in her recent monograph The Limits of Critique, continues in Sedgwick’s line. Felski asks: “Can we be postcritical — as distinct from uncritical?” \cite{Felski:z11z1lQx p.151}. Reparative readers are often critiqued for painting a much clearer picture of the paranoid mode than the reparative mode, leaving it unclear how one is meant to escape paranoia’s double-bind. But this is not to say that the attempt itself is unworthy. [CONCLUSION HERE - DH somehow?]. 



### BLUF ###



These, then, are the three scholarly conversations to which this dissertation contributes: the digital humanities, as an increasingly self-reflective set of practices; eighteenth century studies, and the challenges presented by the 1790s; and the theoretical frameworks within queer theory which seem to offer valuable resources for both. The remainder of this chapter will describe in more detail the relevant scholarship in all three fields, then discuss the overlaps between them which enable my work. Finally, this chapter will conclude with a description of the two experiments which drive the dissertation as a whole, situating them within the three fields, and providing a sketch of their development across the dissertation.



## DH ##



### many histories of DH ###



When telling a history of “DH,” one has many histories to choose from, all freighted with different implications for contemporary practice. [TRADITIONAL HISTORY OF DH]. [FEMINIST HISTORY OF DH.] As these competing historiographies show, much more is at stake than mere description, when certain methodologies are named as “digital humanities.” [CONCLUSION TO THIS PARAGRAPH.]



### code is not neutral ###



The central contention of my computational praxis is that, despite the aura of empirical truth which accrues to some ‘scientific’ methodologies and discourses, nothing is neutral/objective. As Johanna Drucker argues, “data” is not neutral/objective. As Sophia Noble and Wendy Chun demonstrate, algorithms are not neutral/objective. As Alberto Cairo shows, graphs and charts are not neutral/objective. [PUT THESE IN ORDER ACCORDING TO FOLLOWING PARAGRAPHS] Each of these is constructed, by humans, for human purposes, constrained by human biases. As the humanities have long known, of course, things need not be neutral/objective to be meaningful or valuable. By setting aside the desire for a singular neutral/objective truth, we can instead draw quite close to the messy multitudes of truths which enable insight. Accordingly, [CONCLUSION].



### my methods ###



This dissertation will, nonetheless, make use of algorithms, “data”, and data visualizations to carry out its inquiry. At every possible point, however, the underlying methodology will be made visible, and its assumptions scrutinized. Much of the code underlying this project I have written myself. Some has been written at my request. In every case where the code is available to me, the program itself appears in Appendix A (“Codebase”), accompanied by a plain-language explanation of how it operates. Where I have used closed-source software, Appendix A contains an explanation of my best guess at its underlying process. My exact use of these tools — sufficient for another to replicate my work — is provided in Appendix B (“Methodology”). These details are explicated in full in the appendices in order not to over-burden the body of the dissertation, but they are by no means confined to the appendices. Computation is not a “black box” to be consulted for simple answers, but an inextricable from my reasoning and argument.



### capta ###



My attention to the sources of digital knowledge creation comes from Johanna Drucker, and her distinction between “data” and “capta.” Drucker, in “Humanities Approaches to Graphical Display,” specifically addresses the digital humanities practice of creating, and then close-reading, data visualizations. She argues that the tools for visual representation which may be effective in the sciences cannot be simply and uncritically transposed to humanistic subject matter. When an experiment is presented as a ‘data visualization,’ she says, “the rendering of statistical information into graphical form gives it a simplicity and legibility that hides every aspect of the original interpretative framework” (8). In fields where the readers of such charts are also frequent creators of charts, and where norms exist to explicitly describe one’s interpretive frameworks in a methodology section, the simplicity and legibility of an individual chart may be a benefit which does not impede complex scrutiny of the information it presents.[^cf1] In a field like literature, however, the “graphical force” of something like a network graph or even a simple pie chart “conceals what the statistician knows very well — that no ‘data’ preexist their parameterization” (8). Drucker problematizes the term “data,” the etymology of which presents it as a “given” which is stable and independent of observation. She proposes that humanities visualizations embrace, instead, the framework of “capta,” that which is “‘taken’ actively” (3), “fundamentally codependent, constituted relationally, between observer and observed phenomena” (50). Drucker’s assessment shapes my own prioritization of qualitative and reflective computational research. The term “capta” itself has not seen uptake in subsequent digital humanities scholarship, even in cases where scholars explicitly take Drucker’s warnings to heart. Accordingly, for clarity, this dissertation will continue to use the more usual term “data” to refer to the information gathered for analysis here. However, as I integrate and compare a wide variety of data from many disparate sources, a preliminary task of my analysis is always to determine, as precisely as possible, how the information was captured and quantified. 



### data viz ###



Additionally, all of the figures presented in this dissertation are of my own design. My design vocabulary is drawn from the work of Edward Tufte and Alberto Cairo, both of whom provide practical design advice in service of demystifying the visual rhetoric by which graphs present their arguments. Neither Tufte nor Cairo is a scholar of media studies; rather, they are professional practitioners of ‘data visualization’ who reflect critically on the assumptions of their work. Tufte’s work primarily strives to correct badly-designed data visualizations, and the dangerous decisions that bad design can lead people to. His most famous example is an analysis of the scientists’ report at NASA which led to the ill-fated launch of the Challenger space shuttle in 1986: as his extensive visual analysis argues, the scientists (untrained in graphic design) unintentionally obfuscated crucial information about the day’s launch conditions. Tufte’s six principles of design[^cf2] primarily seek to guide undertrained designers away from misleading themselves. Cairo, following on Tufte’s work from the perspective of a data scientist rather than a pure designer, more often turns his attention to successful designs which mislead their audiences intentionally. [MORE ON CAIRO] Following in both Tufte and Cairo’s footsteps, I conceive of the figures throughout this dissertation as rhetorical devices. In service of arguing honestly, therefore, my designs are accompanied by explanations of my design rationale.



### critical algorithm studies ###



My emphasis on transparent, critical, and reflective praxis in the capture and visual presentation of data[^cf3] owes much to the emerging field of critical algorithm studies. Any methodology is, to a certain extent, an “algorithm,” in the loose definition of ‘a series of pre-defined steps to be carried out’. But computational algorithms [ARE IMPORTANTLY DIFFERENT FROM] “algorithms” implemented by humans The emerging field of critical algorithm studies thus responds to an urgent need. [Extended summary of Safiya Noble]. [Write about Wendy Chun too] [EXAMPLE ALGORITHM FROM MY MATERIALS] [Conclusion: I am indebted to the ‘digital cultural studies’ scholars for giving me tools/lenses for my work….?]



### procedural argument ###



An additional and perhaps-unexpected resource, for scrutinizing algorithms critically, comes from the work of those who study games, especially video games. [Ian Bogost argues that procedures contain arguments.] This framework allows us to see that all research methodologies, including non-digital ones, contain implicit arguments about the nature of what is studied. [EXAMPLE PROCEDURE FROM MY MATERIALS - something non-computational?] 



### fruitful models/samples ###



In light of the challenges of “empiricism,” my goal in this dissertation is to produce a series of fruitful models. [Willard McCarty’s descriptive work on the concept of modelling VERBS modelling’s processes of abstraction. ][QUOTES FROM McCARTY] Another way of expressing this might be to borrow from the vocabulary of social science research: I would like to make discoveries about a “population” which is inaccessible to me, namely, “everything printed in England 1789-99.” Since I cannot access this population in full, I have taken a series of “samples,” which I hope to be representative; each sample can be examined as evidence of the makeup of the source population, but must also be examined in and of itself as a sample. [therefore, not attempting ‘accuracy’] [Rather than making claims about the 1790s each claim is filtered through / constrained by the specific model of the 1790s used to make it] Rather than producing a clear and pristine truth, my models are, in fact, quite likely to contradict each other. In these moments of contradiction, [we have the best opportunity to learn, because we can see why they contradict, and therefore why something may or may not be true.] [These opportunity are “fruitful”] [Expand on “fruitfulness”]



## 1790s ##



### English history ###



All of these [capta, samples, algorithms, models, and self-reflective methodologies — match preceding section] do have an aim beyond themselves: to recapture, in as minute detail as possible, the print landscape in England between January 1 1789 and December 31 1799. This eleven-year “decade” was a turbulent one across the Channel, encompassing the whole of the French Revolution, from the Estates General in 1789 to Napoleon’s coup in 1799.[^cf4] In England, [HISTORY OF THE KEY EVENTS OF THIS DECADE IN ENGLAND]. [CONCLUSION: an environment which felt like it was on the edge of history]



### superlatives ###



The [world of letters? Public sphere? What do I call it?] in England responded to these events by [writing WAY TOO MUCH]. This is the decade of Common Sense, it is the decade of Lyrical Ballads; it is the decade of Hannah More, it is the decade of Ann Radcliffe; it was the age of wisdom, it was the age of foolishness; it was the epoch of belief, it was the epoch of incredulity. Charles Dickens’ now-famous superlative degree of comparison captures the tension between empiricist or otherwise political thinkers and Romantic or Gothic artists as contemporary literary scholars grapple with these modes. Each literary ‘mode’ was imbued with the potential for national importance. [WRITE ABOUT IMPORTANCE OF READING/WRITING TO NATIONAL IDENTITY —> CONCLUSION.]



### canons ###



Not coincidentally, the 1790s are also a decade in which some literary “canons” begin to take form. John Guillory contends that the “canon debate” taking place during his moment of writing in 1993 “signifies nothing less than a crisis in the form of cultural capital we call ‘literature’” \cite{Guillory:1993uc p.viii}; the roots of this crisis lie two hundred years earlier, in the eighteenth century formation of a vernacular (rather than classical) literary canon, and in the 1790s “first crisis” (\cite{Guillory:1993uc p.xi} of that canon. Guillory turns particularly to Wordsworth and Coleridge, and the strategies by which they confer a high status on their own work by undermining the cultural capital of other forms. Wordsworth, Coleridge, and the other ‘big six’ Romantics are surely the winners of the eighteenth century historical battle for cultural capital; just as surely, the loser has been the Gothic. E.J. Clery’s The Rise of Supernatural Fiction, 1762-1800 provides an account of what was at stake for the representations of supernatural events in supernatural stories in fiction, drama, and popular news \cite{Clery:HFvEup7z}. The “rise” she describes is not an increase in volume and prominence of supernatural stories, since her starting point in 1762 (the Cock Lane ghost) is a major national phenomenon with many imitators. Rather, supernatural fiction ‘rises’ when it acquires cultural legitimacy. Michael Gamer has more recently expanded on how this ‘rise’ fuelled romanticism’s own rise \cite{Gamer:jX8nTxB-}. In Romanticism and the Gothic: Genre, Reception, and Canon Formation, he details  the interconnectednesss of what are now seen as the separate categories of ‘high’ Romantic literature and ‘low,’ popular Gothic writing. By using Gothic materials in self-avowedly non-Gothic ways, Gamer argues, Romantic writers could appeal to popular taste without risking the loss of cultural capital which attended the Gothic’s “popularity”. Gamer, like Guillory, primarily uses Wordsworth and the ‘winners’ of the struggle for cultural capital: I, like Clery, am more interested in the ‘losers.’ Accordingly, I attend to much that is not literature, in order to better understand why it is not.



#### rise of the novel? ####



### more similar than different ###



All of these schools of writing are, I argue, more similar than they are distinct, in the print marketplace of the 1790s. Which is to say, all of these individual writers are choosing strategies from the same pool of constrained choices. [Gothic strategies - Gamer] [Corresponding society strategies] [Poetic strategies - Mary Robinson] [Hannah More] [CONCLUSION: have to deal with everything at once; individuals, variety]



#### John Mee's book ####



John Mee silently defines “print, publicity, and popular radicalism” as being synonymous with the activities of the London Corresponding Society, and societies like it. These societies and their use of print are obviously crucial parts of the print landscape, reflecting one [take on] publicity, but I seek to go broader.



#### "schools of thought" ####



my own understanding of eighteenth century politics as “schools of thought” governed by memetic natural selection.

Because politics occurs between individual people, not political parties, I argue that political affiliation, like literary genre, is not amenable to simple taxonomic classification.



### conclusion ###



My synthesizing approach [SAYS SOMETHING THAT WRITING PREVIOUS PARAS WILL CLARIFY]



## theory ##



### reparative reading ###



On the broadest level, my primary theoretical framework is that of reparative reading. I understand reparative reading to mean [DEFINITION OF REPARATIVE READING]. Others have worked to carry out scholarship in this mode, including [OTHER REPARATIVE READERS]. [Felski’s neophenomenology in Everyday Aesthetics]   [SUMMARIZE THE MAIN THREADS / CATEGORIES OF THEIR WORK.] [WHY I VALUE REPARATIVE READING (INDEPENDENT OF DH & 1790s)].



### queer theory ###



Implicit in my prioritization of reparative reading is an affinity for queer theory more broadly. I take it as read, for example, that history consists of major discontinuities in cultural ontology and identity, as Foucault describes. I follow Judith Butler in understanding these historically-framed identities as being “performative,” actively re-created in conversation between self and others. [(In my understanding of performative identity creation I also borrow from J.L. Austin, who is not typically understood as a ‘queer theorist,’ but who contributes an invaluable articulation that [WORDS DO THINGS].)] [This queer-theory foundation shapes my approach to literature as an encounter with an ‘other’, which, as Rita Felski says, [FELSKI HAS SOMETHING ON THIS]] [CONCLUSION.]



### surface reading ###



My search for other ways of relating to literature has also led me to emerging work under the umbrella of “surface reading”. “Surface reading” positions itself as an alternative to “symptomatic reading”; [RATHER THAN X, IT Y.] The analogues to reparative and paranoid reading are obvious, but also, I argue, overly simplistic: all paranoid reading is symptomatic, but not all symptomatic reading is paranoid. Reparative reading, as described by Sedgwick and potentially modelled by Felski, is still interested in ‘deep’ meanings of texts, in which striking textual features can be interpreted to locate additional meanings. [A LOT OF QUEER THEORY IS ALSO SYMPTOMATIC, EVEN WHEN IT’S NOT PARANOID (AND TBH IT’S OFTEN PARANOID).] In contrast, “surface reading” [DOES SOMETHING ELSE.] [GIVE EXAMPLES OF SURFACE READINGS.] [GROUP/CATEGORIZE SURFACE READINGS.] [CONCLUSION]



### conclusion ###



Surface reading and reparative meaning are not synonymous modes: Felski, at the forefront of reparative reading, explicitly distances herself from surface reading “I have no quarrel with interpretation, even though I favor description; nor am I drawn to a language of textual surfaces over depths” (CITE).



Talk to Dana Seitler about the distinctions between surface reading and reparative reading

History of queer theory: Oscillations of Literary Theory, AC Fecundo



Reparative reading rejects paranoia & the role of the critic as master

	Felski rejects negativity? & role of critic?

Queer reading rejects ?

Surface reading interpretation (?) — focus on taking the text at its word & examining all details equally



## synthesis of 3 fields ##



### we need Venn ###



Drawing together three scholarly conversations with three distinct histories, it is difficult to attentively delineate the links and the tensions between each thread. Especially since many of these fields have, in fact, overlapped substantially, there is a danger of simplistically conflating distinct lines of thoughts. At the same time, over-emphasis on distinctions can overstate the separations between fields which do in fact (as the existence of this dissertation contents) share important affinities. To navigate these conceptual overlaps carefully, let us make our way through each area of an imagined Venn diagram of the three. We can discuss each pair in turn — DH and eighteenth century studies; eighteenth century studies and queer theory; queer theory and DH — to make our way toward the centre where all three overlap.



### DH & 1790s ###



#### DH & bibliography ####



In the intersection of the digital humanities and eighteenth century studies, I turn to bibliography. If there is any research more magnificent in its scope than [SOME BIG DH THING], it is work like Garside & Raven’s The English Novel. This kind of work seeks to be both comprehensive and accurate. [DESCRIBE THE SIMILARITIES I SEE. — Resources for future research] [Now I’m going to survey the kinds of digital corpora and non-digital bibliographic resources that I focus on.]



#### scholarly archives ####



Eighteenth century materials of various kinds have been collected in many digital archives, of very different scope. These are discussed in more detail in Chapter 2. On the tip of anyone’s tongue, of course, is Gale’s Eighteenth Century Collections Online (ECCO), containing over 180,000 titles 1701-1800, of which 42,000 were printed in England between 1789 and 1799. ECCO is itself (mostly) a subset of the broader English Short Title Catalogue (ESTC), which contains more 460,000 texts 1473-1800, of which 51,965 were printed in England between 1789 and 1799 (indicating that nearly 10,000 in the decade titles appear in the ESTC but not ECCO). The ESTC does not provide access to texts themselves: instead, it is an authoritative bibliographic catalogue, available as a searchable database. It is ECCO which provides texts themselves: ECCO’s 180,000 titles works are available as photographed facsimiles of the full text of each title. The facsimiles can be searched within ECCO’s online interface; these searches examine a plaintext version of the facsimile pages that was generated by Optical Character Recognition (OCR), but this OCR text is not made directly available. As a result, the facsimiles may be read individually by scholars, but cannot form the basis for computational corpus analysis. A subset of ECCO’s texts have been hand-prepared, as part of the Text Creation Partnership (TCP), to be easier to use in computational research. The resulting corpus of ECCO-TCP texts contains 2,231 titles, of which 466 were printed in England between 1789 and 1799. These titles are available as carefully-edited texts encoded according to the Text Encoding Initiative (TEI) standard, which not only provides an accurate version of the text’s words, but encodes substantial details regarding its context on the page. Most large-scale distant reading of eighteenth century literature relies in the ECCO-TCP corpus as its ‘model’ or ‘sample’ to represent the period. Accordingly, one of the tasks of this dissertation is to precisely examine the makeup of thus corpus, and how it differs both from other corpora and from print culture in the period itself. These three digital collections — ECCO, ESTC, and ECCO-TCP — are the primary digital resources for the period, which form the basis of most digital research. However, they represent only one approach toward the collection and presentation of digital texts, to which there are two broad kinds of alternatives. These large but meticulous collections occupy a middle space between, on the one hand, highly selective thematic collections, of which there are many, and the giants of indiscriminate textual accumulation, of which there are few.



#### micro archives ####



Smaller collections seem more scholarly, but have some limitations.] Whereas the ‘main players’ can be easily enumerated for the mega-archives, these specialized collections are numerous. Some will focus on particular kinds of texts, such as the Early Novels Database (2,041 novels 1700-1799) or Broadside Ballads Online (more than 30,000 broadside ballads). Others exhaustively index particular publications, such as The Hampshire Chronicle, the Index to the Lady’s Magazine (1770 to 1818), or the Novels Reviewed Database (1,836 reviews from The Critical Review and The Monthly Review, 1790-1820). Feminist scholarship in particular has seen the creation of resources like the Orlando Project, the Chawton House library Novels Online, Northeastern University’s Women Writers Online and UC Davis’s British Women Romantic Poets. The virtue of these collections is that they achieve even greater accuracy and comprehensiveness within their defined scope. The Shelley-Godwin Archive, for example, can reasonably aspire to digitize every known manuscript of Percy Bysshe Shelley, Mary Wollstonecraft Shelley, William Godwin, and Mary Wollstonecraft, and to provide these manuscripts in hand-encoded plaintext transcripts.

However, as is inevitable, these specialized archives have the vices of their virtues: their specialized focus allows them to adapt precisely to their materials, and their idiosyncratic data structures can rarely be combined with other resources. The William Blake Archive, for example, benefits enormously from  [attention to images — but this isn’t a standard]. Similarly, Project Gutenberg makes no claims to scholarly reliability but nonetheless underlies a not-significant amount of scholarly work.[^cf5] Unlike Google Books, Project Gutenberg actually does have selection criteria: it is only interested in public domain works which contemporary audiences might be interested in reading for pleasure. It narrows the field substantially to exclude works which have either ceased to be broadly interesting (as in the case of most forgotten fiction), or which was never particularly interesting (as in the case of almanacs and tax codes). Project Gutenberg includes 57,796 texts: far more than specialized scholarly archives like the Early Novels Database or the Shelley-Godwin Archive, but nonetheless an order of magnitude fewer than its more-voracious potential competitors. And, like smaller specialized scholarly archives, Project Gutenberg has tailored its holdings to make it easy for readers to read, and quite difficult for its collection to be applied to any other use. By tailoring the structure of the archive itself to its specific materials, these collections [DO SOMETHING GOOD]. But they also [MAKE IT MORE DIFFICULT TO COMBINE THEM].



#### mega archives ####



The best known mega-archive is, of course, Google Books. In a scholarly context, one hesitates even to designate this as an “archive,” particularly in the same breath as resources like ECCO: books of all kinds are scanned indiscriminately with only the bare minimum of roughly-accurate metadata collected about them. Books are sourced from libraries whose collections are being scanned in bulk, or are submitted directly by publishers or authors who are attracted by Google’s call to “Promote your books on Google—for free” (CITE[^cf6]).   These rapidly-scanned books are prone to unpredictable errors, including inaccurate dates, misspellings, duplicate copies, and inaccurate subject classifications (Harper 2016; Jacsó 2008; Weiss 2016) (CITE Mike Sutton and Mark D. Griffiths) — infamously, many books have “1899” assigned as their publication date because this date was used as a placeholder for “no date”.[^cf7] Many photographed pages still include the fingers of the employee holding open the book. Nonetheless, Google Books is frequently used to study the prevalence of various “n-grams” (words or short phrases) over time, thanks to Google’s built-in tool. The tool is able to search books which are, for copyright restrictions, not available directly to readers, making it highly tempting for question about contemporary language use. Similar in scope to Google Books but with more limited research tools is The Internet Archive. The Internet Archive, unlike Google Books, is a non-profit, but like Google Books, it carries out mass scanning of books. The Internet Archive declares that it contains 20 million books and texts, and scans 1,000 books per day in 28 locations around the world (CITE).[^cf8] Equivalent numbers are not published for Google Books, which has received less attention from Google as it encountered more legal barriers; in 2013 books were scanned at the rate of 1,000 pages per hour, and in 2015 more than 25 million books had been scanned. Google Books, Project Gutenberg, and the Internet Archive are not “canonical” sources of texts, but they are nonetheless part of the ecosystem of digital eighteenth century studies.





#### HathiTrust ####



Moreover, as in eighteenth century texts themselves, the boundary between “canonical” and “noncanonical” digital archives is a permeable one: Google Books and the Internet Archive are also integrated into HathiTrust, [EXPLANATION OF HATHITRUST]. The scholarly benefit of HathiTrust is most evident in the study of contemporary literature. On a technical level, whereas OCR typically produces gibberish when faced with eighteenth century typefaces captured in photographs of microfiche, OCR is extremely effective at reading contemporary typefaces and direct high-resolution digital scans of books. The materials 



#### print archives ####



[But of course not everything is digital]. [It is a core contention of my work that DH can’t ignore non-digital resources]. [LIST AND CATEGORIZE MAJOR PRINT BIBLIOGRAPHIC RESOURCES].

Garside

William St Clair



#### scrutiny is not criticism ####



As I scrutinize the underlying assumptions that are structurally reinforced by this work, I do so not in order to dismiss their value. These resources are created to enable future scholarship: for that future scholarship to thrive, 



#### lit already models/samples ####



Literary study already involves modelling / sampling



#### conclusion: filling gaps ####



Thus, I see DH and bibliography as able to enhance each other reciprocally. 



### 1790s & queer ###



#### queer gothics ####



Queer readings of the 1790s — which is to say, of the Gothic — provide an invigorating way to value some of the most vibrant writing of the decade precisely for the features which rendered it less than “respectable.” [HISTORY OF QUEER GOTHIC STUDIES - Palmer I think, leading up to Franz Potter… this history is prob multiple paras] [A lot of really good Gothic work is connected thematically rather than strictly chronologically, examining the “transtemporal affinities and connections” (CITE) that Felski argues are often shut out by contemporary historicist critique. And indeed, this mode of study is falling out of favour regarding the Female Gothic.]



#### reparative gothic ####



[A lot of queer Gothic work has been paranoid] [Something about Susan Sontag & camp being how I reparatively read the Gothic?]



#### I'm not just gothic ####



Although the queerest work in this period has centred on the Gothic, I intentionally do not limit my focus to the Gothic. My broader scope is, in part, based in an argument about the Gothic’s prevalence: following scholars like [EXAMPLE], I see the Gothic not as a clearly-defined literary genre, but rather as an affective ‘mode’ that can (and did) permeate writing far beyond the realm of supernatural fiction. Accordingly, [although I am interested in the Gothic, I study everything.] [Also I’m not just interested in the gothic.]



### queer & DH ###



#### queer DH ####



[“Queer DH” is now a vibrant field in its own right.] [WRITE UP HISTORY / BROAD CATEGORIES OF QUEER DH RESEARCH] I draw on this work in my pursuit of less “extractive” and more anti-oppressive digital humanities methodologies.



#### reparative DH ####



[TALK ABOUT WHAT REPARATIVE DH METHODS LOOK LIKE, SOMEHOW] [Examples - TL Cowan, ]



By marrying “surface reading” and “distant reading” I may seem to leave “reparative reading” behind: after all, Felski’s call for postcritical analysis explicitly insists, “Sometimes serious thinking calls for a judicious decrease rather than and increase of distance” (CITE). Felski then defines a decrease of distance as “a willingness to acknowledge and more fully engage our attachments”: it is in this readiness to acknowledge and embrace the [DETAILS OF SOMETHING-SOMETHING]



#### surprise! ####



Thus far, the importance of queer theory to DH is evident. But what about the other direction? Just as, I argue, both DH and bibliography have important resources to offer to each other, so to do I argue that DH has something to offer queer theory. Specifically, a well-formulated DH praxis can introduce a new relationship to the experience of surprise which is so challenging in paranoid reading. The most common dismissals of DH research are attempts to say, “we already knew that” — essentially, [PARANOID AVOIDANCE OF UNPLEASANT SURPRISE FROM DH THREAT]. This reaction invites two responses. First, [if the experiment told us that everything we knew was COMPLETELY WRONG, this would not be very good because probably at least some of what we know is right]. [Experiments fall into two categories: those which tell us about our methods, and those which tell us about our fields of study]. Second, as scholars such as Ted Underwood have noted, it is often only retroactively that these discoveries are declared to be “obvious” results which everyone “already knew” (CITE). If we are asked to form an explicit hypothesis in advance, we might be very surprised by the exact numbers. [CONCLUSION]



### all together now! ###



#### CANONS ####



“overall, about how texts do or don't 'enter' a 'canon' of writings - by which you mean, as per e.g. Guillory or Bourdieu, and the idea of cultural capital, a set of texts studied, produced, valued (to varying degrees over time) within certain cultural fields, most especially the field of academic research (but also education, modern publishing, creative industries etc). And then your contribution to the many discussions that go on about (and indeed change) canon, is to bring show we can use digital tools to ask and answer that question? I think maybe it is, and if that is the case, then you need to say just that, and that the other issues - timelessness, popularity, marginalization, immediacy, fall out of that larger question”

(This can be a shorter section; write it after the rest?)



## upcoming 2 experiments ##



### overall goal ###



[Having delineated a large and complex scholarly context for this work, it is time, now, to describe [WHAT I ACTUALLY DID]] - save this for after all the rest, may not be necessary



### my 1790s ###



material printed in England between January 1, 1789 and December 31, 1799 (inclusive).



### experiment 1 ###



### experiment 2 ###



### chapter conclusion ###



# THE DISS #



## proposal intro ##



Print Politics in the Digital Archive, 1789–99



My dissertation seeks to determine, in as minute detail as possible, what the print landscape[ TK: Books only, or also serials, periodicals, newspapers, print ephemera (for the 1790s, there are a lot of things like handbills and broadsides in ECCO)? A fairly restrictive definition might be wise …  ] in England 1789-99 was actually like  — in contrast to the version that is presented in filtered and interpreted literary histories, built up by scholars or later generations of writers — and how this print landscape is represented now, in current digital archives[ TK: This will be very valuable, but of course you’re dealing here with a moving target and one subject to sudden transformations as well as gradual / incremental changes. Not sure what the solution is here but it’s something to thing about. Presumably you can’t make this chapter the last thing you do if you need the data for later chapters – or can you?]. My first chapter establishes the vocabulary and theoretical frameworks of the dissertation. Chapter two turns a critical eye on existing digital archives that feature material printed in the 1790s. Chapter three uses these corpora of 1790s literature to examine the idea of “popularity” as it is manifested by print culture. Chapter four introduces a second substantial experiment, a comprehensive mapping of the social networks underlying print production during the decade. Chapter five uses these networks to compare mainstream and non-mainstream printing practices[ TK: NB that you tend to use printing and publishing a bit too interchangeably. Presumably this one should be publishing practices? Print technologies are also changing in this era but that’s a whole different story, not part of yours I would imagine.]. A possible afterword or coda may discuss the role of the Gothic across the textual landscape.



## ch 2 - archives ##



Chapter two takes up contemporary digital archives directly, examining corpora of eighteenth-century literature through the same critical lens by which anthologies and classroom teaching are often scrutinized. It makes the case that digital archives can implicitly shape scholarly research, and begins the process of revealing and interrogating their invisible assumptions. The chapter begins with a task somewhere between a literature review and a scientific meta-analysis. My first goal will be to survey as broadly as possible the accessible mass holdings of eighteenth-century texts (all those containing at least 100 works from the 1790s): simply putting all of this information in one place will be a useful way to review it. Adding a discussion of each archive’s selection criteria will bring it into the realm of a meta-analysis. I expect to find systematic exclusions where archives are investing more labour in their holdings, with narrower selections as they move from bibliographic data to facsimiles to scholarly transcripts. To contextualize these decisions about inclusion, I will research the history of how each corpus was formed. I will discuss and theorize the difficulties involved in researching these histories: drawing on, for example, my experience with HathiTrust’s codebase, I will critique the assumption that digital resources make all information transparent and accessible. Returning to the actual contents of each archive, I will discuss the nature of their exclusions, and consider paths to greater inclusivity. Then I will synthesize these disparate sources of texts and metadata, a substantial technical challenge, to see how the task may be accomplished, and to see what correlations between archives might illuminate the decade. I am particularly curious whether even one text will appear in all corpora, and, if so, which one it will be. Whichever texts appear most persistently will form the basis of my “case study” in this chapter. The second chapter thus establishes the corpora which will drive my argument in chapter three, and will shape the later phases of my research in chapters four and five.



### intro ###



#### lit review ####



##### Lesser & Farmer debate #####



Do these citations with some kind of LaTeX to learn that process



A model for my work can be found in a methodological debate within the study of Early Modern drama, when Farmer & Lesser introduced revisions to Blayney’s field-changing 1997 essay “The Publication of Playbooks.”



Blayney believes that Lesser & Farmer attempt to disprove his “one inescapable fact about printed plays—namely, that they were not the best-selling moneyspinners that so many commentators have evidently believed they should have been” (7). But what really matters to him about identifying the “best-selling moneyspinners” of the day is not the ‘moneyspinning’ — the question of whether, when publisher bought a play, he was making a sound financial decision — but about the cultural centrality of ‘bestsellers’. The total market share of religious texts matters, not because it meant that publishers turned their highest profits off of religious texts, but because “[c]ustomers in early modern bookshops chose to spend far more of their money on religious books than they did on playbooks and other ‘literary’ publications,” evidence of “just how massively important godly books were to early modern readers” (7). Lesser and Farmer do not contradict the importance of religious texts to readers. But, in setting out “not merely to measure comparative popularity but also to explain why and how different kinds of books were published.” (F&L 213), they make the case that books with low market share, books that are not “best-selling,” could nonetheless be “moneyspinners.” Their rebuttal states that “...books could be in high demand even though their reprint rate was low. Likewise, books (such as ballads) could be in high demand even though their profitability per copy was low. And, as seems to have been the case with plays, books could be in high demand even though their market share was low” (F&L 213), but what they leave somewhat unstated is: “in high demand” with whom?



My own work seeks to examine reprints, but in a more limited fashion than Farmer & Lesser were able to do. Rather than determine the reprint rate of various kinds of fiction, I carry out a Blayney-style examination of pure market share. I seek to identify reprints in order to determine the market share of new versus reprinted material in any given year. 



##### How do people determine popularity? #####



	1.	(Reprinting) Simon Bainbridge: best-selling, most-reprinted, most-adapted

	2.	(Assertion) George Taylor: simply asserts that some things are popular

	3.	(Assertion) Peter Murphy: despite promising that his study “examines the tension between the material, economic pressures motivating poetry as an occupation, and traditional notions of the forces of literary history,” Murphy says NOTHING AT ALL about how well, to whom, for how much, etc etc things were sold.

	4.	(Performances) Emmet Kennedy, Marie-Laurence Netter, et al.: number of performances per play (Theatre, Opera, and Audience in Revolutionary Paris: Analysis and Repertory)

	5.	(Book history) Cronin: mostly asserts that people are “popular” or “celebrated”; with Erasmus Darwin, supports this by saying that the book The Botanic Garden is beautiful & expensive

	6.	(Editions, reprints, market share, profitability) Lesser & Farmer, Structures of Popularity in the Early Modern Book Trade - “we need to consider both total number of editions and frequency of reprinting, as well as market share and profitability. No single one of these four measurements by itself equates directly to popularity in the book trade; each addresses different questions about the market performance of books, and each points to a different aspect of both supply and demand.” (208)

	7.	(Market share) Blayney

	8.	(Title counts) MacLeod on the Minerva press — evaluates most popular authors & subgenres based on the number of “works published” or “titles” (unclear if this includes reprints)





##### popularity is actually impossible #####



It is not, in fact, possible to calculate 



Without [certain kinds of evidence], as F&L note, “we will never be able to ascertain precisely the “popularity” of various kinds of books… if by popularity we mean something like the modern best-seller lists” (F&L 16)

Would need size of print runs and cost to produce, as well as sale price, and quantity sold.

[So it’s a little nonsense when people just say that something is popular]



##### Numbers to compare to #####



Comedies vs tragedies performed: the ratio of comedies to tragedies performed was an astonishing 14 to 1 in Paris (Theatre, Opera, and Audience in Revolutionary Paris: Analysis and Repertory by Emmet Kennedy, Marie-Laurence Netter, James P. McGregor, and Mark V. Olsen)



#### corpora ####



##### selection criteria #####



The full scope of my project is to grapple with every online database which contains at least 100 texts meeting my criteria: printed, in England, between the years 1789-99. 

I exclude databases of diaries or correspondence, since they are not printed. This has the effect of excluding single-author databases.



###### women's archives ######



I make an exception for archives which specifically seek to address gaps in archival holdings due to systemic bias, that is, three archives focused on women’s writing: Orlando, Chawton, and [I thought there was a third one].

For the most part archives are either comprehensive and have significantly more than 100 texts, or they are single-author / single-researcher focused, and thus have significantly less than 100. These kinds of reparative projects occupy the middle space.



##### these are all databases #####



The primary methodological challenge to the questions I would like to pose is the standard makeup of these academic resources: self-contained databases, which are searchable for individual materials but not queryable for overall statistics. (I'd love to know the distribution-by-year of everything in the databases as a whole, but that may be beyond my scope.)



What I'm trying to do, essentially, is to forcibly "join" all of those databases -- the ESTC is my best bet so far, it looks like, for unique keys.

A true "standard" is probably both unfeasible and undesirable. So what can be usefully done with things that follow different standards? I think the answer might be OpenRefine, which I haven't seen extolled enough.

Another approach is to ignore the categories and use things like topic modelling; relies on a more intimate knowledge of the information being studies (i.e., humanities expertise)



##### so what? #####



These basic factual questions, about what is in the various eighteenth century digital corpora that represent “mass” 18thC holdings for scholars, matter because []. Even though the specific numbers are likely to change as these digital holdings are continuously updated, my investigation of an archive “snapshot” matters because [they show how questions of fact can (and cannot) be answered?]



##### Google Books #####



###### chooses to be bad ######



Google Books prioritizes low-quality information over no information. The algorithmic extraction of publication dates from title pages, for example, can never be perfect. But algorithms give their predictions with certainty estimates: if accuracy was a higher priority, Google Books could calibrate the algorithm to simply provide no answer when none of the possibilities cross a given certainty threshold.



Per http://languagelog.ldc.upenn.edu/nll/?p=1701 , they actually OVERWRITE metadata provided by partners with their algorithmic information!! They could very easily not.



#### demographics ####



##### titles per year #####



##### men vs women vs unsigned #####



Can I identify male/female ratios?



### reprints ###



#### methods ####



Before I develop custom code, I establish some baselines by taking a random sample of 100 titles from each of my key corpora. I manually identify the original publication date of each title, and whether that title appears reprinted elsewhere in the corpus.



As I expand to algorithmically examine the full corpora, I start with the simplest/dumbest way to identify a reprint: looking on its title page for the words “Xth edition.”

If this method achieves an accuracy of 85%+ (as determined by comparison to my random sample) I won’t bother with trying to fuzzy-match titles?

Then next step is to identify which of these reprinted works are multi-reprints of the same work, which will require some kind of fuzzy title matching… unless it’s small enough for me to do manually (unlikely)



##### taking samples #####



First, I make sure the data is “clean” and comparable to all the others:

- Jan 1 1789 to Dec 31 1799

- ENGLAND ONLY, no Ireland or Scotland

- With ECCO, make sure I don’t have duplicate entries



I get a count of how many titles are in the corpus.



I use random.org to get 100 randomly-generated numbers. I use the “sequence” generator, not the “integer” generator.



#### sample: reprints ####



Compare most-reprinted texts overall to inclusions in smaller archives



ESTC

ECCO

ECCO-TCP



HathiTrust

ProQuest

BL 19thC



END?

WWO+Chawton combo?



Gutenberg

Book Tracker



Google Books??

Internet Archive?



#### sample: print runs ####



Take a random sample for which I attempt to locate size of print run



Radcliffe doesn’t need many editions because her print runs started out large — take a random sample and see if I can find print runs for the works

Compare the popularity order produced by raw edition count to the one normalized by print run — what’s the error rate?



Ask Tom how to find these numbers (it’s not in databases, but I can read a paper book! — This is one of the things that makes my methodology not 100% DH)



#### what's "normal"? ####



Computationally identify reprints in ECCO

Come up with a number that would be a "lot" of reprints vs "not a lot" (to gauge popularity generally)

How old were books, usually? (i.e., how long ago was their first edition)



#### close read: Paine vs WW vs Blake ? ####



Paine vs Wordsworth vs Blake? (Vs CSmith and Radcliffe?) How to accord importance to these writers is at the heart of much of this project.



#### close read: something old? ####



Any cool “1790s lit” not written in the 1790s? Shakespeare? Goldsmith?



### topics ###



#### methods ####



Develop some kind of ontology of topic that encompasses "everything" (sticking to 18thC frameworks of, e.g., history vs romance)



##### topic modelling #####



I turn to topic modelling as a way to move “laterally”: if I can only query attributes which every archive records, I can’t query anything at all.



#### sample: truthful titles ####



Take a random sample to see how accurate titles are to contents overall



#### compare archives ####



Count how many works of each topic appear in each archive -- what kinds of content has been excluded in each, esp. in ECCO-TCP



#### what's "normal"? ####



Make my own guesses as to what the print landscape was like, and what this means (close-read something interesting that emerges, perhaps works that misrepresent their contents)



#### close read: ? ####



### conclusions ###



#### compare archives ####



 Which of these archives are the most "reliable", and which the most "distorted"? (obvs interrogate this framework)

	•	What’s in all these, anyway?

	⁃	What does ECCO-TCP leave out compared to ECCO? Compared to ESTC? (Can I come up with adjustment factors?)

	⁃	How do digital vs physical holdings compare?



#### what's "normal"? ####



What is a "normal" footprint in the print culture of this decade? (i.e., what are the boundaries a work has to surpass to be unusually popular or unusually unpopular?)



## ch 3 - archive popularity ##



Chapter three expands upon the findings of the experiment carried out in chapter two, to examine popularity as it manifests in print culture. Influenced by Lesser and Farmer’s articulation of “structures of popularity,” I will consider popularity[ TK: Another tricky one. Might be best to avoid “popularity” unless you’re also going to factor in (as would be very hard) questions like print-runs (a nightmare imponderable), circulation (something aimed at libraries might have many more readers per copy than a book for home), unauthorized newspaper serializations, anthologization (is that a word?), false title pages (where a self-proclaimed 2nd or 10th edition might actually be just a new tp on remaindered sheets of a first edn that hasn’t sold. You could imagine (and this may have happened in practice) a novel published just once in 2,000 copies being more popular than one claiming five editions, none of which may have been more than 500 copies, and some of which may not have been true new editions at all. But which would come up as more popular give your metrics? This is all really tricky stuff and I think you’ll need a thorough discussion of the issues and assumptions.] in terms of total number of editions, frequency of reprinting, and market share.[ Lesser and Farmer also include profitability as one of the four measurements relevant to popularity in the book trade, but profitability is beyond the current scope of this project.] After determining how to calculate each of these metrics, I will ask: what was most popular during the decade, according to my corpora? How do the corpora differ in their answers, and why? I am particularly curious to see the place that chapbooks and religious tracts have in each corpus. My preliminary research suggests that many of the most reprinted works will substantially pre-date the 1790s in their composition. Accordingly, taking up David Brewer’s challenge to account for the increased “footprint” of some texts beyond the moment of their original publication, I will also pay attention to works originally written before the 1790s which nonetheless can be considered important “1790s literature” due to prominent reprinting. This inquiry’s first question is one of discovery: what works resurface in the 1790s? Its next question is one of close-reading and historical context: what makes them seem newly relevant? Restricting my inquiry only to the 1790s rather than nineteenth-century legacies, I will use my corpora to compare the publication output of various literary celebrities over the course of the decade. In addition to looking at the raw publication counts in the corpora defined in chapter two, I am currently exploring ways to use mentions in reviews and news articles to track prominence and reputation. The chapter as a whole, then, presents a sustained study of the relative popularity of the most prominent works printed during the 1790s, and seeks to answer how these prominent works might affect what we define as “popular literature”.



### consult Reading Experience Database? ###



The Reading Experience Database contains over 30,000 searchable records documenting the history of reading in Britain from 1450 to 1945. Evidence comes from published and unpublished sources such as diaries, commonplace books, memoirs, sociological surveys, and criminal court and prison records.



Combine with Novels Reviewed Database



Also https://vls.english.qmul.ac.uk/ Dissenting Libraries Online

To find out more about the reading habits of individual borrowers, click on Browse borrowers. Explore the borrowing records of tutors, such as the Baptist Frederick W. Gotch, ministerial students, including Robert Cotton Mather (later a Congregational missionary), and their lay counterparts, such as William Rayner Wood (who became a prominent Unitarian businessman). 

The most frequently borrowed books include periodicals, theological textbooks, and historical works. Click on the links to see lists of the most popular titles at Manchester College, Homerton Academy, or Bristol Baptist Academy.



## ch 4 - networks ##



Chapter four introduces my second major experiment, a mapping of the social world of print production 1789-99. As in chapter two, it will be a substantial technical and research project simply to recover contemporary printing practices; this time, rather than asking what was printed, I will ask who it was printed by. A great deal of scholarly work[ TK: Jon Mee, Kevin Gilmartin and Paul Keen are others who would be important here. Plus scholars who focus more on conservatism, perhaps M. O. Grenby for example? Or even much earlier work by Marilyn Butler?] already exists on printing circles, coterie publishing, and individual publishing houses.[^cf9] My project will consult this scholarship to extract and encode connections between authors, printers, and publishers (but not patrons, readers, or other persons not immediately involved in the production of texts) in order to synthesize the implicit social networks underlying 1790s print production. I will begin my research for this chapter by encoding only a few existing studies, in order to evaluate the feasibility of my method at scale. It is possible that, rather than directly consulting the more richly historically-informed work of other scholars, I will instead fall back on inferring networks from the author and publisher metadata included with the corpora examined in chapters two and three. The resulting chapter will explain my methodology and its assumptions, and will provide a rich description of my resulting network graph. The graph I create may reveal one large interconnected network, or several separate networks of varying sizes; these networks may consist of highly distinct clusters, or evenly interconnected webs. Drawing on mathematical graph theory, the chapter will explain the implications of whichever shape the network ultimately displays. It will also present an overview of the people I identify as the “major players” in the publishing world of the 1790s, both mathematically (looking for nodes with various kinds of centrality) and in the scholarship.



### British Book Trade Index ###



OBVIOUSLY this work should be built on the back of the British Book Trade Index, I can’t BELIEVE nobody told me about it!!



http://bbti.bodleian.ox.ac.uk/#

https://www.nls.uk/catalogues/scottish-book-trade-index



## ch 5 - networks popularity ##



Having recaptured these complex networks in some depth, I can then examine them, in chapter five, for their relation to our current understanding of mainstream and radical — or as I am terming them “mainstream” and “non-mainstream” — printing circles. My network graphs will model individual political affiliation as a complex, socially defined practice rather than a taxonomy of concrete and unchanging ideological stances.[ TK: Excellent point, especially in these fast-changing years. But again, this looks like potentially very daunting. Stable binaries are so much more convenient for scholars to work with! I’m excited to see what you come up with here.] This chapter will look for traces of affiliation in the print practices of publishers and of authors. I will consider individual printers with political allegiances, as in Dissenting societies, radical publishers, correspondence societies. This will then enable me to consider authors’ strategic choices as they publish with different printers[ TK: Again presumably you mean publishers not printers? NB too that the choice could work the other way round: authors for hire being commissioned by publishers to write something suitable for a list. I don’t know much about the Minerva Press, but I imagine that’s the way this kind of publisher would have operated, at least in part.]. Having identified radical elements in the publishing world, I will interrogate the radicals’ claims to marginalization. I suspect that I might find that they were not as socially estranged from the mainstream as they describe themselves, and that their printed works may accordingly have been less marginal. I will discuss alternative print markets and alternative circulation, and what kind of “alternatives” they offer to the mainstream. The circulation of works in manuscript presents me two challenges which will be discussed here. The first challenge is methodological: the circulation of manuscripts clearly occurred, and may have constituted “publication” within social circles, but manuscripts fall outside my purview[ TK: Yes, goodness, yes! You can deal with this via a brief discussion of recent scholarship on the persistence of manuscript culture and association practices e.g. Betty Schellenberg, Aileen Douglas, Michelle Levy, I would have thought.]. This chapter will therefore discuss the nature and rough shape of the gap which the exclusion of manuscript works leaves in my study. The second task of this chapter is more theoretical: as queer and decolonial DH scholars note, there is an ethical choice implicated in the decision to systematically discover, collect, and expose communities which intentionally operated below the notice of state observation. Historical distance prevents me from worrying about causing direct harm through my work, but nonetheless I will critically interrogate my own research practices and contextualize my choices within the horizon of expectations of the radical circles I (and other scholars) expose. Finally, having discussed the networks of radical and mainstream publishing in the 1790s, I will also compare the position of radical publishers in the 1790s with their status in the corpora discussed in chapters two and three (where they may in fact be marginalized; I expect to find conservative works overrepresented in the corpora). Together, these approaches will further complicate the story of popularity which the dissertation challenges elsewhere, by suggesting ways to reassess of the popularity of radical works.



## coda? - gothic ##



A potential coda or afterword could build on the work of Robert Miles and others to describe the role of the Gothic as a trans-generic mode which can appear across all print production (assuming that turns out to be true, of course.) Some of my earlier work suggests that Gothic modes of writing, unlike most literary content, can be “spotted” computationally. Since the Gothic operates by means of distinctive tropes and sensory appeals, the Gothic parts of a history and the Gothic parts of a picaresque can be distinguished from the non-Gothic parts of each by computational methods that could not distinguish a history from a picaresque. (Importantly, stylometric methods are not able to distinguish a parody of the Gothic from a “real” Gothic; as I theorize and interpret my findings, then, I would take up Horner and Zlosnik’s work on Gothic humour to discuss the problem of parody in taxonomy.) This final section could use a stylometric approach to identify and then search for “Gothic vocabularies” in full texts, computationally, in order to quantify the reach of the Gothic across my corpora. How many works can be identified as having Gothic influences? What kinds of literary production are most resistant to the Gothic? Does the Gothic appear differently in mainstream vs radical presses? This afterword would sketch out a preliminary map of the Gothic in the print world of the 1790s. This closing section would thus cite and build upon my prior work with the Gothic, in the context of the 1790s as a period when the penetration of Gothic modes into mainstream print had particularly complex political stakes.



## Works Cited ##



But wait, I want to use LaTeX or some other citation manager for this.

Command-shift-C will call up the Papers citation tool.

\cite{Scheuermann:2001tc}

How can I use this to cite specific page numbers?



# Acknowledgements #



SSHRC (OGS?)

ESTC, HathiTrust, U Toronto Libraries (for ECCO metadata)

Alex G, Terry, Tom

Cai, Ashley

Alex + Austin, Alyssa, Jakob, and all the other “civilians”/“innocent bystanders”

Alex StrickVL?? Beeminder? 

OBNS



# Works Referenced #



https://www.itsmarc.com/crs/mergedprojects/helpauth/helpauth/tag_list.htm

Library of Congress MARC info



# Appendix A: codebase #



# Appendix B: detailed methods #



## "data cleaning" ##



### ECCO ###



My ECCO metadata presented particular challenges. I had access to MARC records, which stands for MAchine Readable Catalogue. At several points, I read this data with my feeble non-machine eyes in order to guide my data processing. Using MarcEdit, I converted these MARC records to csv files which could, on OpenRefine, be read, manipulated, and merged like my other corpora. Since I was not able to simply convert “all the MARC headings that exist” using MarcEdit, I used all numbers 1 to 999 and [will] delete empty columns.

ECCO encodes much of its data in “unassigned” columns, rather than the standardized LOC categories.





https://www.itsmarc.com/crs/mergedprojects/helpauth/helpauth/tag_list.htm

Library of Congress MARC info

[^cf1]: It may also be the case, of course, that even fields with a long history of graphical display would benefit from greater scrutiny of the evidence they use; see: the Data Dinosaur. But this is beyond the remit of what an English PhD can address.

[^cf2]: 1. show comparisons, contrasts, differences
	
	2. show causality, mechanism, explanation, systemic structure (intervention relies on manipulable causality -- can't do anything with the information without causality)
	
	3. show multiple variables (3 or more) -- the world is multivariate
	
	4. *completely integrate* words, numbers, maps, graphics, etc, etc. Provide information at exact point of need
	
	5. documentation must thoroughly describe evidence and its sources, provide complete measurement scales
	
	6. presentations succeed based on their content. for better presentations, get better content.

[^cf3]: As a recurrent Freudian slip, I have more than once typo’d the word “data” as “danger”

[^cf4]: Although these events, of course, did not occur on January 1 or December 31, respectively, the entirety of 1789 and 1799 are both included in my study here, out of sheer technological necessity.

[^cf5]: I have heard it quipped more than once in digital humanities gatherings that you always think you’re going to get your texts from somewhere else, but Project Gutenberg is where you’ll actually get them.

[^cf6]: https://books.google.ca/intl/en/googlebooks/partners/

[^cf7]: CITE http://languagelog.ldc.upenn.edu/nll/?p=1701

[^cf8]: https://archive.org/about/

[^cf9]: Per Terry’s suggestions, I would likely begin here with Jon Klancher, The Making of English Reading Audiences, 1790-1832; Marcus Wood, Radical Satire and Print Culture, 1790-1822; and David Worrall, Radical Culture: Discourse, Resistance, and Surveillance, 1790-1820. Other promising titles include Social networks in the long eighteenth century : clubs, literary salons, textual coteries, ed. Ileana Baird; and The enlightenment & the book : Scottish authors & their publishers in eighteenth-century Britain, Ireland & America, by Richard B. Sher, to capture different parts of the publishing landscape.