Title: DISSERTATION  
Author: Lawrence Evalyn

# ch 1 - intro #



## Intro ##



### intro to overall argument ###



This dissertation seeks to determine, in as minute detail as possible, what the print landscape in England 1789-99 was actually like. It also seeks to explain, in equally minute detail, why this task of historical recovery is, in fact, impossible. [FLESH OUT MY ACTUAL ARGUMENT AND TOPIC]



### many definitions of DH ###



The field of “digital humanities,” now several scholarly generations into its development, has entered the phase in which so many scholars are carrying out “DH” research that no universally-acceptable definition of “DH” can exist. Many definitions are fundamentally methodological. [ADD A COUPLE DEFINITIONS OF DH HERE]. These definitions describe what might be called a “computational humanities.” Other definitions take up the new importance of digitality in daily life. [ADD SOME DIGITAL CULTURAL STUDIES STYLE DEFINITIONS HERE]. This kind of work is increasingly described as “digital cultural studies.” In positioning this work as a “DH” dissertation, I might at first glance seem to belong squarely within the “computational humanities.” To be sure, much of this work is intended to apply existing computational methodologies to conduct otherwise old-fashioned literary research. Several of my contributions, too, are purely methodological in nature, in the development of new code and new guidelines for computational research using particular digital resources. However, as a fuller discussion of Johanna Drucker’s distinction between “data” and “capta” will elucidate later in this chapter, no computational research exists separately from a specific, local, culturally-defined context. Accordingly, my computational research into eighteenth century literature and my development of new computational methodologies are both inevitably tied to “digital culture.” My results often have more to say about contemporary digital archives, and the history of literary record-keeping, than they do about the eighteenth century itself. I therefore rely on an extensive body of work in cultural digital studies to examine not only the eighteenth century, but eighteenth century studies.



### many histories of 1790s ###



So, too, are there many “histories” — or perhaps, narratives — available to describe the 1790s. [FOCUS ON POLITICS]. [FOCUS ON ROMANTICISM]. [FOCUS ON GOTHIC]. [RISE OF THE NOVEL] Of necessity, each of these histories must exclude something. [WHAT EACH EXCLUDES].



### reparative reading ###



It is difficult, when faced with flawed and complex competing narratives, to resist the impulse to simply critique and reject all options. If we may learn any lessons from the 1790s, however, surely one must be the danger of universal paranoia. Eve Sedgwick persuasively describes, in “Paranoid Reading and Reparative Reading,” the dominance of paranoia in literary criticism \cite{Sedgwick:2015up}. Rita Felski, in her article “After Suspicion” and then further in her recent monograph The Limits of Critique, continues in Sedgwick’s line. Felski asks: “Can we be postcritical — as distinct from uncritical?” \cite{Felski:z11z1lQx p.151}. Reparative readers are often critiqued for painting a much clearer picture of the paranoid mode than the reparative mode, leaving it unclear how one is meant to escape paranoia’s double-bind. But this is not to say that the attempt itself is unworthy. [CONCLUSION HERE - DH somehow?]. 



### BLUF ###



These, then, are the three scholarly conversations to which this dissertation contributes: the digital humanities, as an increasingly self-reflective set of practices; eighteenth century studies, and the challenges presented by the 1790s; and the theoretical frameworks within queer theory which seem to offer valuable resources for both. The remainder of this chapter will describe in more detail the relevant scholarship in all three fields, then discuss the overlaps between them which enable my work. Finally, this chapter will conclude with a description of the two experiments which drive the dissertation as a whole, situating them within the three fields, and providing a sketch of their development across the dissertation.



## DH ##



### many histories of DH ###



When telling a history of “DH,” one has many histories to choose from, all freighted with different implications for contemporary practice. [TRADITIONAL HISTORY OF DH]. [FEMINIST HISTORY OF DH.] As these competing historiographies show, much more is at stake than mere description, when certain methodologies are named as “digital humanities.” [CONCLUSION TO THIS PARAGRAPH.]



### code is not neutral ###



The central contention of my computational praxis is that, despite the aura of empirical truth which accrues to some ‘scientific’ methodologies and discourses, nothing is neutral/objective. As Johanna Drucker argues, “data” is not neutral/objective. As Sophia Noble and Wendy Chun demonstrate, algorithms are not neutral/objective. As Alberto Cairo shows, graphs and charts are not neutral/objective. [PUT THESE IN ORDER ACCORDING TO FOLLOWING PARAGRAPHS] Each of these is constructed, by humans, for human purposes, constrained by human biases. As the humanities have long known, of course, things need not be neutral/objective to be meaningful or valuable. By setting aside the desire for a singular neutral/objective truth, we can instead draw quite close to the messy multitudes of truths which enable insight. Accordingly, [CONCLUSION].



### my methods ###



This dissertation will, nonetheless, make use of algorithms, “data”, and data visualizations to carry out its inquiry. At every possible point, however, the underlying methodology will be made visible, and its assumptions scrutinized. Much of the code underlying this project I have written myself. Some has been written at my request. In every case where the code is available to me, the program itself appears in Appendix A (“Codebase”), accompanied by a plain-language explanation of how it operates. Where I have used closed-source software, Appendix A contains an explanation of my best guess at its underlying process. My exact use of these tools — sufficient for another to replicate my work — is provided in Appendix B (“Methodology”). These details are explicated in full in the appendices in order not to over-burden the body of the dissertation, but they are by no means confined to the appendices. Computation is not a “black box” to be consulted for simple answers, but an inextricable from my reasoning and argument.



### capta ###



My attention to the sources of digital knowledge creation comes from Johanna Drucker, and her distinction between “data” and “capta.” Drucker, in “Humanities Approaches to Graphical Display,” specifically addresses the digital humanities practice of creating, and then close-reading, data visualizations. She argues that the tools for visual representation which may be effective in the sciences cannot be simply and uncritically transposed to humanistic subject matter. When an experiment is presented as a ‘data visualization,’ she says, “the rendering of statistical information into graphical form gives it a simplicity and legibility that hides every aspect of the original interpretative framework” (8). In fields where the readers of such charts are also frequent creators of charts, and where norms exist to explicitly describe one’s interpretive frameworks in a methodology section, the simplicity and legibility of an individual chart may be a benefit which does not impede complex scrutiny of the information it presents.[^cf1] In a field like literature, however, the “graphical force” of something like a network graph or even a simple pie chart “conceals what the statistician knows very well — that no ‘data’ preexist their parameterization” (8). Drucker problematizes the term “data,” the etymology of which presents it as a “given” which is stable and independent of observation. She proposes that humanities visualizations embrace, instead, the framework of “capta,” that which is “‘taken’ actively” (3), “fundamentally codependent, constituted relationally, between observer and observed phenomena” (50). Drucker’s assessment shapes my own prioritization of qualitative and reflective computational research. The term “capta” itself has not seen uptake in subsequent digital humanities scholarship, even in cases where scholars explicitly take Drucker’s warnings to heart. Accordingly, for clarity, this dissertation will continue to use the more usual term “data” to refer to the information gathered for analysis here. However, as I integrate and compare a wide variety of data from many disparate sources, a preliminary task of my analysis is always to determine, as precisely as possible, how the information was captured and quantified. 



### data viz ###



Additionally, all of the figures presented in this dissertation are of my own design. My design praxis is informed by the work of Edward Tufte and Alberto Cairo, both of whom provide practical design advice in service of demystifying the visual rhetoric by which graphs present their arguments.[^cf2] Neither Tufte nor Cairo is a scholar of media studies; rather, they are professional practitioners of ‘data visualization’ who reflect critically on the assumptions of their work. Tufte’s work primarily strives to correct badly-designed data visualizations, and the dangerous decisions that bad design can lead people to. His most famous example is an analysis of the scientists’ report at NASA which led to the ill-fated launch of the Challenger space shuttle in 1986: as his extensive visual analysis argues, the scientists (untrained in graphic design) unintentionally obfuscated crucial information about the day’s launch conditions \cite{Tufte:2001vw}. Tufte’s six principles of design[^cf3] primarily seek to guide undertrained designers away from misleading themselves. Cairo, following on Tufte’s work from the perspective of an active journalist, more often turns his attention to successful designs which mislead their audiences intentionally. His forthcoming book, How Charts Lie, addresses the readers of infographics with insights into visual literacy \cite{Cairo:2019uf}. His preceding book, The Truthful Art, addresses the creators of good-faith infographics with insights into visual manipulation \cite{Cairo:2016uv}. Cairo draws a distinction between “data visualization” and “infographics”: “an infographic tells the stories that its designer wants to explain, but a data visualization lets people build their own insights based on the evidence provided,” summarized more succinctly as “infographics to explain, data visualizations to explore” \cite{Cairo:2014tl}. Using this terminology, my argument will proceed with infographics in the body of the dissertation as curated figures to support my argument, with fuller data visualizations available in Appendix C: Data to allow further exploration. Following in both Tufte and Cairo’s footsteps, I conceive of the figures throughout this dissertation as rhetorical devices. In service of arguing honestly, therefore, my designs — in the body of the dissertation and in Appendix C — are accompanied by footnoted explanations of my design rationale. 



### critical algorithm studies ###



My emphasis on transparent, critical, and reflective praxis in the capture and visual presentation of data[^cf4] owes much to the emerging field of critical algorithm studies. Any methodology is, to a certain extent, an “algorithm,” in the loose definition of ‘a series of pre-defined steps to be carried out’. But computational algorithms [ARE IMPORTANTLY DIFFERENT FROM] “algorithms” implemented by humans The emerging field of critical algorithm studies thus responds to an urgent need. [Extended summary of Safiya Noble]. [Write about Wendy Chun too] [EXAMPLE ALGORITHM FROM MY MATERIALS] [Conclusion: I am indebted to the ‘digital cultural studies’ scholars for giving me tools/lenses for my work….?]



### procedural argument ###



An additional and perhaps-unexpected resource, for scrutinizing algorithms critically, comes from the work of those who study games, especially video games. [Ian Bogost argues that procedures contain arguments.] This framework allows us to see that all research methodologies, including non-digital ones, contain implicit arguments about the nature of what is studied. [EXAMPLE PROCEDURE FROM MY MATERIALS - something non-computational?] 



### fruitful models/samples ###



In light of the challenges of “empiricism,” my goal in this dissertation is to produce a series of fruitful models. [Willard McCarty’s descriptive work on the concept of modelling VERBS modelling’s processes of abstraction. ][QUOTES FROM McCARTY] Another way of expressing this might be to borrow from the vocabulary of social science research: I would like to make discoveries about a “population” which is inaccessible to me, namely, “everything printed in England 1789-99.” Since I cannot access this population in full, I have taken a series of “samples,” which I hope to be representative; each sample can be examined as evidence of the makeup of the source population, but must also be examined in and of itself as a sample. [therefore, not attempting ‘accuracy’] [Rather than making claims about the 1790s each claim is filtered through / constrained by the specific model of the 1790s used to make it] Rather than producing a clear and pristine truth, my models are, in fact, quite likely to contradict each other. In these moments of contradiction, [we have the best opportunity to learn, because we can see why they contradict, and therefore why something may or may not be true.] [These opportunity are “fruitful”] [Expand on “fruitfulness”]



## 1790s ##



### English history ###



All of these [capta, samples, algorithms, models, and self-reflective methodologies — match preceding section] do have an aim beyond themselves: to recapture, in as minute detail as possible, the print landscape in England between January 1 1789 and December 31 1799. This eleven-year “decade” was a turbulent one across the Channel, encompassing the whole of the French Revolution, from the Estates General in 1789 to Napoleon’s coup in 1799.[^cf5] In England, [HISTORY OF THE KEY EVENTS OF THIS DECADE IN ENGLAND]. [CONCLUSION: an environment which felt like it was on the edge of history]



### superlatives ###



The [world of letters? Public sphere? What do I call it?] in England responded to these events by [writing WAY TOO MUCH]. This is the decade of Common Sense, it is the decade of Lyrical Ballads; it is the decade of Hannah More, it is the decade of Ann Radcliffe; it was the age of wisdom, it was the age of foolishness; it was the epoch of belief, it was the epoch of incredulity. Charles Dickens’ now-famous superlative degree of comparison captures the tension between empiricist or otherwise political thinkers and Romantic or Gothic artists as contemporary literary scholars grapple with these modes. Each literary ‘mode’ was imbued with the potential for national importance. [WRITE ABOUT IMPORTANCE OF READING/WRITING TO NATIONAL IDENTITY —> CONCLUSION.]



### canons ###



Not coincidentally, the 1790s are also a decade in which some literary “canons” begin to take form. John Guillory contends that the “canon debate” taking place during his moment of writing in 1993 “signifies nothing less than a crisis in the form of cultural capital we call ‘literature’” \cite{Guillory:1993ve p.viii}; the roots of this crisis lie two hundred years earlier, in the eighteenth century formation of a vernacular (rather than classical) literary canon, and in the 1790s “first crisis” (\cite{Guillory:1993ve p.xi} of that canon. Guillory turns particularly to Wordsworth and Coleridge, and the strategies by which they confer a high status on their own work by undermining the cultural capital of other forms. Wordsworth, Coleridge, and the other ‘big six’ Romantics are surely the winners of the eighteenth century historical battle for cultural capital; just as surely, the loser has been the Gothic. E.J. Clery’s The Rise of Supernatural Fiction, 1762-1800 provides an account of what was at stake for the representations of supernatural events in supernatural stories in fiction, drama, and popular news \cite{Clery:HFvEup7z}. The “rise” she describes is not an increase in volume and prominence of supernatural stories, since her starting point in 1762 (the Cock Lane ghost) is a major national phenomenon with many imitators. Rather, supernatural fiction ‘rises’ when it acquires cultural legitimacy. Michael Gamer has more recently expanded on how this ‘rise’ fuelled romanticism’s own rise \cite{Gamer:jX8nTxB-}. In Romanticism and the Gothic: Genre, Reception, and Canon Formation, he details  the interconnectednesss of what are now seen as the separate categories of ‘high’ Romantic literature and ‘low,’ popular Gothic writing. By using Gothic materials in self-avowedly non-Gothic ways, Gamer argues, Romantic writers could appeal to popular taste without risking the loss of cultural capital which attended the Gothic’s “popularity”. Gamer, like Guillory, primarily uses Wordsworth and the ‘winners’ of the struggle for cultural capital: I, like Clery, am more interested in the ‘losers.’ Accordingly, I attend to much that is not literature, in order to better understand why it is not.



#### rise of the novel? ####



### more similar than different ###



All of these schools of writing are, I argue, more similar than they are distinct, in the print marketplace of the 1790s. Which is to say, all of these individual writers are choosing strategies from the same pool of constrained choices. [Gothic strategies - Gamer] [Corresponding society strategies] [Poetic strategies - Mary Robinson] [Hannah More] [CONCLUSION: have to deal with everything at once; individuals, variety]



#### John Mee's book ####



John Mee silently defines “print, publicity, and popular radicalism” as being synonymous with the activities of the London Corresponding Society, and societies like it. These societies and their use of print are obviously crucial parts of the print landscape, reflecting one [take on] publicity, but I seek to go broader.



#### "schools of thought" ####



my own understanding of eighteenth century politics as “schools of thought” governed by memetic natural selection.

Because politics occurs between individual people, not political parties, I argue that political affiliation, like literary genre, is not amenable to simple taxonomic classification.



### conclusion ###



My synthesizing approach [SAYS SOMETHING THAT WRITING PREVIOUS PARAS WILL CLARIFY]



## theory ##



### reparative reading ###



On the broadest level, my primary theoretical framework is that of reparative reading. I understand reparative reading to mean [DEFINITION OF REPARATIVE READING]. Others have worked to carry out scholarship in this mode, including [OTHER REPARATIVE READERS]. [Felski’s neophenomenology in Everyday Aesthetics]   [SUMMARIZE THE MAIN THREADS / CATEGORIES OF THEIR WORK.] [WHY I VALUE REPARATIVE READING (INDEPENDENT OF DH & 1790s)].



### queer theory ###



Implicit in my prioritization of reparative reading is an affinity for queer theory more broadly. I take it as read, for example, that history consists of major discontinuities in cultural ontology and identity, as Foucault describes. I follow Judith Butler in understanding these historically-framed identities as being “performative,” actively re-created in conversation between self and others. [(In my understanding of performative identity creation I also borrow from J.L. Austin, who is not typically understood as a ‘queer theorist,’ but who contributes an invaluable articulation that [WORDS DO THINGS].)] [This queer-theory foundation shapes my approach to literature as an encounter with an ‘other’, which, as Rita Felski says, [FELSKI HAS SOMETHING ON THIS]] [CONCLUSION.]



### surface reading ###



My search for other ways of relating to literature has also led me to emerging work under the umbrella of “surface reading”. “Surface reading” positions itself as an alternative to “symptomatic reading”; [RATHER THAN X, IT Y.] The analogues to reparative and paranoid reading are obvious, but also, I argue, overly simplistic: all paranoid reading is symptomatic, but not all symptomatic reading is paranoid. Reparative reading, as described by Sedgwick and potentially modelled by Felski, is still interested in ‘deep’ meanings of texts, in which striking textual features can be interpreted to locate additional meanings. [A LOT OF QUEER THEORY IS ALSO SYMPTOMATIC, EVEN WHEN IT’S NOT PARANOID (AND TBH IT’S OFTEN PARANOID).] In contrast, “surface reading” [DOES SOMETHING ELSE.] [GIVE EXAMPLES OF SURFACE READINGS.] [GROUP/CATEGORIZE SURFACE READINGS.] [CONCLUSION]



### conclusion ###



Surface reading and reparative meaning are not synonymous modes: Felski, at the forefront of reparative reading, explicitly distances herself from surface reading “I have no quarrel with interpretation, even though I favor description; nor am I drawn to a language of textual surfaces over depths” (CITE).



Talk to Dana Seitler about the distinctions between surface reading and reparative reading

History of queer theory: Oscillations of Literary Theory, AC Fecundo



Reparative reading rejects paranoia & the role of the critic as master

	Felski rejects negativity? & role of critic?

Queer reading rejects ?

Surface reading interpretation (?) — focus on taking the text at its word & examining all details equally



## synthesis of 3 fields ##



### we need Venn ###



Drawing together three scholarly conversations with three distinct histories, it is difficult to attentively delineate the links and the tensions between each thread. Especially since many of these fields have, in fact, overlapped substantially, there is a danger of simplistically conflating distinct lines of thoughts. At the same time, over-emphasis on distinctions can overstate the separations between fields which do in fact (as the existence of this dissertation contents) share important affinities. To navigate these conceptual overlaps carefully, let us make our way through each area of an imagined Venn diagram of the three. We can discuss each pair in turn — DH and eighteenth century studies; eighteenth century studies and queer theory; queer theory and DH — to make our way toward the centre where all three overlap.



### DH & 1790s ###



#### DH & bibliography ####



In the intersection of the digital humanities and eighteenth century studies, I turn to bibliography. If there is any research more magnificent in its scope than [SOME BIG DH THING], it is work like Garside & Raven’s The English Novel. This kind of work seeks to be both comprehensive and accurate. [DESCRIBE THE SIMILARITIES I SEE. — Resources for future research] [Now I’m going to survey the kinds of digital corpora and non-digital bibliographic resources that I focus on.]



#### scholarly archives ####



Eighteenth century materials of various kinds have been collected in many digital archives, of very different scope. These are discussed in more detail in Chapter 2. On the tip of anyone’s tongue, of course, is Gale’s Eighteenth Century Collections Online (ECCO), containing over 180,000 titles 1701-1800, of which 42,000 were printed in England between 1789 and 1799. ECCO is itself (mostly) a subset of the broader English Short Title Catalogue (ESTC), which contains more 460,000 texts 1473-1800, of which 51,965 were printed in England between 1789 and 1799 (indicating that nearly 10,000 in the decade titles appear in the ESTC but not ECCO). The ESTC does not provide access to texts themselves: instead, it is an authoritative bibliographic catalogue, available as a searchable database. It is ECCO which provides texts themselves: ECCO’s 180,000 titles works are available as photographed facsimiles of the full text of each title. The facsimiles can be searched within ECCO’s online interface; these searches examine a plaintext version of the facsimile pages that was generated by Optical Character Recognition (OCR), but this OCR text is not made directly available. As a result, the facsimiles may be read individually by scholars, but cannot form the basis for computational corpus analysis. A subset of ECCO’s texts have been hand-prepared, as part of the Text Creation Partnership (TCP), to be easier to use in computational research. The resulting corpus of ECCO-TCP texts contains 2,231 titles, of which 466 were printed in England between 1789 and 1799. These titles are available as carefully-edited texts encoded according to the Text Encoding Initiative (TEI) standard, which not only provides an accurate version of the text’s words, but encodes substantial details regarding its context on the page. Most large-scale distant reading of eighteenth century literature relies in the ECCO-TCP corpus as its ‘model’ or ‘sample’ to represent the period. Accordingly, one of the tasks of this dissertation is to precisely examine the makeup of thus corpus, and how it differs both from other corpora and from print culture in the period itself. These three digital collections — ECCO, ESTC, and ECCO-TCP — are the primary digital resources for the period, which form the basis of most digital research. However, they represent only one approach toward the collection and presentation of digital texts, to which there are two broad kinds of alternatives. These large but meticulous collections occupy a middle space between, on the one hand, highly selective thematic collections, of which there are many, and the giants of indiscriminate textual accumulation, of which there are few.



#### micro archives ####



Smaller collections seem more scholarly, but have some limitations.] Whereas the ‘main players’ can be easily enumerated for the mega-archives, these specialized collections are numerous. Some will focus on particular kinds of texts, such as the Early Novels Database (2,041 novels 1700-1799) or Broadside Ballads Online (more than 30,000 broadside ballads). Others exhaustively index particular publications, such as The Hampshire Chronicle, the Index to the Lady’s Magazine (1770 to 1818), or the Novels Reviewed Database (1,836 reviews from The Critical Review and The Monthly Review, 1790-1820). Feminist scholarship in particular has seen the creation of resources like the Orlando Project, the Chawton House library Novels Online, Northeastern University’s Women Writers Online and UC Davis’s British Women Romantic Poets. The virtue of these collections is that they achieve even greater accuracy and comprehensiveness within their defined scope. The Shelley-Godwin Archive, for example, can reasonably aspire to digitize every known manuscript of Percy Bysshe Shelley, Mary Wollstonecraft Shelley, William Godwin, and Mary Wollstonecraft, and to provide these manuscripts in hand-encoded plaintext transcripts.

However, as is inevitable, these specialized archives have the vices of their virtues: their specialized focus allows them to adapt precisely to their materials, and their idiosyncratic data structures can rarely be combined with other resources. The William Blake Archive, for example, benefits enormously from  [attention to images — but this isn’t a standard]. Similarly, Project Gutenberg makes no claims to scholarly reliability but nonetheless underlies a not-significant amount of scholarly work.[^cf6] Unlike Google Books, Project Gutenberg actually does have selection criteria: it is only interested in public domain works which contemporary audiences might be interested in reading for pleasure. It narrows the field substantially to exclude works which have either ceased to be broadly interesting (as in the case of most forgotten fiction), or which was never particularly interesting (as in the case of almanacs and tax codes). Project Gutenberg includes 57,796 texts: far more than specialized scholarly archives like the Early Novels Database or the Shelley-Godwin Archive, but nonetheless an order of magnitude fewer than its more-voracious potential competitors. And, like smaller specialized scholarly archives, Project Gutenberg has tailored its holdings to make it easy for readers to read, and quite difficult for its collection to be applied to any other use. By tailoring the structure of the archive itself to its specific materials, these collections [DO SOMETHING GOOD]. But they also [MAKE IT MORE DIFFICULT TO COMBINE THEM].



#### mega archives ####



The best known mega-archive is, of course, Google Books. In a scholarly context, one hesitates even to designate this as an “archive,” particularly in the same breath as resources like ECCO: books of all kinds are scanned indiscriminately with only the bare minimum of roughly-accurate metadata collected about them. Books are sourced from libraries whose collections are being scanned in bulk, or are submitted directly by publishers or authors who are attracted by Google’s call to “Promote your books on Google—for free” (CITE[^cf7]).   These rapidly-scanned books are prone to unpredictable errors, including inaccurate dates, misspellings, duplicate copies, and inaccurate subject classifications (Harper 2016; Jacsó 2008; Weiss 2016) (CITE Mike Sutton and Mark D. Griffiths) — infamously, many books have “1899” assigned as their publication date because this date was used as a placeholder for “no date”.[^cf8] Many photographed pages still include the fingers of the employee holding open the book. Nonetheless, Google Books is frequently used to study the prevalence of various “n-grams” (words or short phrases) over time, thanks to Google’s built-in tool. The tool is able to search books which are, for copyright restrictions, not available directly to readers, making it highly tempting for question about contemporary language use. Similar in scope to Google Books but with more limited research tools is The Internet Archive. The Internet Archive, unlike Google Books, is a non-profit, but like Google Books, it carries out mass scanning of books. The Internet Archive declares that it contains 20 million books and texts, and scans 1,000 books per day in 28 locations around the world (CITE).[^cf9] Equivalent numbers are not published for Google Books, which has received less attention from Google as it encountered more legal barriers; in 2013 books were scanned at the rate of 1,000 pages per hour, and in 2015 more than 25 million books had been scanned. Google Books, Project Gutenberg, and the Internet Archive are not “canonical” sources of texts, but they are nonetheless part of the ecosystem of digital eighteenth century studies.





#### HathiTrust ####



Moreover, as in eighteenth century texts themselves, the boundary between “canonical” and “noncanonical” digital archives is a permeable one: Google Books and the Internet Archive are also integrated into HathiTrust, [EXPLANATION OF HATHITRUST]. The scholarly benefit of HathiTrust is most evident in the study of contemporary literature. On a technical level, whereas OCR typically produces gibberish when faced with eighteenth century typefaces captured in photographs of microfiche, OCR is extremely effective at reading contemporary typefaces and direct high-resolution digital scans of books. The materials 



#### print archives ####



[But of course not everything is digital]. [It is a core contention of my work that DH can’t ignore non-digital resources]. [LIST AND CATEGORIZE MAJOR PRINT BIBLIOGRAPHIC RESOURCES].

Garside

William St Clair



#### scrutiny is not criticism ####



As I scrutinize the underlying assumptions that are structurally reinforced by this work, I do so not in order to dismiss their value. These resources are created to enable future scholarship: for that future scholarship to thrive, 



#### lit already models/samples ####



Literary study already involves modelling / sampling



#### conclusion: filling gaps ####



Thus, I see DH and bibliography as able to enhance each other reciprocally. 



### 1790s & queer ###



#### queer gothics ####



Queer readings of the 1790s — which is to say, of the Gothic — provide an invigorating way to value some of the most vibrant writing of the decade precisely for the features which rendered it less than “respectable.” [HISTORY OF QUEER GOTHIC STUDIES - Palmer I think, leading up to Franz Potter… this history is prob multiple paras] [A lot of really good Gothic work is connected thematically rather than strictly chronologically, examining the “transtemporal affinities and connections” (CITE) that Felski argues are often shut out by contemporary historicist critique. And indeed, this mode of study is falling out of favour regarding the Female Gothic.]



#### reparative gothic ####



[A lot of queer Gothic work has been paranoid] [Something about Susan Sontag & camp being how I reparatively read the Gothic?]



#### I'm not just gothic ####



Although the queerest work in this period has centred on the Gothic, I intentionally do not limit my focus to the Gothic. My broader scope is, in part, based in an argument about the Gothic’s prevalence: following scholars like [EXAMPLE], I see the Gothic not as a clearly-defined literary genre, but rather as an affective ‘mode’ that can (and did) permeate writing far beyond the realm of supernatural fiction. Accordingly, [although I am interested in the Gothic, I study everything.] [Also I’m not just interested in the gothic.]



### queer & DH ###



#### queer DH ####



[“Queer DH” is now a vibrant field in its own right.] [WRITE UP HISTORY / BROAD CATEGORIES OF QUEER DH RESEARCH] I draw on this work in my pursuit of less “extractive” and more anti-oppressive digital humanities methodologies.



#### reparative DH ####



[TALK ABOUT WHAT REPARATIVE DH METHODS LOOK LIKE, SOMEHOW] [Examples - TL Cowan, ]



By marrying “surface reading” and “distant reading” I may seem to leave “reparative reading” behind: after all, Felski’s call for postcritical analysis explicitly insists, “Sometimes serious thinking calls for a judicious decrease rather than and increase of distance” (CITE). Felski then defines a decrease of distance as “a willingness to acknowledge and more fully engage our attachments”: it is in this readiness to acknowledge and embrace the [DETAILS OF SOMETHING-SOMETHING]



#### surprise! ####



Thus far, the importance of queer theory to DH is evident. But what about the other direction? Just as, I argue, both DH and bibliography have important resources to offer to each other, so to do I argue that DH has something to offer queer theory. Specifically, a well-formulated DH praxis can introduce a new relationship to the experience of surprise which is so challenging in paranoid reading. The most common dismissals of DH research are attempts to say, “we already knew that” — essentially, [PARANOID AVOIDANCE OF UNPLEASANT SURPRISE FROM DH THREAT]. This reaction invites two responses. First, [if the experiment told us that everything we knew was COMPLETELY WRONG, this would not be very good because probably at least some of what we know is right]. [Experiments fall into two categories: those which tell us about our methods, and those which tell us about our fields of study]. Second, as scholars such as Ted Underwood have noted, it is often only retroactively that these discoveries are declared to be “obvious” results which everyone “already knew” (CITE). If we are asked to form an explicit hypothesis in advance, we might be very surprised by the exact numbers. [CONCLUSION]



### all together now! ###



#### CANONS ####



“overall, about how texts do or don't 'enter' a 'canon' of writings - by which you mean, as per e.g. Guillory or Bourdieu, and the idea of cultural capital, a set of texts studied, produced, valued (to varying degrees over time) within certain cultural fields, most especially the field of academic research (but also education, modern publishing, creative industries etc). And then your contribution to the many discussions that go on about (and indeed change) canon, is to bring show we can use digital tools to ask and answer that question? I think maybe it is, and if that is the case, then you need to say just that, and that the other issues - timelessness, popularity, marginalization, immediacy, fall out of that larger question”

(This can be a shorter section; write it after the rest?)



## upcoming 2 experiments ##



### overall goal ###



[Having delineated a large and complex scholarly context for this work, it is time, now, to describe [WHAT I ACTUALLY DID]] - save this for after all the rest, may not be necessary



### my 1790s ###



material printed in England between January 1, 1789 and December 31, 1799 (inclusive).



### experiment 1 ###



### experiment 2 ###



### chapter conclusion ###

[^cf1]: It may also be the case, of course, that even fields with a long history of graphical display would benefit from greater scrutiny of the evidence they use; see: the Data Dinosaur. But this is beyond the remit of what an English PhD can address.

[^cf2]: I cite Tufte and Cairo as the thinkers whose design philosophies best accord with my own current understanding of the work and craft of persuasive data visualization, but my actual practical training as a graphic designer is indebted to Judith Galas, Sonia Davis Gutiérrez, and Tom Hapgood.

[^cf3]: 1. show comparisons, contrasts, differences
	
	2. show causality, mechanism, explanation, systemic structure (intervention relies on manipulable causality -- can't do anything with the information without causality)
	
	3. show multiple variables (3 or more) -- the world is multivariate
	
	4. *completely integrate* words, numbers, maps, graphics, etc, etc. Provide information at exact point of need
	
	5. documentation must thoroughly describe evidence and its sources, provide complete measurement scales
	
	6. presentations succeed based on their content. for better presentations, get better content.

[^cf4]: As a recurrent Freudian slip, I have more than once typo’d the word “data” as “danger”

[^cf5]: Although these events, of course, did not occur on January 1 or December 31, respectively, the entirety of 1789 and 1799 are both included in my study here, out of sheer technological necessity.

[^cf6]: I have heard it quipped more than once in digital humanities gatherings that you always think you’re going to get your texts from somewhere else, but Project Gutenberg is where you’ll actually get them.

[^cf7]: https://books.google.ca/intl/en/googlebooks/partners/

[^cf8]: CITE http://languagelog.ldc.upenn.edu/nll/?p=1701

[^cf9]: https://archive.org/about/