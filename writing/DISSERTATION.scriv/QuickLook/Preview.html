<html>

<head>
<title>DISSERTATION</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<!-- NOTE: margin property = top-right-bottom-left -->
<style type="text/css">

	body {background-color: #e2e2e2}
    
    p.topLevelItemTitle {
    	margin: 30px 0px 5px 0px;
    	font-family: Times, Times New Roman, Palatino, Cochin, Serif;
    	font-size: 30px;
    	}
    	
    p.folderTitle {
    	margin: 30px 0px 5px 0px;
    	font-family: Times, Times New Roman, Palatino, Cochin, Serif;
    	font-size: 18px;
    	}
    
    p.itemTitle {
    	margin: 30px 0px 5px 0px;
    	font-family: Helvetica, Arial, Sans-Serif;
    	font-size: 12px;
    	font-weight: bold;
    	}
    	
    p.itemText {
    	margin: 0px 0px 10px 0px;
    	font-family: Helvetica, Arial, Sans-Serif;
    	font-size: 12px;
    	}
    	
    p.itemTextStart {
    	margin: 30px 0px 10px 0px;
    	font-family: Helvetica, Arial, Sans-Serif;
    	font-size: 12px;
    	}
    
    .page {border: 1px solid #c0c0c0; background: #fff}
    
    hr {
        border: none;
        height: 1px;
        color: #d4d4d4;
        background-color: #d4d4d4;
      	}
      	
    hr.afterTitle {
    	margin-top: -3px;
    }
      	
    hr.afterText {
    	margin-top: 30px;
    }
      	
    ul {
      	list-style-type: none;
      	padding-left: 30px;
      	}
      	
</style>

</head>

<body>

<table border="0" width="100%" cellspacing="3">
<tr>
<td>

<table class="page" width="100%" cellspacing="10" cellpadding="2">

<!-- Top margin -->
<!-- Not needed, because of the padding above titles. -->
<!--<tr><td height="15px"></td></tr>-->

<tr>

<!-- 42 + 30 of list indent = 72 - one inch. -->
<!-- Actually that ends up too much, so we do 25 + 30 = 55px. -->
<td width="25px">

<td valign="top">

<ul>
<li>
<p class="topLevelItemTitle">introduction</p>
<p class="itemText">Chapter One</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">intro</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">dramatic open</p>
<p class="itemText">According to the English Short Title Catalogue (ESTC), the most popular English authors of the 1790s were Thomas Paine, Hannah More, John Wesley, and William Shakespeare. Of course this claim immediately falls apart on further scrutiny. In fact, by the metric of ‘unique entries in the ESTC database,’ the most popular author of the decade is by far Great Britain, followed by Great Britain, Great Britain, Great Britain, and King George III. Paine, More, Wesley and Shakespeare are only able to rise...</p>
</li>
<li>
<p class="itemTitle">dramatic goals</p>
<p class="itemText">Despite the crucial importance of corpus-building to the interpretation of “distant reading” research, it is often extremely difficult to know what is in a corpus. Even large institutional resources used by many scholars provide little context for their choices of what to include or exclude. These hidden choices are particularly problematic when historical selection factors might have led to the creation of databases which re-create social inequalities. I focus specifically on writing printed in...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">from canon to corpus</p>
<p class="itemText">Play with the idea of the digital revolution? Challenging the simplicity of people’s assumptions about the digital revolution</p>
<p class="itemText">Profusion of print in this decade</p>
<p class="itemText">Revolution -> print culture in revolution -> revolutionary women writers -> and then I am interested in Charlotte Smith in particular</p>
<p class="itemText">Page 4 is very jumpy -- Smith has a long history of contentious reception -- pull out these details. To get to reviewing culture more smoothly. Be more specific about why she might have fallen out of favor ...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">1790s canon debate</p>
<p class="itemText">The problem of evaluating literature is not a new or a simple one. In the eighteenth century, the debate took the form of urgently needing to distinguish ‘trash’ from ‘treasure’. Michael Gamer, in Romanticism and the Gothic: Genre, Reception, and Canon Formation, highlights the role of the eighteenth-century reviewer as a crucial mediator between the writers and readers of books. Importantly, although the assessments take the form of reviews of individual works, Gamer also argues that the critic...</p>
</li>
<li>
<p class="itemTitle">1990s canon debate</p>
<p class="itemText">In other words, Gamer and Taylor both affirm the key conclusion of John Guillory’s Cultural Capital: The Problem of Literary Canon Formation, that “in fact ‘aesthetic value’ is nothing more or other than cultural capital" (332). Guillory’s sociological history of literary canons is a well established part of literary studies, which will take on new dimensions as I apply to to the current moment of digital databases. In the eighteenth century, he argues, the cultural capital of vernacular English...</p>
</li>
<li>
<p class="itemTitle">DH canon debate</p>
<p class="itemText">Perhaps indicating that Guillory was correct, twenty years later, we are still debating the need for “literary criticism … to conceptualize a new disciplinary domain” (Guillory 265), now in the context of computation. The reconceptualization of literary study itself is at the core of Franco Moretti’s coinage of ‘distant reading’: the problem for which “[r]eading ‘more’ seems hardly to be the solution” (“Conjectures” 55) is the problem of conceiving of world literature, rather than the “canonical...</p>
</li>
<li>
<p class="itemTitle">what I'm doing here</p>
<p class="itemText">The relocation of the debate from the canon to the corpus is not without grounds. As this dissertation will explore in depth, challenges to the technological accessibility of texts have created new hierarchies, and a new “great unread.” Each archive represents a unique set of choices in response to the same sets of questions: what to include, why, how; what to make accessible, why, how, to whom; what, in the end, makes a text matter, and what we are meant to do with texts. For example, the Engli...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">frameworks</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">overview</p>
<p class="itemText">My work takes a critical algorithm studies approach to digital databases of eighteenth-century literature, examining the structural assumptions of the most-used resources (including some that scholars don’t like to admit to using). I close read the database structures, file formats, and historical documentation for the English Short Title Catalogue, Eighteenth Century Collections Online, the Text Creation Partnership, HathiTrust, Project Gutenberg, and Google Books, to examine how each resource’...</p>
</li>
<li>
<p class="itemTitle">reparative reading</p>
<p class="itemText">The theoretical frameworks of this dissertation are drawn from the fields of feminist DH and queer DH, and from non-DH schools of thought which seem to offer valuable tools. My core motivating framework, as I conceptualize my work, is that of reparative reading. Eve Sedgwick’s “Paranoid Reading and Reparative Reading” persuasively describes in the dominance of paranoia in literary criticism, and attempts to sketch an alternative in what she terms reparative reading. A paranoid rhetoric of exposu...</p>
</li>
<li>
<p class="itemTitle">felski, surface readers</p>
<p class="itemText">I have mentioned moving away from critique as well as from paranoia: in rethinking the role of critique, I draw upon the work of Rita Felski, and the theories of “surface reading” described by Sharon Marcus, Stephen Best, and Heather Love. Felski, in her article “After Suspicion” and then further in her monograph The Limits of Critique, seeks to attend seriously to literary attachments, including our own attachments as critics. Felski’s approach to these attachments is essentially sociological, ...</p>
</li>
<li>
<p class="itemTitle">computation reveals assumptions</p>
<p class="itemText">Love’s later article, “Close Reading and Thin Description,” provides a more precise articulation of the kind of close reading that she calls for, in which an “exhaustive, fine-grained attention to phenomena” (404) enables “taking up the position of the device; by turning oneself into a camera, one could—at least ideally—pay equal attention to every aspect of a scene that is available to the senses and record it faithfully” (407). Although Love is uninterested in “distant reading” as synonymous w...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTextStart">“The relationship between the individual cultural object and the curated dataset is not a transparent one; the latter is rather a heavily mediated and discipline-specific representation of the former. Through the collection and curation of our own dataset we are acutely aware of the choices that went into its creation. The use of already curated datasets has other undeniable advantages: it may temper the influence of the researcher on his or her findings; furthermore, from a practical standpoint...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">distant reading without Moretti</p>
<p class="itemText">To bring these principles into the field of Digital Humanities by way of an example, I want to offer an alternative geneaology for the practice of distant reading itself. Rachel Buurma and Laura Heffernen provide a valuable history of Josephine Miles as the first ‘distant reader’. Miles’ history, briefly, is as follows:</p>
<p class="itemText">In the 1930s, as a graduate student at Berkeley, she completed her first distant reading project: an analysis of the adjectives favored by Romantic poets. In the 1940s, with the ...</p>
</li>
<li>
<p class="itemTitle">critical algorithm studies</p>
<p class="itemText">What’s crucial, to use computational reading reparatively, is to use it reflectively. The desirable kinds of computation which I describe above will not happen inevitably. Here I draw upon the rich body of work emerging in critical algorithm studies, which examines (and attempts to reform) the human elements of computational algorithms. Any methodology is, to a certain extent, an “algorithm,” in the loose definition of ‘a series of pre-defined steps to be carried out’. But computational algorith...</p>
</li>
<li>
<p class="itemTitle">reparative DH</p>
<p class="itemText">Critical algorithm studies is therefore a crucial background for my work — but “critical” is literally in the name of of the field, and I still seek to be post-critical and reparative. As I encounter the limitations of the various information and tools through which I attempt to understand the 1790s, my goal is to do something other than facilely observe that they are limited. Instead, I want to identify the best ways to continue building on their foundations. In a digital humanities context, a ...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">methods</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">my methods</p>
<p class="itemText">This dissertation undertakes computational distant reading. At every possible point, however, the underlying methodology will be made visible, and its assumptions scrutinized. The bibliographic histories of my multiple corpora are explicit objects of inquiry. Much of the code underlying this project I have written myself. Some has been written at my request. In every case where the code is available to me, the program itself appears in Appendix A (“Codebase”), accompanied by a plain language exp...</p>
</li>
<li>
<p class="itemTitle">capta</p>
<p class="itemText">My attention to the sources of digital knowledge creation comes, in part, from Johanna Drucker, and her distinction between “data” and “capta.” Drucker, in “Humanities Approaches to Graphical Display,” specifically addresses the digital humanities practice of creating, and then close reading, data visualizations. She argues that the tools for visual representation which may be effective in the sciences cannot be simply and uncritically transposed to humanistic subject matter. When an experiment ...</p>
</li>
<li>
<p class="itemTitle">data viz</p>
<p class="itemText">Additionally, all of the figures presented in this dissertation are of my own design. My design praxis is informed by the work of Edward Tufte and Alberto Cairo, both of whom provide practical design advice in service of demystifying the visual rhetoric by which graphs present their arguments. Neither Tufte nor Cairo is a scholar of media studies; rather, they are professional practitioners of ‘data visualization’ who reflect critically on the assumptions of their work. Tufte’s work primarily st...</p>
</li>
<li>
<p class="itemTitle">fruitful models</p>
<p class="itemText">This dissertation understands archives, bibliographies, anthologies, and corpora to all be, variously, models of an imagined object of study. In the language of social science, these models might be described as ‘samples,’ which are intended to permit discoveries about an underlying ‘population’ by being ‘representative’ of that population’s features. Only the language and not the methods of social science need to be imported here, since it has long been ordinary practice in literary studies to ...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">scope</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">1790s</p>
<p class="itemText">All of the computational work in this dissertation aims to identify, in as minute detail as possible, all works printed in England between January 1 1789 and December 31 1799. This eleven-year “decade” was a turbulent one across the Channel, encompassing the whole of the French Revolution, from the Estates General in 1789 to Napoleon’s coup in 1799. In England, these events caused strong and variously nationalist reactions in a country which had so recently lost its colonies in America and feare...</p>
</li>
<li>
<p class="itemTitle">Charlotte Smith</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">intro</p>
<p class="itemText">To navigate the 1790s, I turn to an author whose career and works usefully focalize my core questions of genre, publics, and the status of literature: Charlotte Smith. Smith was highly productive in multiple genres throughout the 1790s, and had a complex and contested literary legacy after the 1790s. As literary scholars re-assess ideas about literary seriousness, popularity, and women’s writing, our assessment of Smith has shifted as well. By examining their bibliographies with computational me...</p>
</li>
<li>
<p class="itemTitle">writing</p>
<p class="itemText">Charlotte Smith is selected as a writer who was productive in multiple genres, only some of which may end up represented in corpora. Charlotte Smith’s literary career began with the publication of her volume of poetry Elegiac Sonnets, in 1784. This work is the one upon which much of Smith’s fame and prestige rested in the eighteenth century. A second edition of Elegiac Sonnets rapidly followed the first in the same year, with only slight amendments. The third and fourth editions of Elegiac Sonne...</p>
</li>
<li>
<p class="itemTitle">life</p>
<p class="itemText">Smith’s personal life sometimes overshadows this career. As her works often make clear to her readers, after a briefly comfortable youth as the daughter of a well-off country gentleman who lived beyond his means, she was married at age sixteen to Benjamin Smith, “son of a prosperous London merchant and owner of Barbados sugar cane plantations. The marriage was contracted hastily to remove her from her paternal home, now dominated by her new wealthy stepmother. Looking back in bitterness nearly f...</p>
</li>
<li>
<p class="itemTitle">scholarship</p>
<p class="itemText">Smith’s posthumous critical reception has undergone multiple shifts in appreciation and obscurity. Duckling’s study of her presence in anthologies indicates that shortly after her death in 1806, Smith was widely eulogized and anthologized, remembered and emulated as an important British poet. As the nineteenth century went on, poetesses began to be anthologized separately from poets, in collections with ambitions that were commercial rather than intellectual; Smith, too, “lost intellectual groun...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">databases</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">intro</p>
<p class="itemText">A core object of study for this dissertation is the makeup and history of contemporary digital databases. Eighteenth-century materials of various kinds have been collected in many digital archives, of very different scopes. I will draw materials from the English Short-Title Catalogue (ESTC), Eighteenth Century Collections Online (ECCO), the ECCO Text Creation Partnership corpus (ECCO-TCP), Google Books, Project Gutenberg and HathiTrust. My examination of these six databases will, of necessity, e...</p>
</li>
<li>
<p class="itemTitle">scholarly archives</p>
<p class="itemText">The first three databases I examine will be no surprise to eighteenth-century scholars: ESTC, ECCO, and ECCO-TCP. Gale’s Eighteenth Century Collections Online (ECCO), contains over 180,000 titles 1701-1800, of which 42,000 were printed in England between 1789 and 1799. ECCO is itself (mostly) a subset of the broader English Short Title Catalogue (ESTC), which contains more 460,000 texts 1473-1800, of which 51,965 were printed in England between 1789 and 1799 (indicating that nearly 10,000 titles...</p>
</li>
<li>
<p class="itemTitle">micro archives</p>
<p class="itemText">Smaller collections allow for more scholarly curation, but have corresponding limitations. Whereas the ‘main players’ of the the mega-archives can be easily enumerated, these specialized collections are numerous. Some will focus on particular kinds of texts, such as the Early Novels Database (2,041 novels 1700-1799) or Broadside Ballads Online (more than 30,000 broadside ballads). Others exhaustively index particular publications, such as The Hampshire Chronicle (1,950 references to fiction in i...</p>
</li>
<li>
<p class="itemTitle">Google Books</p>
<p class="itemText">Instead, I look at a set of larger archives of more contested “scholarly” status: Google Books, Project Gutenberg, and HathiTrust. Google Books may be the most infamous database of books. In a scholarly context, one hesitates even to designate this as an “archive,” particularly in the same breath as resources like ECCO: books of all kinds are scanned indiscriminately with only the bare minimum of roughly accurate metadata collected about them. These rapidly scanned books are prone to unpredictab...</p>
</li>
<li>
<p class="itemTitle">Project Gutenberg</p>
<p class="itemText">Also in the category of smaller and specialized archives is Project Gutenberg. Project Gutenberg makes no claims to scholarly reliability but nonetheless underlies a not-significant amount of scholarly work — its cultural capital as a resource lags far behind its use and utility. Project Gutenberg is easily conceived of as a haphazard, ‘unscholarly’ source for materials, but unlike Google Books, Project Gutenberg actually does have selection criteria. Project Gutenberg will only collect public d...</p>
</li>
<li>
<p class="itemTitle">HathiTrust</p>
<p class="itemText">What makes Google Books of interest in the context of this dissertation is its relationship to HathiTrust, an increasingly popular resource for scholars. HathiTrust’s collection contains digitized content from “a variety of sources, including Google, the Internet Archive, Microsoft, and in-house member institution initiatives.” The “in-house member institutions” include one hundred and fifty-five universities, colleges, and consortia of universities. The aggregate scholarly authority of these in...</p>
</li>
<li>
<p class="itemTitle">Gutenberg</p>
<p class="itemText">HathiTrust’s success in acquiring scholarly capital stands in interesting contrast with Project Gutenberg’s continued lack of cachet. Project Gutenberg is used in research with similar frequency to Google Books’ n-gram tool, but scholars often mention Project Gutenberg with a note of apology for not having found a better source. Its cultural capital as a resource lags far behind its actual use and utility, likely, I argue, because its organizing principles are the ‘unserious’ ones of popularity ...</p>
</li>
<li>
<p class="itemTitle">conclusion</p>
<p class="itemText">As this brief survey of eighteenth-century digital archives shows, there is no ‘perfect’ corpus for large scale study of eighteenth-century texts.  Moreover, I argue, the imperfect samples which each archive provides are shaped not only by historical factors of eighteenth-century print culture, but also by contemporary digital culture. Each archive represents a unique set of choices in response to the same sets of questions: what to include, why, how; what to make accessible, why, how, to whom; ...</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">dissertation map</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">chapter 2: Smith</p>
<p class="itemText">Chapter two describes in more detail the databases to be studied, and examines Charlotte Smith and the ways that her writing is made accessible today. The specific experimentation undertaken in chapter two tests the basic assumptions and methods of my project. I begin with a the histories of the ESTC, ECCO, ECCO-TCP, Project Gutenberg, Google Books, and HathiTrust: highlighting the chronological relationships between these resources can explain each database’s scope and technical implementation....</p>
</li>
<li>
<p class="itemTitle">chapter 3: databases</p>
<p class="itemText">In chapter three, I re-examine my core databases, but no longer with Smith as a focalizing lens. Instead, I undertake computational assessment and comparison of the databases’ contents. My research examines the authorship and subject matter (broadly construed) of all titles printed in England between 1789 and 1799 which are included in each database. I calculate the proportion of the titles in each resource that are attributed to men, to women, or are left unsigned. My naive hypothesis is that, ...</p>
</li>
<li>
<p class="itemTitle">chapter 4: random selection</p>
<p class="itemText">In my fourth chapter, I playfully attempt what might be considered a devil’s advocate method of textual selection: pure random sampling. Using a random number generator, I select arbitrary texts to close read, and weave together a narrative of 1790s print from their contents. Much of my work will involve defining and justifying the parameters for my random selection — ESTC, or a full-text database? How many texts? From which years? — but once I have taken my sample, I will not re-sample. For eac...</p>
</li>
<li>
<p class="itemTitle">conclusion</p>
<p class="itemText">A final brief conclusion to this dissertation offers an assessment of the role of digital textual collections in contemporary literary study.</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">the moving target has been moving since the 1970s</p>
<p class="itemText">“One implication of the publication history of short-title catalogues is that they have been deemed functional and valuable even before they were complete. (That estimation is crucial, for their full completion is for all practical purposes impossible.) Judging that even a preliminary form of the records was useful to scholars, the planners of ESTC determined to conduct its development ‘in full public view’ and to make the incomplete file available ‘warts and all’ (in the words of Henry Snyder a...</p>
</li>
<li>
<p class="itemTitle">lit review: eds of digital systems</p>
<p class="itemText">Increasingly, projects do in fact actively theorize and address their datasets.</p>
<p class="itemText"></p>
<p class="itemText">Mark Vareschi and Mattie Burkert, for example, in “Archives, Numbers, Meaning: The Eighteenth-Century Playbill at Scale,” have an argument to make about eighteenth century theatrical genres, but also “theorizing a new dataset of our own creation as a description that mediates and transforms our relationship to the objects it describes” (598). ”Our study shows the need to attend to the unstable ontologies present in ...</p>
</li>
<li>
<p class="itemTitle">why 1790s?</p>
<p class="itemText">Some limiting factor was necessary to make this project feasible from a technical standpoint. I needed to define a small enough scope that I could attempt something like comprehensiveness within that scope. I also knew that for many of the databases I wanted to use, I would not be able to access their full records, but samples of up to roughly 50,000 records had been given to other scholars (based on other papers I saw people publish on the ESTC). I decided that roughly a decade would give me en...</p>
</li>
<li>
<p class="itemTitle">popular / normal</p>
<p class="itemText">The meaning of “popular” shifts depending on what is conceived of as its “opposite.” Is it an aesthetic category, popular vs highbrow, Gothic novel vs poetry? Is is a sociological/economic term, popular vs elite, ballads and chapbooks vs books? Is it tied to reception, popular vs unpopular, Udolpho vs The Two Emilys? Or tied to legacy, popular vs forgotten, Lyrical Ballads vs The Lemon? I am interested in all of these varying definitions of popularity because they are all tied to what actually i...</p>
</li>
<li>
<p class="itemTitle">why CSmith?</p>
<p class="itemText">In addition to being a prolific and interesting writing who was prominent across multiple genres (of which there are many other authors), Charlotte Smith offers an interesting case study in a ‘successful’ recovery project. This allows me to ask: to what extend do research infrastructures ‘lag behind’ scholarly consensus? No eighteenth centuryist is now likely to say that Smith is irrelevant or unimportant to the period. In the infrastructure of literary canons as described by Guillory, she has c...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">the genre thing</p>
<p class="itemText">Smith is also self-consciously navigating a series of questions about genre that interest me, namely, the fact that not everybody reads everything, or for the same reasons — she is not the same author from genre to genre.</p>
<p class="itemText">“Very few Smith scholars work actively on both the novels and the poetry, and consequently we have been learning about two separate Smiths, each closely linked to the genre she writes in, neither closely linked to the other. Because the novel during the Romantic period is under...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">disciplinary infrastructure</p>
<p class="itemText">“But however essential it is for data-rich literary history, modeling cannot be the sole foundation for the field. Models of literary systems are not simply arguments about the existence of and connections between literary works in the past; they are arguments made with reference to the disciplinary infrastructure—the bibliographies and collections, analog and digital—that transmit evidence of past works and relationships to the present. Modeling, even when integrated with descriptive bibliograp...</p>
</li>
<li>
<p class="itemTitle">locally distant</p>
<p class="itemText">One of Underwood’s contentions is that “we understand [literary] history, locally, very well,” (31) and the role of computational study is to examine the large-scale trends which would join together the individual moments of literary history. This dissertation, however, attempts to study a very local moment with a larger body of evidence than is usually feasible to examine.</p>
</li>
<li>
<p class="itemTitle">blog post: state of books in the world</p>
<p class="itemText">The problem of textual selection— the paired difficulty and importance of deciding which few books one will actually read— is an urgently meaningful problem in the “real world,” outside the realms of academia. A common solution is one which will likely alarm and distress most scholars who have dedicated themselves to thinking through canonical selection, or even the construction of a syllabus: a solution which could perhaps be called ‘radical impatience.’ Consider, for example, the following adv...</p>
</li>
<li>
<p class="itemTitle">Bode on Underwood & Hathi</p>
<p class="itemText">“Of the data-rich literary history projects discussed in this chapter, Underwood and Sellers’s work on changing standards of literary prestigePage 51 → most consistently enacts the curatorial elements present elsewhere in digital humanities, not least in terms of data publication. As the authors explain in an online working paper on the project, its most time-consuming element was not training their supervised model but constructing their dataset: identifying the different subgenres—poetry, pros...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="topLevelItemTitle">ch 1 - historical set-up</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">ch 1 - historical set-up</p>
</li>
<li>
<p class="itemTitle">database histories</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">introduction: it's all about labour</p>
<p class="itemText">In the next section I will close read the implicit models underlying each database, to examine how each enforces a particular concept of “literature” and “a text.” However, before these models can make sense, we must understand the history of how they were built. I contend that each database is best understood as a negotiation between the noncommercial values of textual reproduction and [capitalism]. Each database has the goal of making valuable information available. After the 1990s, they are p...</p>
</li>
<li>
<p class="itemTitle">ESTC timeline history</p>
<p class="itemText">The history of the English Short-Title Catalog is long, as befits its enormous scope. “The English Short-Title Catalog (ESTC) is a vast database designed to include a bibliographic record, with holdings, of every surviving copy of letterpress produced in Great Britain or any of its dependencies, in any language, worldwide, from 1473-1800” (CBSR). Today, “The English Short-Title Catalogue is the most comprehensive record of what has appeared in print in Britain and the English-speaking world for ...</p>
</li>
<li>
<p class="itemTitle">ECCO timeline history</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">tie to ESTC</p>
<p class="itemText">To understand the history of the ESTC and ECCO, we actually need to begin with another resource: Early English Books Online, or EEBO.</p>
<p class="itemText"></p>
<p class="itemText">“EEBO’s relationship with the original STC and Wing is straightforward and clear; EEBO’s relationship with electronic ESTC, on the other hand, is less well-known.20 A series of agreements made between ESTC and University Microfilms/ProQuest between 1989 and 1997 allowed EEBO to draw directly on ESTC’s existing bibliographical data. Consequently, / every search ru...</p>
</li>
<li>
<p class="itemTitle">corporate history</p>
<p class="itemText">Began as Research Publications, Inc in 1981, which began the Eighteenth Century Collection in 1983. Their rival was University Microfilms. RP became Thomson Gale, now Gale Cengage. UM became ProQuest.</p>
<p class="itemText"></p>
<p class="itemText">By 1997, Research Publications, Inc had become Primary Source Media. (LOC http://id.loc.gov/authorities/names/n98069963.html) In September 1998, “the Thomson Corporation [merged] three of its electronic and reference publishing subsidiaries—Gale Research, Information Access Company (IAC), and Prim...</p>
</li>
<li>
<p class="itemTitle">ECC microfilm</p>
<p class="itemText">1983 Eighteenth Century Collection microfilm begins to be produced by Research Publications, Inc</p>
<p class="itemText"></p>
<p class="itemText">EEBO: “unlike scholarly facsimile editions, the selection process for microfilming was often arbitrary. Copies were selected primarily by reference to the copies listed in STC and Wing, with particular preference for certain major collections; they were not selected because they were considered representative of a particular edition. By bringing together the bibliographical record for an edition and...</p>
</li>
<li>
<p class="itemTitle">ECC -> O</p>
<p class="itemText">ECCO, as a distinct resource, is a historic latecomer compared to EEBO. The initial microfilms were created in [???] by [???]. In 2003, Thomson Gale began making digital copies of the Eighteenth Century Collection microfilms available to subscribers online. The digital images were made from the microfilm masters, which were 400 dpi, and thus higher resolution than the microfilm copies. </p>
<p class="itemText"></p>
<p class="itemText">“the move from microfilms to the Internet has meant easier searching, easier physical access, easier manipula...</p>
</li>
<li>
<p class="itemTitle">Part II</p>
<p class="itemText">“Part I includes 135,000 printed works, comprising more than 26 million scanned facsimile pages.” (Gale, “Part I”) “From books and directories to bibles and sheet music to sermons and pamphlets, Eighteenth Century Collections Online, Part II features a variety of materials to provide a critical tool for both faculty research and classroom use. With more than fifty thousand new titles of previously unavailable or inaccessible materials, Eighteenth Century Collections Online, Part II is an essenti...</p>
</li>
<li>
<p class="itemTitle">Gale DSL</p>
<p class="itemText">In late 2019, Gale began allowing access to a new interface, the Gale Digital Scholar Lab, which dramatically changed the forms of access available for ECCO texts. It became possible not only to see the underlying OCR for texts, but to run pre-built text mining on it, and to download the OCR as text files. The only limit to downloading is that only 10,000 texts may be downloaded at a time, but as long as the desired corpus can be defined as “collections” in chunks of 10,000 or less, any number o...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">TCP timeline history</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">1999 creation</p>
<p class="itemText">“The Text Creation Partnership started, in 1999, as a collaboration between the university libraries of Michigan and Oxford, the Council on Library and Information Resources, and the publisher of Early English Books Online, Proquest. The aim was to create high quality ‘standardized, digitally-encoded electronic text editions’ starting with 25,000 titles from Early English Books Online.” (Gregg n. pag.)</p>
<p class="itemText">“The Text Creation Partnership was conceived in 1999 between the University of Michigan Librar...</p>
</li>
<li>
<p class="itemTitle">2005 ECCO-TCP</p>
<p class="itemText">“EEBO-TCP met its goal of producing 25,000 books in 2009 (thereafter known as “EEBO-TCP Phase 1”), and then undertook work on a second phase to convert the first edition of each remaining unique monographic work in EEBO—another 40,000 or so books, for a total of around 70,000, if all hopes were realized.” (TCP “About”)</p>
<p class="itemText">“In 2005, the TCP executive board and staff sought to expand the TCP model to other databases of historical books, namely, Gale Cengage’s Eighteenth-Century Collections Online (EC...</p>
</li>
<li>
<p class="itemTitle">Phase II EEBO</p>
<p class="itemText">“Begun in 2009, Phase II both shrank and expanded the scope of EEBO TCP.  Selection became more discriminating and focused more on English-language (and Welsh- and Gaelic-language) texts to the exclusion of French and Latin titles, and also set aside the serials (periodicals) as a fit project for another time. But within the constraints of English-language monographic titles, it aspired to something approaching comprehensive treatment: EEBO Phase II planned to convert each and every unique work ...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">PG timeline history</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">book creation</p>
<p class="itemText">Project Gutenberg began in 1971 with one individual, Michael Hart, who did not begin with a specific project vision in mind. From the beginning, then, Project Gutenberg was not goal-oriented in the same way as the other resources under discussion. By this I mean that Project Gutenberg orients itself toward goals of a fundamentally different kind than the goals which structure other textual archives, not that it has no goal. Project Gutenberg is, in general, subject to being dismissed as unseriou...</p>
</li>
<li>
<p class="itemTitle">Distributed Proofreaders</p>
<p class="itemText">“A fast growth thanks to Distributed Proofreaders, a website launched in October 2000 by Charles Franks to share the proofreading of books between many volunteers. Volunteers choose one of the books listed on the site and proofread a given page. They don't have any quota to fulfill, but it is recommended they do a page per day if possible. It doesn't seem much, but with hundreds of volunteers it really adds up.” (Lebert)</p>
<p class="itemText">“In 2002 Distributed Proofreaders became part of Project Gutenberg.” (Hosch...</p>
</li>
<li>
<p class="itemTitle">spinoffs</p>
<p class="itemText">Because the texts are available without restrictions, a number of [spin-off] websites exist, some of which extend PG’s mission and some of which are slightly exploitative. On the most purely beneficial side are website “mirrors,” which duplicate the contents of the website in order to distribute the costs of hosting and to make sure that the texts remain accessible even if the “primary” Project Gutenberg website goes down. Also in keeping with Project Gutenberg’s core mission are projects which ...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">list</p>
<p class="itemText">All directly quoted from “Partners, Affiliates and Resources”</p>
<p class="itemText"></p>
<p class="itemText"></p>
<p class="itemText"></p>
<p class="itemText">2 Sister Projects</p>
<p class="itemText">2.1 Project Gutenberg of Australia</p>
<p class="itemText">2.2 Project Gutenberg of Canada</p>
<p class="itemText">2.3 Projekt Gutenberg DE</p>
<p class="itemText">2.4 Project Gutenberg Europe</p>
<p class="itemText">2.5 Project Gutenberg Self Publishing Portal</p>
<p class="itemText">2.6 Projekt Runeberg</p>
<p class="itemText">2.7 ReadingRoo.ms</p>
<p class="itemText"></p>
<p class="itemText">3 Affiliates</p>
<p class="itemText">3.1 ClassicalArchives.com</p>
<p class="itemText">3.2 The Internet Archive</p>
<p class="itemText">3.3 Librivox.org</p>
<p class="itemText">3.4 LiteralSystems</p>
<p class="itemText">3.5 ManyBooks.net</p>
<p class="itemText">3.6 The Online Books Page</p>
<p class="itemText">3.7 Outernet</p>
<p class="itemText">3.8 RocketReader.com</p>
<p class="itemText">3.9 Wattpad</p>
<p class="itemText"></p>
<p class="itemText">4 Links to locations...</p>
</li>
<li>
<p class="itemTitle">CD/DVD project</p>
<p class="itemText">“PG has been giving away CDs and DVDs; a volunteer mails them out for free on request.” (Hane)</p>
<p class="itemText"></p>
<p class="itemText">Wikipedia: ”In August 2003, Project Gutenberg created a CD containing approximately 600 of the "best" e-books from the collection. The CD is available for download as an ISO image. When users are unable to download the CD, they can request to have a copy sent to them, free of charge.</p>
<p class="itemText">In December 2003, a DVD was created containing nearly 10,000 items. At the time, this represented almost the entire col...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">institutional support</p>
<p class="itemText">In 2000, Distributed Proofreaders was founded. Also “In 2000, a non-profit corporation, the Project Gutenberg Literary Archive Foundation, Inc. was chartered in Mississippi, United States to handle the project's legal needs. Donations to it are tax-deductible. Long-time Project Gutenberg volunteer Gregory Newby became the foundation's first CEO.” (Wikipedia)</p>
<p class="itemText"></p>
<p class="itemText">At some point Carnegie Mellon University agreed to administer the project’s finances.</p>
<p class="itemText">It’s currently hosted by ibiblio at UNC Chapel Hill....</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">PGII ?</p>
<p class="itemText">In 2004, there was some discussion of spinning off a PGII with the World eBook Library. “The co-founders say that PG 2 came from the need to include existing e-book collections, such as those found in schools, universities, and professional and religious organizations. Many such e-books do not fall into the acceptable criteria of Project Gutenberg. "For those books, PG 2 was created to find a home. PG 2 is a consortium of collections. Our vision is to create an additional portal where a broader ...</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">GB timeline history</p>
<p class="itemText">“…one can certainly argue that the project is as old as Google itself. In 1996, Google co-founders Sergey Brin and Larry Page were graduate computer science students working on a research project supported by the Stanford Digital Library Technologies Project. Their goal was to make digital libraries work, and their big idea was as follows: in a future world in which vast collections of books are digitized, people would use a “web crawler” to index the books’ content and analyze the connections b...</p>
</li>
<li>
<p class="itemTitle">Hathi timeline history</p>
<p class="itemText">“The vast majority of those digitized books-around 95 percent, as of mid-2017- had originally been scanned as part of the Google Books project; the agreements that Google Books entered into with the libraries typically stipulated that Google had to provide the library with a digital copy of each book scanned from that library.” (Bauder)</p>
<p class="itemText">“When Google partnered with university libraries to scan their collections, it had agreed to give them each a copy of the scanning data, and in 2008 the HathiTru...</p>
</li>
<li>
<p class="itemTitle">synthesizing histories</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">summary</p>
<p class="itemText">To review all of these events, <$n#table:databases-timeline> shows the milestones of all of these databases in chronological order.</p>
</li>
<li>
<p class="itemTitle">commercialization</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">EEBO ProQuest</p>
<p class="itemText">“ProQuest is to be commended for its attitude to the wider scholarly community.27 EEBO is a commercial product but nonetheless there is an encouraging and genuine wish to engage with its users. This ranges from the active monitoring and rapid responding to queries submitted via its ‘Webmaster’ form to informal and formal consultations with students, scholars, and other users. EEBO representatives appear at – and often sponsor – academic events. Content is frequently corrected, updated, expanded ...</p>
</li>
<li>
<p class="itemTitle">ECCO</p>
<p class="itemText">“It is perhaps the inconsistency of the OCR readings, obvious from this rough assessment, that makes Gale bashful about the restricted files. The editors of the ESTC confess to their public resource being a construction site in a way that the proprietors of private, commercial websites like ECCO prefer not to. But few really mind these days, especially if improvements are seen to be ongoing. Gale should be more relaxed about the incompleteness of their work, though perhaps not quite so relaxed a...</p>
</li>
<li>
<p class="itemTitle">Bullard</p>
<p class="itemText">“Viewing the field of eighteenth-century digital humanities as a single prospect, it is the contrast between publicly funded, open-access sites, and privately owned, subscription- access resources that is most striking. Each side of the divide has much to learn from the other. Publicly funded academic projects must acquire the pragmatism and ambitiousness of scale that commercial developers have always shown. Commercial developers must adapt themselves more generously to the principles of schola...</p>
</li>
<li>
<p class="itemTitle">TCP public / private</p>
<p class="itemText">Two questions in the FAQ, “Why would I buy something that is achievable only if others do the same?” and “Why would I buy something that is going to become freely available?” taken together imply the speculative and ambitious nature of the original project. In the official answers provided to these evidently frequently asked questions, there is a sense that the project posed a prisoner’s dilemma: every individual institution’s “best” move, from a game theory perspective, was to contribute nothin...</p>
</li>
<li>
<p class="itemTitle">employment/labor</p>
<p class="itemText">“Members of the Board also felt that TCP should complete an equity review of all of its employees to see what salaries are being offered from other universities and whether TCP’s salaries are in-line with what is being offered elsewhere. It was suggested that TCP might want to do a 10% raise across the board for all reviewing staff that remain with the project for five years.” (TCP Executive Board, Meeting Minutes 2005-10-20) In the next year, “Mark also reported on one item from the previous Bo...</p>
</li>
<li>
<p class="itemTitle">HathiTrust copyright</p>
<p class="itemText">Wikipedia: “In September 2011, the Authors Guild sued HathiTrust (Authors Guild, Inc. v. HathiTrust), alleging massive copyright violation.[12] A federal court ruled against the Authors Guild in October 2012, finding that HathiTrust's use of books scanned by Google was fair use under US law.[13] The court's opinion relied on the transformativeness doctrine of federal copyright law, holding that the Trust had transformed the copyrighted works without infringing on the copyright holders' rights. T...</p>
</li>
<li>
<p class="itemTitle">Google</p>
<p class="itemText">In 2005 the TCP was thinking about themselves as competing with Google: “John Price-Wilkin, Associate University Librarian for Library Information Technology & Technical and Access Services, was a guest of the Board to talk about issues relating to the Google initiative and TCP’s role in promoting “enhanced” product to the library and academic community. TCP does have an important role in noting that OCR text, though good for many things, cannot serve all purposes scholars need, and TCP should c...</p>
</li>
<li>
<p class="itemTitle">PG manifesto</p>
<p class="itemText">The Project Gutenberg mission has always been focused on freely giving away things which were acknowledges to have financial value. After all, Hart’s goal was to “pay back” the $100,000,000 he had been given in computing time — giving away ebooks would generate and give away this financial value. But even in seeking to “pay back” there is an impulse behind Project Gutenberg which exceeds [capitalism]. The explanatory documents of the project, when it became a major volunteer undertaking in the 1...</p>
</li>
<li>
<p class="itemTextStart">are they really making money or do they just think they are</p>
</li>
<li>
<p class="itemTextStart">“Proprietary mass-digitized collections such as Google Books, Early English Books Online, and The British Newspaper Archive (owned by Google, ProQuest, and findmypast, respectively) are increasingly used in humanities research. But their scope and scale—let alone the histories of transmission that produce them—can be very difficult to discern; indeed, the commercial imperatives of these enterprises arguably depend on them presenting these collections as comprehensive.” (Bode 47)</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">I should probably add/address Internet Archive and HathiTrust essentially violating their copyright agreements for coronavirus</p>
</li>
</ul>
<hr class="afterTitle"/>

<li>
<p class="itemTitle">table:databases-timeline</p>
<p class="itemText">1918 Pollard first proposes a “short-title handlist”</p>
<p class="itemText">1926 Pollard and Redgrave Short-Title Catalogue for 1476–1640</p>
<p class="itemText">1938 Eugene B. Power founds University Microfilms</p>
<p class="itemText">1945 Wing starts collecting his STC, 1641–1700</p>
<p class="itemText">1951 Donald Wing’s catalogue for 1641–1700, first edition</p>
<p class="itemText">1971 First text in what would be Project Gutenberg. Over the next twenty years, Michael Hart personally keyed the first hundred books.</p>
<p class="itemText">1972 Beginning of second ed of Wing STC, 1641–1700</p>
<p class="itemText">1976 Proposal for Eighteenth Century Short T...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">1790s women history</p>
</li>
</ul>
<hr class="afterTitle"/>

<li>
<p class="topLevelItemTitle">ch 2 - Charlotte Smith</p>
<p class="itemText">Chapter Two</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">intro</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">BLUF</p>
<p class="itemText">Ian Gadd argues that critiques of digital databases are often not based on the right grounds: “the real risk of scholarly misuse of [Early English Books Online] is less to do with the physical features of early printed books that it fails, one way or another, to represent (problematic though these are) and more to do with a lack of an informed knowledge of what exactly EEBO is.” (Gadd 682) The observation applies far beyond EEBO: although it is easiest to critique digital resources for their fai...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">Smith in databases</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">defining terms</p>
<p class="itemText">For the purposes of this chapter, I examine Smith’s works which fall outside this dissertation’s decade of interest. As Table <$n#table:Smith-4dbs> shows, Smith’s publishing career began in 1784 and continued until her death in 1806; when I refer to Smith’s “full” output, I consider all 47 editions of her works published in her lifetime or in the year immediately following her death. Her 1790s output (that is, the editions published 1789-99) consists of 30 of those editions.  I have slightly exp...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">table:Smith-4dbs</p>
<p class="itemText"></p>
<p class="itemText">Table <$n:table:Smith-4dbs>: All editions of Charlotte Smith’s works published in England during her lifetime or in the year immediately following her death, and their inclusion in the ESTC, ECCO, ECCO-TCP, and HathiTrust databases.</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">winnowing down (4 dbs)</p>
<p class="itemText">Figure <$n#fig:Smith-4dbs-alluvial> shows how Smith’s presence in four major databases has the effect of winnowing down her full output arbitrarily. Even the largest collection, the 42 editions included in the ESTC, is not comprehensive: since the ESTC does not include any works published after 1800, it excludes volumes 4 and 5 of Letters of a Solitary Wanderer (1802), three works for children (Conversations, Introducing Poetry, 1804; History of England, 1806; and Natural History of Birds, 1807)...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">fig:Smith-4dbs-alluvial</p>
<p class="itemText"></p>
<p class="itemText">Figure <$n:fig:Smith-4dbs-alluvial>: An alluvial chart, showing the winnowing down of Smith’s works from database to database. Of the 47 editions printed in England between 1784 and 1807, 42 are included in the ESTC, and 5 do not appear in the ESTC because they were printed after 1800 and thus fall outside its purview. ECCO contains 37 of Smith’s 47 editions, all of which also appear in the ESTC. ECCO is missing the 5 editions not listed in the ESTC (since it, too, does not contain works past 1...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">Smith in PG</p>
<p class="itemText">Only one of Charlotte Smith’s works is available in Project Gutenberg: Emmeline, the Orphan of the Castle (first published 1788).</p>
</li>
<li>
<p class="itemTitle">Smith at U of T</p>
<p class="itemText">Searching the ESTC for records which both have “Toronto” in the library name and “Charlotte Turner” in the author name turns up two records: volume one of Rural Walks (1795) and Minor Morals (1798), both held at the Toronto public library. The Toronto Public Library catalogue has two distinct author identities for “Smith, Charlotte Turner, 1749-1806, author.” and for “Smith, Charlotte, 1749-1806,” and the special collections holdings only appear under the latter name (making them initially diffi...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">database models</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">method vs source</p>
<p class="itemText">Mark Merry’s Designing Databases for Historical Research as a rich entrypoint for historians to learn about database construction, in particular the chapter on “Conceptual models of database design” that contrasts “source-oriented” and “method-oriented” models:</p>
<p class="itemText">“The Source-oriented model of database design dictates that everything about the design of the historical database is geared towards recording every last piece of information from the sources, omitting nothing, and in effect becoming a di...</p>
</li>
<li>
<p class="itemTitle">ESTC model</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">edition & ideal copy</p>
<p class="itemText">One reason that it can be informative to close-read the data structures of a resource like the ESTC is that a resource’s categories of knowledge are driven by the uses to which it expects that knowledge to be put. Examining the implicit assumptions that will make a given organization of knowledge seem logical, we can work backwards to the purpose of mission of the initial knowledge creation. Thus Tabor describes the data structure and the mission of the ESTC in a single statement: “ESTC’s most b...</p>
</li>
<li>
<p class="itemTitle">data structure</p>
<p class="itemText">So, how do these ideas of the edition and the ideal copy shape the data structures employed in the building of the ESTC? Consulting an individual ESTC record in the online database, as we can see in Figure <$n#fig:estc-emigrants-record>, reveals a lot of information all pointing ‘outside’ of the ESTC itself. It begins with six details which will be present for every title: the “System Number” and “Citation Number” uniquely identifying the record; the author; the title; the publication informatio...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">fig:estc-emigrants-record</p>
<p class="itemText">Figure <$n:fig:estc-emigrants-record>: A screencap of the ESTC record for Charlotte Smith’s The Emigrants (1793).</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">searching</p>
<p class="itemText">There are several different ways to search ESTC records. The “Search” button takes a user to the “Basic Search” function, from which there are also links to “Advanced Search,” “Browse,” and “Browse Libraries List” (which takes the user to the identical page as “Browse” but with “Library name” pre-selected as the index to browse). Once you have found a work of interest, however, several new forms fo searching become available, implied in the hyperlink formatting: almost any field in the entry can...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">ECCO model</p>
<p class="itemText">An edition being “included” in ECCO looks different from its inclusion in the ESTC — whereas the ESTC lists just one record for each multivolume work, ECCO lists each volume separately, with links to the other volumes available in the “full citation” for the volume.</p>
<p class="itemText"></p>
<p class="itemText">“Such consideration for users is sadly rather less visible with EEBO’s eighteenth-century equivalent ECCO. Unlike EEBO, ECCO presents users with a single, cropped page. In so doing, it has taken the opportunity to remove every blank...</p>
</li>
<li>
<p class="itemTitle">TCP model</p>
<p class="itemText">Although the ECCO-TCP now seems obviously built for text-mining distant reading, in fact it is largely organized around searching and consulting individual works.</p>
<p class="itemText"></p>
<p class="itemText">“ECCO natively supports OCR-based full-text searching of this corpus. This is significant because it meant that unlike EEBO-TCP (which produced searchable text where there was previously none at all), ECCO-TCP could only hope to produce more accurate text (and more reusable text) than what was already available. The larger size of ECC...</p>
</li>
<li>
<p class="itemTitle">Hathi model</p>
<p class="itemText">Wikipedia: “PageTurner is the web application on the HathiTrust website for viewing publications.[17] From PageTurner readers can navigate through a publication, download a PDF version of it, and view pages in different ways, such as one page at a time, scrolling, flipping, or thumbnail views.[17][18]”</p>
<p class="itemText"></p>
<p class="itemText">See: https://www.hathitrust.org/technology</p>
<p class="itemText">See: https://search-proquest-com.myaccess.library.utoronto.ca/results/58AF728D91BD440DPQ/false?accountid=14771</p>
</li>
<li>
<p class="itemTitle">PG model</p>
<p class="itemText">The structuring principle of Project Gutenberg is its missions to make books available for pleasure reading. I argue that its core concept, analogous to the “edition” in the ESTC, or the “book” in ECCO and HathiTrust, is the “story.” Many of the priorities of Project Gutenberg which seem incompatible with scholarly approaches to textual history are explained by thinking of Project Gutenberg as being structured around “stories” rather than “books.”</p>
<p class="itemText"></p>
<p class="itemText">“At the end of 1993, Project Gutenberg's eTexts...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">usage</p>
<p class="itemText">The article ”Quantitative patterns of stylistic influence in the evolution of literature” uses Project Gutenberg — do mathematicians not know what a good source of literature is, or do they know better than us?</p>
<p class="itemText"></p>
<p class="itemText">Cite Hammond’s book re: comparing modernists to bestsellers — he can’t always find bestsellers, it depends on whether bestsellers were enjoyed enough for someone to bother to type them up</p>
</li>
<li>
<p class="itemTitle">I trust Project Gutenberg more than I trust HathiTrust</p>
</li>
</ul>
<hr class="afterTitle"/>

<li>
<p class="itemTitle">GB model</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">GB chooses to be bad</p>
<p class="itemText">Google Books prioritizes low-quality information over no information. The algorithmic extraction of publication dates from title pages, for example, can never be perfect. But algorithms give their predictions with certainty estimates: if accuracy was a higher priority, Google Books could calibrate the algorithm to simply provide no answer when none of the possibilities cross a given certainty threshold.</p>
<p class="itemText"></p>
<p class="itemText">Per http://languagelog.ldc.upenn.edu/nll/?p=1701 , they actually OVERWRITE metadata provided...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">database selection</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">ESTC selection</p>
<p class="itemText">“It has been difficult to consider playbills at scale because they were excluded from the catalogs that form the basis for mass digitization efforts. The absence of playbills from Eighteenth-Century Collections Online (ECCO), as well as from its pre-1700 counterpart Early English Books Online (EEBO), is a result of the decision, as reported by R. C. Alston, not to include them in the English Short Title Catalog (ESTC) on which those collections are built.” (Vareschi and Burkert 600 — citing R. C...</p>
</li>
<li>
<p class="itemTitle">ECCO selection</p>
<p class="itemText">“while ESTC may be based on two thousand public and private libraries worldwide, the Eighteenth Century microfilm series is based on books from only a tiny fraction of that number - almost certainly less than twenty libraries, and rarely anywhere other than the British Library, the Bodleian, Harvard, and the Hunt” (Spedding 440)</p>
<p class="itemText"></p>
<p class="itemText">The “microfilm series is not a random - and therefore randomly representatve— selection of items from ESTC. Texts have been selected for filming on the basis of criteri...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">ECCO subject headings</p>
<p class="itemText">”subject heading assignment is pragmatic and heuristic rather than an exercise in truth and accuracy. …normally the question to be asked is whether they are good or bad, helpful or irrelevant, rather than true (accurate) or false (incorrect). The assignment of subject headings cannot and need not conform to the same standards that apply to descriptive bibliography in the tradition of W. W. Greg and Fredson Bowers. What descriptive accuracy is to cataloging and bibliography, consistency is to the...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">TCP selection</p>
<p class="itemText">What is in the TCP? Well, when active transcription was taking place, “users (especially those affiliated with partner libraries) were welcome to request works from EEBO that had not yet been keyed, and that their requests would go to the top of the queue” (TCP “FAQ”). So — the TCP contains whatever individual works happened to interest particular scholars.</p>
<p class="itemText"></p>
<p class="itemText">The TCP, unlike the ESTC and ECCO, intentionally avoids including multiple editions of a given work. This decision was a pragmatic one moti...</p>
</li>
<li>
<p class="itemTitle">Gutenberg selection</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">PG selection</p>
<p class="itemText"></p>
<p class="itemText"></p>
<p class="itemText">“There are three portions of the Project Gutenberg Library, basically be described as:</p>
<p class="itemText">Light Literature; such as Alice in Wonderland, Through the Looking-Glass, Peter Pan, Aesop's Fables, etc.</p>
<p class="itemText">Heavy Literature; such as the Bible or other religious documents, Shakespeare, Moby Dick, Paradise Lost, etc.</p>
<p class="itemText">References; such as Roget's Thesaurus, almanacs, and a set of encyclopedia, dictionaries, etc.</p>
<p class="itemText">The Light Literature Collection is designed to get persons to the computer in the first place, wheth...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">PG is the new kind of game</p>
<p class="itemText">The founding logic of Project Gutenberg resonates strikingly with Bordieu’s call to “universalize in reality the conditions of access” (qtd in Guillory 340, emphasis original) to literature.</p>
<p class="itemText">The first Project Gutenberg texts are almost a parody of important texts: The Declaration of Independence, The King James Bible. These are the texts assumed to be urgently desired by “99% of the general public” (Hart “History and Philosophy”). They are then followed, however, by a work which has rarely been ...</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">Hathi selection</p>
</li>
<li>
<p class="itemTitle">Google selection</p>
</li>
</ul>
</ul>
<hr class="afterTitle"/>

<li>
<p class="itemTitle">OCR</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">what accuracy is needed?</p>
<p class="itemText">How accurate does OCR need to be? This depends on how the OCR will then be used.</p>
</li>
<li>
<p class="itemTitle">checking OCR</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">let's check for accuracy</p>
<p class="itemText">The existence of a carefully hand-corrected transcription of The Emigrants in ECCO-TCP provides an opportunity to check the reliability of the OCR in both ECCO and HathiTrust. I will proceed from the assumption that the ECCO-TCP files are 100% accurate, and that any differences between the OCR and ECCO-TCP represents an OCR error. Before beginning the experiment, my hypothesis was that both ECCO and HathiTrust would differ from each other in where and how they are inaccurate, but would have simi...</p>
</li>
<li>
<p class="itemTitle">first page</p>
<p class="itemText">To make these comparisons concrete, consider the first page of Smith’s dedication, as it is captured by OCR in ECCO and HathiTrust, and in the ECCO-TCP transcript:</p>
<p class="itemText"></p>
<p class="itemText">TO WILLIAM COWPER, Es DEAR SIR, THERE is,- I hope, some propriety in my addrefing a Com- potion to you, which would,never perhaps have existed, had I not, amid the heavy prefure of many sorrows, derived infinite consolation from your Poetry, and some degree of animation and of confidencefrom your efieen. . 'he.following performance i...</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">fig:juxta-emigrants-p1</p>
<p class="itemText"></p>
<p class="itemText">Figure <$n:fig:juxta-emigrants-p1>: Juxta’s “Heat Map” visualization of the “base” witness of the first page of The Emigrants (i.e., the ECCO-TCP version carefully prepared by scholars), highlighting words which differ in the two witnesses of the ECCO OCR and the normalized HathiTrust OCR. A darker highlight indicates that the word varies in more than one witness.</p>
</li>
<li>
<p class="itemTitle">fig:juxta-emigrants-histogram</p>
<p class="itemText"></p>
<p class="itemText">Figure <$n:fig:juxta-emigrants-histogram>: A histogram, produced by Juxta, showing where the two ECCO and normalized HathiTrust witnesses show the most difference from the base ECCO-TCP copy. “Longer lines indicate areas of considerable difference, while shorter lines indicate greater similarity between documents.” (“A User Guide to Juxta Commons”)</p>
</li>
<li>
<p class="itemTitle">fig:ecco-emigrants-p1</p>
<p class="itemText"></p>
<p class="itemText">Figure <$n:fig:ecco-emigrants-p1>: The facsimile of the first page of The Emigrants found in ECCO, which forms the basis of the ECCO OCR text.</p>
</li>
<li>
<p class="itemTitle">fig:hathi-emigrants-p1</p>
<p class="itemText"></p>
<p class="itemText">Figure <$n:fig:hathi-emigrants-p1>: The facsimile of the first page of The Emigrants found in HathiTrust, which forms the basis of the HathiTrust OCR text.</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">others on OCR</p>
<p class="itemText">“16 In his discussion of JSTOR's "intolerably corrupt" OCR text, Nicholson Baker suggests that the reason why the user is prevented from scrolling through this naked OCR output is that scholars "might, after a few days, be dis- turbed by the frequency and strangeness of its mistakes . . . and they might no longer be willing to put their trust in the scholarly integrity of the database."17 Baker's criticism of JSTOR, however, is based on an error rate (with editorial intervention) of just one typ...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">conclusion</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">corpora as the new canons</p>
<p class="itemText">Like literary canons, these corpora — especially smaller ones, like the Eighteenth Century Collections Online Text Creation Partnership — are vulnerable to a critique of their selection methods on the grounds of representation. However, unlike the various changing literary canons of the past, digital corpora tend to conceal which particular titles have been selected as representative. I argue that Charlotte Smith’s inclusion in these resources lags behind a scholarly consensus which sees her as ...</p>
</li>
<li>
<p class="itemTitle">my OCR recs</p>
<p class="itemText">We are on the cusp of eighteenth-century OCR meeting the standards of twenty-first century OCR. What texts should be OCR’d, by whom, and what should be done with those text files?</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="topLevelItemTitle">ch 3 - database demographics</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">intro</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">BLUF</p>
</li>
</ul>
<hr class="afterTitle"/>

<li>
<p class="itemTitle">data cleaning</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">now I'm making my own thing</p>
<p class="itemText">The next phase of this project does not deal with these databases directly, but with my own curated samples. I have collected as much information as I can about all the works published in England 1789-99 held within each database. What follows is a detailed description of each of these samples, and of the further work which I employed to prepare these samples for computational experimentation</p>
</li>
<li>
<p class="itemTitle">tidy data</p>
<p class="itemText">“The more I listen to humanists working through data issues and challenges, I see a common tension arise:</p>
<p class="itemText">1. We know that all data is a reductive construction</p>
<p class="itemText">2. We also worry a lot about creating data that’s clean and</p>
<p class="itemText">usable enough to share, which would seem to imply we’ve already compromised on point 1.” (Lincoln)</p>
<p class="itemText"></p>
<p class="itemText">“Katie Rawson and Trevor Muñoz’s “Against Cleaning”, and the “Tidy Data” paper they cite by statistician Hadley Wickham. Although the former comes from a humanistic / librarian pers...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">gender-guesser</p>
</li>
<li>
<p class="itemTitle">my data collecction</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">ESTC</p>
<p class="itemText">My own sliver of the ESTC was generously provided to me by the British Library in January 2017. It contains all items matching the query I specified, “(Words= alldocuments and W-year= 1789->1799 and W-Country of publica= enk),” which requests all documents published between 1789 and 1799 (inclusive) with a place of publication encoded as “England.” Running this search on the ESTC website at the time returned 52,001 records. The tools used to create the file, according to the librarian with whom ...</p>
</li>
<li>
<p class="itemTitle">ECCO - MARC</p>
<p class="itemText">My first source of ECCO metadata consisted of MARC records, kindly provided by University of Toronto libraries (my thanks to Leslie Barnes!). I requested information for all works published 1789-99 in the UK (so, including Ireland and Scotland, but excluding America.) Later I changed my mind and didn’t want Ireland and Scotland any more, which created a problem for myself.</p>
<p class="itemText">My ECCO metadata presented particular challenges. I had access to MARC records, which stands for MAchine Readable Catalogue....</p>
</li>
<li>
<p class="itemTitle">ECCO - DSL</p>
<p class="itemText">Several years in to the project, Gale released a new interface for their various collections, the Digital Scholar Lab, which provided new forms of access to ECCO texts. Through the Digital Scholar Lab, it was now permitted to download the OCR transcripts of facsimiles, though only 10,000 items could be downloaded at a time. To work within the Digital Scholar Lab’s restrictions, I created eleven “Content Sets,” one for each year 1789-99, and downloaded them individually. The query used to find ea...</p>
</li>
<li>
<p class="itemTitle">ECCO TCP</p>
<p class="itemText">Somewhat oddly, because the Text Creation Partnership texts are made freely available, they are also somewhat difficult to track down. There is no central location with all of them and their related information — not even the TCP’s website. In [YEAR], the website contained many broken links to possible places to download the corpus, and the best guide was actually a blog post. By [YEAR], a general redesign of the TCP’s website added more up to date links for TCP texts and clarified what kinds of...</p>
</li>
<li>
<p class="itemTitle">HathiTrust</p>
<p class="itemText">The first step was to make a “collection” in the HathiTrust system.</p>
<p class="itemText">To search the catalog based on metadata is the best way to find what I want, but to add works found in that way, I would have needed to open each individual file. The catalog search returned 4,026 items.</p>
<p class="itemText">So instead I did a “full-text search” for a bogus search term but with my date range, added a restriction to England, and removed the search term. This method returned 8,220 full-text results, which I could add to my collection ...</p>
</li>
<li>
<p class="itemTitle">Google Ngram</p>
<p class="itemText">I attempted to find information about what is contained in Google Books, and rapidly discovered that there are no ways to search via bibliographic data, (though a search for a keyword can be filtered by publication date), nor are there any ways to identify how many titles were returned for a given query. Slightly more information was available for information about the Ngram viewer which was, as of 2013, not based on the ordinary Google Books holdings, but rather on specialized pre-selected and ...</p>
</li>
<li>
<p class="itemTitle">Project Gutenberg</p>
<p class="itemText">Project Gutenberg does not provide publication information about works (except for info about the publication of the ebook), so in order to identify which were published in England between 1789 and 1799, I would have to use my other corpora as a guide.</p>
<p class="itemText">[Is this something 18thConnect has done at all? Or would be interested in doing…?]</p>
<p class="itemText"></p>
<p class="itemText">Nonetheless it is possible to download “catalogs” of everything included in PG, in both plain text and XML and MARC versions. I downloaded plaintext lists for PG a...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">my data cleaning</p>
</li>
<li>
<p class="itemTextStart">The columns are: “Type of resource” (“Monograph” or “Serial”); “ESTC citation number”; “Name” (e.g., of an author, editor or illustrator); “Dates associated with name” (generally, the years they lived); “Type of name” (“meeting/conference,” “organization,” or “person”); “Role” (e.g., “author,” “cartographer,” or “bookseller”), “All names”, “Title”, “Variant titles”, “Place of publication”, “Publisher”, “Date of publication” (a single year), “Date of publication (not standardised)” (e.g., a year ...</p>
</li>
<li>
<p class="itemTitle">why topic model</p>
<p class="itemText">When working with large literary databases, scholars naturally wish to know what kind of literature they are working with. A high incidence of religious language in an eighteenth century corpus, for example, will mean something different depending on how many of the documents included in the corpus are sermons. However, the larger and more heterogenous the database, the less likely it is that all of its contents have been thoroughly and consistently identified. Eighteenth century texts predate s...</p>
</li>
<li>
<p class="itemTitle">why titles count</p>
<p class="itemText">In designing this tool, I want to take advantage of one of the unique features of eighteenth century literature: long and descriptive titles. In most periods of literary history, the information that gets input in the “title” field of a database offers a scholar very little to work with. Eighteenth century books were advertised and sold without any visual cues as to their contents; they attracted readers through the strength of their title pages alone. Bibliographers have consistently chosen to ...</p>
</li>
<li>
<p class="itemTitle">questions for comparison</p>
<p class="itemText"> Which of these archives are the most "reliable", and which the most "distorted"? (obvs interrogate this framework)</p>
<p class="itemText"> • What’s in all these, anyway?</p>
<p class="itemText"> ⁃ What does ECCO-TCP leave out compared to ECCO? Compared to ESTC? (Can I come up with adjustment factors?)</p>
<p class="itemText"> ⁃ How do digital vs physical holdings compare?</p>
</li>
<li>
<p class="itemTitle">raw notes</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">Numbers to compare to</p>
<p class="itemText">Comedies vs tragedies performed: the ratio of comedies to tragedies performed was an astonishing 14 to 1 in Paris (Theatre, Opera, and Audience in Revolutionary Paris: Analysis and Repertory by Emmet Kennedy, Marie-Laurence Netter, James P. McGregor, and Mark V. Olsen)</p>
<p class="itemText">Suarez numbers</p>
<p class="itemText">Some Statistics on the Number of Surviving Printed Titles for Great Britain and Dependencies from the Beginnings of Print in England to the year 1800, by Alain Veylit. </p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="topLevelItemTitle">Raw Writing</p>
<p class="itemText">Chapter Two</p>
</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">other ESTC notes</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">what it is</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">database structure</p>
<p class="itemText">“The Project staff found that many eighteenth-century books in hundreds of libraries around the world have never been / catalogued at all, or are described in a group heading,” especially for single-sheet items (Korshin 210-211). “Panizzis ‘Rules' lead to confusing entries and filing for anonymous entries or for items with corporate authorship. For these, and many other related reasons, Alston and Jannetta decided to write their own cataloguing rules, allowing their entries eventually to be conv...</p>
</li>
<li>
<p class="itemTitle">intended use</p>
<p class="itemText">Using the database:</p>
<p class="itemText">“the needs of the specialist audience that has formed ESTC’s main constituency in the past and may reasonably be expected to continue as such: the explorers in the field who need detailed maps. In my task of mediating between the file and its users, I find that these people approach early books with questions regarding one or both of two broad topics: intellectual content and physical characteristics, the latter including the location of copies,” with most interested in “the ...</p>
</li>
<li>
<p class="itemTitle">STAR</p>
<p class="itemText">The ESTC is not actually only one database: “The STAR file, maintained at the ESTC editorial office in Riverside, California, has been functioning for years as a repository for revisions that are transmitted in periodic updates to the publicly accessible file. … In consequence, though invisible and inaccessible to most of ESTC’s users, STAR contains the most up-to-date version of the file.” (Tabor 373) There are two kinds of information, in particular, which the STAR file contains and which is c...</p>
</li>
<li>
<p class="itemTitle">errors</p>
<p class="itemText">Transcription errors</p>
<p class="itemText"></p>
<p class="itemText">Broken records</p>
<p class="itemText">“A broken record occurs when information added to a record has not been checked against the copies already listed under that record” (Karian 285)</p>
<p class="itemText"></p>
<p class="itemText">Inaccurate dates</p>
<p class="itemText">‘The ESTC sometimes records the date as questionable, and sometimes records the date within a range. But when one does a large-scale search for records—for example, everything from 1720—there is no easy way to screen out items not definitively dated to 1720” (Karian 291)</p>
<p class="itemText"></p>
<p class="itemText">“only records bibliographi...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">estc comment</p>
<p class="itemText">As Suarez notes, the ESTC is a unique resource for pre-19thC works: “Regrettably, although this volume of The Cambridge history of the book in Britain ends in 1830, it is not possible to perform a similarly comprehensive analysis for the first decades of the nineteenth century because we have no equivalent bibliographical control for this period” (Suarez 40).</p>
</li>
<li>
<p class="itemTitle">ESTC > ECCO</p>
<p class="itemText">“To use a metaphor, some people prefer to explore the world through books of photographs with occasional schematic maps. ESTC, on the other hand, provides the equivalent of a detailed topographic map, but no pictures. Such technical tools have limited appeal, even to some specialists; but if you want to thoroughly learn the lie of the land, you will need one, and the more complete and accurate the better.” (Tabor)</p>
<p class="itemText"></p>

</li>
<hr class="afterText"/>
<ul>
<li>
<p class="itemTitle">history</p>
<p class="itemText">“An increasingly common trend, I am sorry to report, is that more and more people do not want ESTC at all — they want ECCO or EEBO. The younger generation of scholars in particular, lured by full-text images and ransacking the Web for illustrations for their books and articles, are using these utilities as de facto bibliographic databases. They find that the stripped-down records and simplified indexes are good enough for their purposes. To a minority of them, the fact that other works, editions...</p>
</li>
</ul>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">sampling</p>
<p class="itemText">Other work which has used the methodology of sampling includes </p>
<p class="itemText"></p>
<p class="itemText">Suarez: “Lacking the resources to conduct a detailed analysis of the entire ESTC from 1701 to 1800, I have resorted to sampling. Electing to examine all eighteenth-century records that appear in years ending in three – 1703, 1713, 1723 and so on – I have sought to avoid a number of cohort effects, most especially the cumulation of indeterminate records into years ending in ‘0’ or ‘1’ and, to a lesser degree, ‘5’.” (41)</p>
</li>
<li>
<p class="itemTitle">random sampling</p>
</li>
<hr class="afterTitle"/>
<ul>
<li>
<p class="itemTitle">method</p>
<p class="itemText">I created a “content set” called ECCO-1798 in Gale Digital Scholar Labs, by searching for all works in ECCO published “between” 1798 and 1798. This located 4,158 records. I downloaded the metadata for these 4,158 records as a CSV. I then used random.org’s “Random Integer Generator” to generate ten integers from 1 to 4,158 (inclusive), resulting in the following numbers: 1792, 2365, 159, 3511, 919, 170, 2136, 2259, 190, and 2242. I looked up the ten works appearing in those rows of the spreadshee...</p>
</li>
<li>
<p class="itemTitle">10 random 1798 titles</p>
<p class="itemText">159 - Poetry; original and selected Monograph Monograph Literature and Language I. [1796-98] Gale London, United Kingdom  British Library null GALE|CW0115892706 </p>
<p class="itemText">170 - Sir, You are desired to meet the committee for improving the navigation of the River Thames, and for preventing encroachments on the said river, on board the navigation barge, at Staines, on Saturday, the 7th day of July 1798, at eight o'clock in the morning, and proceed from thence down the river at nine precisely, ... Monograph ...</p>
</li>
<li>
<p class="itemTitle">10 random 1789 titles</p>
<p class="itemText">1053 - Le juge à paix, et officier de paroisse, pour la province de Quebec. Extrait de Richard Burn, chancellier du diocèse de Charlisle, & un des juges à paix de Sa Majesté, pour les comtés de Westmorland & Cumberland. Traduit par Jos. F. Perrault M.DCC.LXXXIX.[1789] London, United Kingdom Richard Burn </p>
<p class="itemText">2464 - An apology for professing the religion of nature, in the eighteenth century of the Christian aera; addressed to the Right Reverend Dr. Watson, Lord Bishop of Landaff MDCCLXXXIX. [1789] Ox...</p>
</li>
</ul>
<hr class="afterText"/>

<li>
<p class="itemTitle">what scholarly edition would I want to build?</p>
<p class="itemText">I could end by describing what Bode-like scholarly edition I’d like to make. What would it be?</p>
<p class="itemText">Datasets of men’s, women’s, and unsigned writing from the 1790s? Filtering to fiction, or poetry? Or sermons?? Non-literary writing? Things that people might want to teach?</p>
<p class="itemText">Circulating libraries? Maybe one specific library, to be feasible?</p>
<p class="itemText">Reprints??</p>
</li>
<li>
<p class="itemTitle">note on encoding</p>
<p class="itemText">A collocation formula like “ix,[3],68[i.e. 60]p. ; 4⁰” (the physical description of Smith’s The Emigrants provided in the ESTC, ECCO, and ECCO-TCP) is no more transparent and obvious in meaning than the following markup:</p>
<p class="itemText"><listPrefixDef></p>
<p class="itemText">            <prefixDef ident="tcp"</p>
<p class="itemText">                       matchPattern="([0-9\-]+):([0-9IVX]+)"</p>
<p class="itemText">                       replacementPattern="https://data.historicaltexts.jisc.ac.uk/view?pubId=ecco-$1&index=ecco&pageId=ecco-$1-$20"/></p>
<p class="itemText">            <prefixDef ident="ch...</p>
</li>
<li>
<p class="itemTitle">1790s abolition</p>
<p class="itemText">Vincent Carretta sees a lull in abolitionist activities during the late 1790s. Do I see anything like that?</p>
</li>
</ul>
</ul>

</td>
<td width="55px">
</td>
</tr>

<!-- Bottom margin -->
<tr><td height="15px"></td></tr>

</table>

</td>
</tr>
</table>

</body>
</html>
