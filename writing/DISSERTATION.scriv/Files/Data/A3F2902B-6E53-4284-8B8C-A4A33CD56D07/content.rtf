{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Georgia;}
{\colortbl;\red255\green255\blue255;\red204\green102\blue255;\red15\green128\blue255;\red253\green162\blue255;
}
{\*\expandedcolortbl;;\cssrgb\c84466\c51457\c100000;\cssrgb\c0\c58980\c100000;\cssrgb\c99933\c71615\c100000;
}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl312\slmult1\pardirnatural\partightenfactor0

\f0\b\fs22 \cf2 What\'92s crucial, to use computational reading reparatively, is to use it 
\i \cf2 reflectively
\i0 \cf2 . 
\b0 \cf2 The desirable kinds of computation which I describe above will not happen inevitably. Here I draw upon the rich body of work emerging in critical algorithm studies, which examines (and attempts to reform) the human elements of computational algorithms. \cf0 Any methodology is, to a certain extent, an \'93algorithm,\'94 in the loose definition of \'91a series of pre-defined steps to be carried out\'92. But computational algorithms differ from \'93algorithms\'94 implemented by humans. Computational algorithms have two key vulnerabilities: first, their operations are less easily scrutinized; second, their results are more easily trusted. The second vulnerability \'97 the cultural aura of empirical trustworthiness which accrues to anything \'91computational\'92 \'97 is another flavour of the same vulnerability that Drucker describes with \'91data\'92 generally. Because the human agents who designed and trained any given algorithm appear to be absent from its operation, the algorithm appears able to discover truth directly. This is how Daily Wire reporter Ryan Saavedra was able to tweet with disdain that \'93Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist\'94 \cf3 (@\cf2 RealSaavedra\cf3 )\cf0 : anything \'93driven by math,\'94 he assumes, must be incapable of human fallibilities like racism. But as Safiya Noble shows extensively in 
\i Algorithms of Oppression
\i0 , algorithms by default reproduce, and can easily exaggerate, the assumptions and biases of the culture in which they are made \cf3 (\cb4 CITE\cb1 )\cf0 . In other words, in a racist world, algorithms 
\i are
\i0  racist \'97 and sexist, and duplicative of all other systemic inequities.\
}