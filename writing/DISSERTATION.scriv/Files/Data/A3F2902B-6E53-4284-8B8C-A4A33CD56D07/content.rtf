{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Georgia;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl312\slmult1\pardirnatural\partightenfactor0

\f0\fs22 \cf0 My emphasis on transparent, critical, and reflective praxis in the capture and visual presentation of {\field{\*\fldinst{HYPERLINK "scrivcmt://981477E4-12BF-4379-AEEA-95717DD33AC5"}}{\fldrslt data}} owes much to the emerging field of critical algorithm studies. Any methodology is, to a certain extent, an \'93algorithm,\'94 in the loose definition of \'91a series of pre-defined steps to be carried out\'92. But computational algorithms differ from \'93algorithms\'94 implemented by humans. Computational algorithms have two key vulnerabilities: first, their operations are less easily scrutinized; second, their results are more easily trusted. The second vulnerability \'97 the cultural aura of empirical trustworthiness which accrues to anything \'91computational\'92 \'97 is another flavour of the same vulnerability that Drucker describes with \'91data\'92 generally. Because the human agents who designed and trained any given algorithm appear to be absent from its operation, the algorithm appears able to discover truth directly. This is how Daily Wire reporter Ryan Saavedra was able to tweet with disdain that \'93Rep. Alexandria Ocasio-Cortez (D-NY) claims that algorithms, which are driven by math, are racist\'94 \\cite\{Saavedra:2019wr\}: anything \'93driven by math,\'94 he assumes, must be incapable of human fallibilities like racism. But as Safiya Noble shows extensively in 
\i Algorithms of Oppression
\i0 , algorithms by default reproduce, and can easily exaggerate, the assumptions and biases of the culture in which they are made \\cite\{Noble:2018wo\}. In other words, in a racist world, algorithms 
\i are
\i0  racist \'97 and sexist, and duplicative of all other systemic institutional inequities.\
Wendy Chun suggests that the problem with much algorithmic inquiry lies in its most core assumption: the insistence that the future must look like the past \\cite\{Chun:2018tq\}. This assumption is essential to any system which exclusively bases its predictions on past data. It is particularly intertwined with what Chun calls \'93homophily,\'94 \'93the axiom that similarity breeds connection\'97which grounds contemporary network science\'94 \\cite\{Chun:2018tq p.60\}. Homophily, as it is currently applied to network science, Chun argues, both \'93assumes and creates segregation\'94 \\cite\{Chun:2018tq p.76\} in a fashion that allows it to operate \'93like money laundering for bias\'94 \\cite\{Chun:2018tq pp.62-63\}. Importantly, however, the analogy to money laundering is imperfect: it cannot be resolved with \'93better, cleaner data\'94 \\cite\{Chun:2018tq p.64\}. Instead, Chun insists, \'93new theories of connection\'97which do not presume a dangerously banal and reciprocal notion of friendship\'97are needed\'94 \\cite\{Chun:2018tq p.89\}, a call to action which places its emphasis not on the information provided to an algorithm but on the algorithm\'92s procedures.}