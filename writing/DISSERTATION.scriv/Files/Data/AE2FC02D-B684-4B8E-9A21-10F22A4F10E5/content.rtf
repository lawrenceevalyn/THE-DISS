{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Georgia;}
{\colortbl;\red255\green255\blue255;\red15\green128\blue255;}
{\*\expandedcolortbl;;\cssrgb\c0\c58980\c100000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid1\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid1}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl312\slmult1\pardirnatural\partightenfactor0

\f0\fs22 \cf2 I attempted to find information about what is contained in Google Books, and rapidly discovered that there are no ways to search via bibliographic data, (though a search for a keyword can be filtered by publication date), nor are there any ways to identify how many titles were returned for a given query. Slightly more information was available for information about the Ngram viewer which was, 
\b as of 2013
\b0 , not based on the ordinary Google Books holdings, but rather on specialized pre-selected and pre-processed corpora, created in 2009 and 2012 (\'93Google Books Ngram Viewer: Info\'94).\
I\'92m not planning to download any Google Ngram data, I just want to know what (if anything) can determine about its sources, to shed light on use of the Ngram viewer.\
\
\'93Below are descriptions of the corpora that can be searched with the Google Books Ngram Viewer. All corpora were generated in either July 2009 or July 2012; we will update these corpora as our book scanning continues, and the updated versions will have distinct persistent identifiers. Books with low OCR quality and serials were excluded\'94 (\'93Google Books Ngram Viewer: Info\'94)\
\
Possibly containing stuff 1789-99 (\'93Google Books Ngram Viewer: Info\'94)\
\pard\tx220\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\li720\fi-720\sl312\slmult1\pardirnatural\partightenfactor0
\ls1\ilvl0\cf2 {\listtext	\uc0\u8226 	}\'93English One Million\'94 - \'93The "Google Million". All are in English with dates ranging from 1500 to 2008. No more than about 6000 books were chosen from any one year, which means that all of the scanned books from early years are present, and books from later years are randomly sampled. The random samplings reflect the subject distributions for the year (so there are more computer books in 2000 than 1980).\'94\
\ls1\ilvl0{\listtext	\uc0\u8226 	}\'93British English 2012\'94 / \'93British English 2009\'94 - Books predominantly in the English language that were published in Great Britain.\
\ls1\ilvl0{\listtext	\uc0\u8226 	}\'93English 2012\'94 / \'93English 2009\'94 - \'93Books predominantly in the English language published in any country.\'94\
\ls1\ilvl0{\listtext	\uc0\u8226 	}\'93English Fiction 2012\'94 / \'93English Fiction 2009\'94 - \'93Books predominantly in the English language that a library or publisher identified as fiction.\'94\
\pard\tx560\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\sl312\slmult1\pardirnatural\partightenfactor0
\cf2 \
\'93Compared to the 2009 versions, the 2012 versions have more books, improved OCR, improved library and publisher metadata. The 2012 versions also don't form ngrams that cross sentence boundaries, and do form ngrams across page boundaries, unlike the 2009 versions. With the 2012 corpora, the tokenization has improved as well, using a set of manually devised rules (except for Chinese, where a statistical system is used for segmentation). In the 2009 corpora, tokenization was based simply on whitespace.\'94 (\'93Google Books Ngram Viewer: Info\'94)\
\'93Many more books are published in modern years. Doesn't this skew the results? It would if we didn't normalize by the number of books published in each year.\'94 (\'93Google Books Ngram Viewer: Info\'94)\
\
\
Also consult \'93Characterizing the Google Books corpus: Strong limits to inferences of socio-cultural and linguistic evolution\'94 for more info}