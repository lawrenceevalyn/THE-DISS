<?xml version="1.0" encoding="UTF-8"?>
<Comments>
    <Comment ID="F786BEC7-7D93-4034-8DE2-A77298CDD56F" Color="0.999133 0.954802 0.756378"><![CDATA[{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Q for Alex: have I done enough on canons to make this work?}]]></Comment>
    <Comment ID="3DC180A9-F367-41C0-ABEC-50B740FDAC68" Color="0.999133 0.954802 0.756378"><![CDATA[{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Most alarming \'97 and I don\'92t know how to verify this sufficiently to state it as fact in the diss \'97 is the fact that, when they have multiple scans from multiple copies of a given text, they just pick the metadata from one of those copies and apply it to all of the copies. So a scan of a book will be accompanied by what appears to be a detailed physical description of that book, but it might actually describe a different book! And there is no indication whatsoever on the site that this is true}]]></Comment>
    <Comment ID="11F18703-D8CC-4888-B729-DC3E24760DDC" Footnote="Yes" Color="0.949769 0.949769 0.949769"><![CDATA[{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf400
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs24 \cf0 For example, it might be able to acquire a text document with all of the words of a novel, but sorted into alphabetic order: such a text file can be used for some analyses based on word-frequency, but cannot be read. Or, it might be possible to find collocations of where a given word appears, but with only a limited number of words of context on either side of the term in question. Or, scholars can run pre-written code provided by HathiTrust to carry out things like topic modelling on the full, intact texts of their chosen works, but without being able to inspect those texts or run their own code on them. All of these modes of analysis make research much more difficult to carry out, and nearly impossible to verify. In the study of contemporary copyrighted literature, however, even these very limited tools for corpus analysis are valuable.}]]></Comment>
</Comments>